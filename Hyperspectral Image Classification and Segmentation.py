# -*- coding: utf-8 -*-
"""Hyperspectral_Image_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rzlDOSR4iA7KGblq6A55rN_pVNbB0AEm

# Imports
"""

import numpy as np
import types
import pandas as pd
import requests
import glob
import os
import sys
import time
import math
import hashlib
import random
import traceback
import colorsys
import gc

from pathlib import Path
from tqdm import tqdm
import urllib.request
from typing import Dict, Tuple, Union, List, Optional, Type, Callable, Any
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter

from scipy.io import loadmat
from scipy.spatial import distance
from scipy.stats import entropy, pearsonr
from scipy.ndimage import rotate

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, label_binarize
from sklearn.decomposition import PCA, FastICA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import silhouette_score, calinski_harabasz_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, precision_score, jaccard_score, recall_score, accuracy_score, f1_score, classification_report, precision_recall_curve, precision_recall_fscore_support, roc_curve, auc

from types import SimpleNamespace
import torch.optim as optim

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, TensorDataset
import torchvision.transforms.functional as TF
from torch.optim.lr_scheduler import _LRScheduler
from torchvision import transforms
from dataclasses import dataclass, field

import matplotlib.pyplot as plt
from matplotlib import gridspec
from matplotlib.gridspec import GridSpec
from matplotlib import cm
from matplotlib.patches import Patch
from matplotlib.colors import LinearSegmentedColormap, ListedColormap
from mpl_toolkits.axes_grid1 import make_axes_locatable
from matplotlib_venn import venn2
from mpl_toolkits.mplot3d import Axes3D
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

"""# **1.Data Acquisition and Preprocessing**

## Downloading Datasets
*   Indian Pines
*   Pavia University
*   Salinas Scene
"""

class HyperspectralDataLoader:
    """
    Class to handle downloading and loading of hyperspectral datasets
    """

    # Dataset URLs and information
    DATASETS = {
        'indian_pines': {
            'data_url': 'http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat',
            'gt_url': 'http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat',
            'data_key': 'indian_pines_corrected',
            'gt_key': 'indian_pines_gt'
        },
        'pavia_university': {
            'data_url': 'http://www.ehu.eus/ccwintco/uploads/e/ee/PaviaU.mat',
            'gt_url': 'http://www.ehu.eus/ccwintco/uploads/5/50/PaviaU_gt.mat',
            'data_key': 'paviaU',
            'gt_key': 'paviaU_gt'
        },
        'salinas': {
            'data_url': 'http://www.ehu.eus/ccwintco/uploads/a/a3/Salinas_corrected.mat',
            'gt_url': 'http://www.ehu.eus/ccwintco/uploads/f/fa/Salinas_gt.mat',
            'data_key': 'salinas_corrected',
            'gt_key': 'salinas_gt'
        }
    }

    def __init__(self, dataset_name: str, download_dir: str = 'datasets',silent=False):
        """
        Initialize the data loader

        Args:
            dataset_name: Name of the dataset ('indian_pines', 'pavia_university', 'salinas')
            download_dir: Directory to store downloaded files
        """
        self.dataset_name = dataset_name.lower()
        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(parents=True, exist_ok=True)

        if self.dataset_name not in self.DATASETS:
            raise ValueError(f"Dataset {dataset_name} not supported. Choose from {list(self.DATASETS.keys())}")

        self.dataset_info = self.DATASETS[self.dataset_name]

    def download_file(self, url: str, filename: str,silent) -> str:
        """
        Download file from URL with progress bar

        Args:
            url: URL to download from
            filename: Name to save the file as

        Returns:
            Path to downloaded file
        """
        filepath = self.download_dir / filename

        if not silent:
          if filepath.exists():
              print(f"File {filename} already exists. Skipping download.")
              return str(filepath)

          print(f"Downloading {filename}...")

        try:
            response = requests.head(url)
            file_size = int(response.headers.get('content-length', 0))

            progress = tqdm(total=file_size, unit='iB', unit_scale=True)

            def report_hook(count, block_size, total_size):
                progress.update(block_size)

            urllib.request.urlretrieve(url, str(filepath), reporthook=report_hook)
            progress.close()

            print(f"Successfully downloaded {filename}")
            return str(filepath)

        except Exception as e:
            print(f"Error downloading {filename}: {str(e)}")
            if filepath.exists():
                filepath.unlink()
            raise

    def load_dataset(self, silent=False, download: bool = True) -> Tuple[np.ndarray, np.ndarray]:
        """
        Download (if needed) and load the dataset

        Args:
            download: Whether to download the dataset if it's not found locally

        Returns:
            Tuple of (hyperspectral_data, ground_truth)
        """
        data_filename = f"{self.dataset_name}_data.mat"
        gt_filename = f"{self.dataset_name}_gt.mat"

        if download:
            data_path = self.download_file(self.dataset_info['data_url'], data_filename,silent)
            gt_path = self.download_file(self.dataset_info['gt_url'], gt_filename,silent)
        else:
            data_path = str(self.download_dir / data_filename)
            gt_path = str(self.download_dir / gt_filename)

            if not (Path(data_path).exists() and Path(gt_path).exists()):
                raise FileNotFoundError("Dataset files not found locally. Set download=True to download.")

        try:
            data = loadmat(data_path)[self.dataset_info['data_key']]
            gt = loadmat(gt_path)[self.dataset_info['gt_key']]

            if not silent:
              print(f"Dataset loaded successfully!")
              print(f"Data shape: {data.shape}")
              print(f"Ground truth shape: {gt.shape}")
              print(f"Number of classes: {len(np.unique(gt))}")

            return data, gt

        except Exception as e:
            print(f"Error loading dataset: {str(e)}")
            raise

def get_dataset_info(dataset_name: str) -> Dict:
    """
    Get information about the dataset

    Args:
        dataset_name: Name of the dataset ('indian_pines', 'pavia_university', 'salinas')

    Returns:
        Dictionary containing dataset information
    """
    datasets = {
        'indian_pines': {
            'num_classes': 16,
            'num_bands': 200,
            'spatial_size': (145, 145),
            'wavelength_range': '0.4-2.5 µm',
            'spatial_resolution': '20m',
            'class_names': [
                'Background',          # 0
                'Alfalfa',            # 1
                'Corn-notill',        # 2
                'Corn-mintill',       # 3
                'Corn',               # 4
                'Grass-pasture',      # 5
                'Grass-trees',        # 6
                'Grass-pasture-mowed',# 7
                'Hay-windrowed',      # 8
                'Oats',               # 9
                'Soybean-notill',     # 10
                'Soybean-mintill',    # 11
                'Soybean-clean',      # 12
                'Wheat',              # 13
                'Woods',              # 14
                'Buildings-Grass-Trees-Drives', # 15
                'Stone-Steel-Towers'  # 16
            ],
            'noisy_bands': [104-1, 105-1, 150-1, 151-1, 152-1, 153-1, 154-1, 155-1]
        },

        'pavia_university': {
            'num_classes': 9,
            'num_bands': 103,
            'spatial_size': (610, 340),
            'wavelength_range': '0.43-0.86 µm',
            'spatial_resolution': '1.3m',
            'class_names': [
                'Background',          # 0
                'Asphalt',            # 1
                'Meadows',            # 2
                'Gravel',             # 3
                'Trees',              # 4
                'Painted metal sheets',# 5
                'Bare Soil',          # 6
                'Bitumen',            # 7
                'Self-Blocking Bricks',# 8
                'Shadows'             # 9
            ],
            'noisy_bands': []
        },

        'salinas': {
            'num_classes': 16,
            'num_bands': 204,
            'spatial_size': (512, 217),
            'wavelength_range': '0.4-2.5 µm',
            'spatial_resolution': '3.7m',
            'class_names': [
                'Background',            # 0
                'Brocoli_green_weeds_1', # 1
                'Brocoli_green_weeds_2', # 2
                'Fallow',               # 3
                'Fallow_rough_plow',    # 4
                'Fallow_smooth',        # 5
                'Stubble',              # 6
                'Celery',               # 7
                'Grapes_untrained',     # 8
                'Soil_vinyard_develop', # 9
                'Corn_senesced_weeds',  # 10
                'Lettuce_romaine_4wk',  # 11
                'Lettuce_romaine_5wk',  # 12
                'Lettuce_romaine_6wk',  # 13
                'Lettuce_romaine_7wk',  # 14
                'Vinyard_untrained',    # 15
                'Vinyard_vertical_trellis' # 16
            ],
            'noisy_bands': [108-1, 109-1, 110-1, 111-1, 112-1, 113-1, 114-1, 115-1]
        }
    }

    dataset_name = dataset_name.lower()
    if dataset_name in datasets:
        return datasets[dataset_name]
    else:
        raise ValueError(f"Dataset {dataset_name} not supported. Choose from {list(datasets.keys())}")

def main():
    """
    Example of how to use the data loader with different datasets
    """
    for dataset_name in ['indian_pines', 'pavia_university', 'salinas']:
        print(f"\nTesting {dataset_name.upper()} dataset:")

        loader = HyperspectralDataLoader(dataset_name)

        data, ground_truth = loader.load_dataset()

        print("\nDataset Information:")
        print(f"Data shape: {data.shape}")
        print(f"Ground truth shape: {ground_truth.shape}")
        print(f"Data type: {data.dtype}")
        print(f"Unique classes: {np.unique(ground_truth)}")

        info = get_dataset_info(dataset_name)
        print(f"\nDetailed Information for {dataset_name}:")
        print(f"Number of classes: {info['num_classes']}")
        print(f"Number of spectral bands: {info['num_bands']}")
        print(f"Spatial size: {info['spatial_size']}")
        print(f"Wavelength range: {info['wavelength_range']}")
        print(f"Spatial resolution: {info['spatial_resolution']}")

        print("\nClass Names:")
        for i, name in enumerate(info['class_names']):
            print(f"Class {i}: {name}")

        if info['noisy_bands']:
            print(f"\nNoisy bands: {[b+1 for b in info['noisy_bands']]}")

if __name__ == "__main__":
    main()

"""## SELECT DATASET"""

SELECTED_DATASET = ['indian_pines']  # Options: 'indian_pines', 'pavia_university', 'salinas'

"""## Data Format Conversion and Organization"""

class HyperspectralDataOrganizer:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, dataset_name: str, silent: str):
        """
        Initialize with memory-efficient handling for all datasets

        Args:
            data: Hyperspectral data
            ground_truth: Ground truth labels
            dataset_name: Name of dataset ('indian_pines', 'pavia_university', 'salinas')
        """
        self.data = data.astype(np.float32)
        self.ground_truth = ground_truth
        self.dataset_name = dataset_name
        self.info = get_dataset_info(dataset_name)

        self.print_class_distribution(silent)

    def print_class_distribution(self,silent=False):
        """
        Print the distribution of classes including background
        """
        unique_classes, counts = np.unique(self.ground_truth, return_counts=True)
        total_pixels = self.ground_truth.size

        if not silent:
          print("\nClass Distribution:")
          print(f"{'Class':<25} {'Count':<10} {'Percentage':>10}")
          print("-" * 45)

          for cls, count in zip(unique_classes, counts):
              if cls == 0:
                  class_name = "Background/Unlabeled"
              else:
                  class_name = self.info['class_names'][cls]
              percentage = (count / total_pixels) * 100
              print(f"{class_name:<25} {count:<10} {percentage:>10.2f}%")

          print("\nSummary:")
          print(f"Total pixels: {total_pixels}")
          print(f"Background pixels: {counts[0]}")
          print(f"Labeled pixels: {sum(counts[1:])}")
          print(f"Number of actual classes: {len(unique_classes)-1}")

    def normalize_data(self, method='standard', chunk_size=1000) -> np.ndarray:
        """
        Memory-efficient normalization

        Args:
            method: 'standard' or 'minmax'
            chunk_size: Size of chunks for processing
        """

        print(f"\nNormalizing data using {method} method...")

        h, w, b = self.data.shape
        data_2d = self.data.reshape(-1, b)

        if h * w > 100000:
            if method == 'standard':
                mean = np.zeros(b, dtype=np.float32)
                squared_sum = np.zeros(b, dtype=np.float32)
                n_samples = h * w

                for i in range(0, h*w, chunk_size):
                    chunk = data_2d[i:i+chunk_size]
                    mean += chunk.sum(axis=0)
                mean /= n_samples

                for i in range(0, h*w, chunk_size):
                    chunk = data_2d[i:i+chunk_size]
                    squared_sum += ((chunk - mean) ** 2).sum(axis=0)
                std = np.sqrt(squared_sum / n_samples)

                for i in range(0, h*w, chunk_size):
                    chunk = data_2d[i:i+chunk_size]
                    data_2d[i:i+chunk_size] = (chunk - mean) / (std + 1e-8)

            elif method == 'minmax':
                min_val = np.min(data_2d, axis=0)
                max_val = np.max(data_2d, axis=0)

                for i in range(0, h*w, chunk_size):
                    chunk = data_2d[i:i+chunk_size]
                    data_2d[i:i+chunk_size] = (chunk - min_val) / (max_val - min_val + 1e-8)

        else:
            if method == 'standard':
                mean = np.mean(data_2d, axis=0)
                std = np.std(data_2d, axis=0)
                data_2d = (data_2d - mean) / (std + 1e-8)

            elif method == 'minmax':
                min_val = np.min(data_2d, axis=0)
                max_val = np.max(data_2d, axis=0)
                data_2d = (data_2d - min_val) / (max_val - min_val + 1e-8)

        self.data = data_2d.reshape(h, w, b)
        return self.data

    def create_pixel_samples(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        Create pixel-wise samples for training (excluding background)
        """
        print("\nCreating pixel-wise samples...")

        valid_indices = np.where(self.ground_truth > 0)

        X = self.data[valid_indices[0], valid_indices[1], :].astype(np.float32)
        y = (self.ground_truth[valid_indices[0], valid_indices[1]] - 1).astype(np.int32)

        print(f"Created {len(X)} labeled samples with {X.shape[1]} features")
        print(f"Class range after conversion: {np.min(y)} to {np.max(y)}")
        return X, y

    def create_patch_samples(self, patch_size: int = 13, padding: str = 'reflect',
                           batch_size: int = None) -> Tuple[np.ndarray, np.ndarray]:
        """
        Memory-efficient patch creation

        Args:
            patch_size: Size of patches
            padding: Type of padding
            batch_size: Size of batches for processing (auto-determined if None)
        """
        print(f"\nCreating patches of size {patch_size}x{patch_size}...")

        pad_size = patch_size // 2

        padded_data = np.pad(
            self.data,
            ((pad_size, pad_size), (pad_size, pad_size), (0, 0)),
            mode=padding
        )

        valid_indices = np.where(self.ground_truth > 0)
        num_samples = len(valid_indices[0])

        if batch_size is None:
            if num_samples > 50000:  # (Salinas)
                batch_size = 1000
            elif num_samples > 20000:  # (Pavia University)
                batch_size = 2000
            else:  # (Indian Pines)
                batch_size = 5000

        patches = np.zeros((num_samples, patch_size, patch_size, self.data.shape[2]),
                         dtype=np.float32)
        labels = (self.ground_truth[valid_indices[0], valid_indices[1]] - 1).astype(np.int32)

        num_batches = int(np.ceil(num_samples / batch_size))

        for batch_idx in tqdm(range(num_batches), desc="Processing patches"):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, num_samples)

            for i in range(start_idx, end_idx):
                center_x = valid_indices[0][i] + pad_size
                center_y = valid_indices[1][i] + pad_size

                patches[i] = padded_data[
                    center_x - pad_size:center_x + pad_size + 1,
                    center_y - pad_size:center_y + pad_size + 1,
                    :
                ]

            if batch_idx % 10 == 0:
                import gc
                gc.collect()

        print(f"Created {len(patches)} patches of shape {patches.shape[1:]}")
        return patches, labels

    def organize_samples(self, patch_size: int = 13) -> Dict:
        """
        Organize data into pixel and patch samples with proper normalization
        """
        self.normalize_data(method='standard')

        pixels_X, pixels_y = self.create_pixel_samples()
        patches_X, patches_y = self.create_patch_samples(patch_size=patch_size)

        samples = {
            'pixels': {
                'X': pixels_X,
                'y': pixels_y,
                'shape': pixels_X.shape
            },
            'patches': {
                'X': patches_X,
                'y': patches_y,
                'shape': patches_X.shape
            },
            'class_names': self.info['class_names'][1:],
            'num_classes': self.info['num_classes']
        }

        return samples

def process_hyperspectral_data(dataset_name: str,silent=False):
    """
    Process any of the three hyperspectral datasets

    Args:
        dataset_name: 'indian_pines', 'pavia_university', or 'salinas'
    """
    try:
        loader = HyperspectralDataLoader(dataset_name)
        data, ground_truth = loader.load_dataset() #silent=True

        if not silent:
          print("\nGround Truth Information:")
          print(f"Shape: {ground_truth.shape}")
          print(f"Unique values: {np.unique(ground_truth)}")
          print(f"Value range: {ground_truth.min()} to {ground_truth.max()}")

        organizer = HyperspectralDataOrganizer(data, ground_truth, dataset_name,silent=False)

        samples = organizer.organize_samples()

        if not silent:
          print("\nOrganized Data Information:")
          print(f"Pixel samples shape: {samples['pixels']['shape']}")
          print(f"Patch samples shape: {samples['patches']['shape']}")
          print(f"Number of classes for classification: {samples['num_classes']}")

        return samples

    except Exception as e:
        print(f"Error processing {dataset_name} dataset: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

for dataset in SELECTED_DATASET:
    print(f"\nProcessing {dataset.upper()} dataset...")
    samples = process_hyperspectral_data(dataset)
    if samples is not None:
        print(f"Successfully processed {dataset} dataset!")

"""## Splitting Dataset (80/10/10)"""

class HyperspectralDataSplitter:
    def __init__(self, samples: Dict):
        """
        Initialize the splitter with organized samples
        """
        if samples is None or not isinstance(samples, dict):
            raise ValueError("Invalid samples provided to DataSplitter")

        try:
            self.pixels = {
                'X': samples['pixels']['X'].astype(np.float32),
                'y': samples['pixels']['y'].astype(np.int32)
            }
            self.patches = {
                'X': samples['patches']['X'].astype(np.float32),
                'y': samples['patches']['y'].astype(np.int32)
            }
        except KeyError as e:
            raise KeyError(f"Missing required key in samples dictionary: {e}")

    def split_data(self,
                  train_size: float = 0.8,
                  val_size: float = 0.1,
                  random_state: int = 42,
                  batch_size: int = None) -> Dict:
        """
        Split both pixel and patch data into train/val/test sets
        """
        try:
            print("\n" + "="*50)
            print("Dataset Splitting")
            print("="*50)
            print(f"\nSplit ratios:")
            print(f"- Train: {train_size:.1%}")
            print(f"- Validation: {val_size:.1%}")
            print(f"- Test: {1-train_size-val_size:.1%}")

            total_samples = len(self.pixels['y'])
            use_batches = total_samples > 50000

            if use_batches:
                print("\nUsing batch processing for large dataset...")
                batch_size = batch_size or 10000

            temp_size = train_size + val_size

            if use_batches:
                indices = np.arange(total_samples)
                train_val_idx, test_idx = train_test_split(
                    indices,
                    train_size=temp_size,
                    stratify=self.pixels['y'],
                    random_state=random_state
                )

                train_idx, val_idx = train_test_split(
                    train_val_idx,
                    train_size=train_size/temp_size,
                    stratify=self.pixels['y'][train_val_idx],
                    random_state=random_state
                )

                def process_data_batch(data, indices):
                    processed_data = []
                    for i in range(0, len(indices), batch_size):
                        batch_indices = indices[i:i + batch_size]
                        processed_data.append(data[batch_indices])
                    return np.concatenate(processed_data, axis=0)

                X_train_pixel = process_data_batch(self.pixels['X'], train_idx)
                X_val_pixel = process_data_batch(self.pixels['X'], val_idx)
                X_test_pixel = process_data_batch(self.pixels['X'], test_idx)

                y_train_pixel = self.pixels['y'][train_idx]
                y_val_pixel = self.pixels['y'][val_idx]
                y_test_pixel = self.pixels['y'][test_idx]

                X_train_patch = process_data_batch(self.patches['X'], train_idx)
                X_val_patch = process_data_batch(self.patches['X'], val_idx)
                X_test_patch = process_data_batch(self.patches['X'], test_idx)

                y_train_patch = self.patches['y'][train_idx]
                y_val_patch = self.patches['y'][val_idx]
                y_test_patch = self.patches['y'][test_idx]

            else:
                X_temp_pixel, X_test_pixel, y_temp_pixel, y_test_pixel = train_test_split(
                    self.pixels['X'],
                    self.pixels['y'],
                    train_size=temp_size,
                    stratify=self.pixels['y'],
                    random_state=random_state
                )

                X_temp_patch, X_test_patch, y_temp_patch, y_test_patch = train_test_split(
                    self.patches['X'],
                    self.patches['y'],
                    train_size=temp_size,
                    stratify=self.patches['y'],
                    random_state=random_state
                )

                val_ratio = val_size / temp_size

                X_train_pixel, X_val_pixel, y_train_pixel, y_val_pixel = train_test_split(
                    X_temp_pixel,
                    y_temp_pixel,
                    test_size=val_ratio,
                    stratify=y_temp_pixel,
                    random_state=random_state
                )

                X_train_patch, X_val_patch, y_train_patch, y_val_patch = train_test_split(
                    X_temp_patch,
                    y_temp_patch,
                    test_size=val_ratio,
                    stratify=y_temp_patch,
                    random_state=random_state
                )

            splits = {
                'pixel_data': {
                    'train': (X_train_pixel, y_train_pixel),
                    'val': (X_val_pixel, y_val_pixel),
                    'test': (X_test_pixel, y_test_pixel)
                },
                'patch_data': {
                    'train': (X_train_patch, y_train_patch),
                    'val': (X_val_patch, y_val_patch),
                    'test': (X_test_patch, y_test_patch)
                }
            }

            self._print_split_info(splits, y_train_pixel, y_val_pixel, y_test_pixel)

            return splits

        except Exception as e:
            print(f"Error during data splitting: {e}")
            raise

    def _print_split_info(self, splits, y_train, y_val, y_test):
        """Helper method to print split information"""
        print("\nSplit sizes:")
        print("\nPixel-wise samples:")
        print(f"- Train: {splits['pixel_data']['train'][0].shape}")
        print(f"- Validation: {splits['pixel_data']['val'][0].shape}")
        print(f"- Test: {splits['pixel_data']['test'][0].shape}")

        print("\nPatch-wise samples:")
        print(f"- Train: {splits['patch_data']['train'][0].shape}")
        print(f"- Validation: {splits['patch_data']['val'][0].shape}")
        print(f"- Test: {splits['patch_data']['test'][0].shape}")

        total_samples = len(y_train) + len(y_val) + len(y_test)
        print(f"\nActual split proportions:")
        print(f"- Train: {len(y_train)/total_samples:.1%}")
        print(f"- Validation: {len(y_val)/total_samples:.1%}")
        print(f"- Test: {len(y_test)/total_samples:.1%}")

def split_dataset(samples: Dict,
                 train_size: float = 0.8,
                 val_size: float = 0.1,
                 random_state: int = 42) -> Dict:
    """
    Convenience function to split the dataset
    """
    try:
        splitter = HyperspectralDataSplitter(samples)
        return splitter.split_data(train_size, val_size, random_state)
    except Exception as e:
        print(f"Error in split_dataset: {e}")
        return None

if __name__ == "__main__":
    all_dataset_splits = {}

    for dataset in SELECTED_DATASET:
        print(f"\n{'='*50}")
        print(f"Processing {dataset.upper()}")
        print(f"{'='*50}")

        if samples is not None:
            splits = split_dataset(samples)

            if splits is not None:
                all_dataset_splits[dataset] = splits

                X_train_pixel, y_train_pixel = splits['pixel_data']['train']
                X_val_pixel, y_val_pixel = splits['pixel_data']['val']
                X_test_pixel, y_test_pixel = splits['pixel_data']['test']

                X_train_patch, y_train_patch = splits['patch_data']['train']
                X_val_patch, y_val_patch = splits['patch_data']['val']
                X_test_patch, y_test_patch = splits['patch_data']['test']

                print(f"\nDataset: {dataset} - Summary")
                print(f"Pixel-wise data shapes:")
                print(f"- Train: {X_train_pixel.shape} labels: {y_train_pixel.shape}")
                print(f"- Validation: {X_val_pixel.shape} labels: {y_val_pixel.shape}")
                print(f"- Test: {X_test_pixel.shape} labels: {y_test_pixel.shape}")

                print(f"\nPatch-wise data shapes:")
                print(f"- Train: {X_train_patch.shape} labels: {y_train_patch.shape}")
                print(f"- Validation: {X_val_patch.shape} labels: {y_val_patch.shape}")
                print(f"- Test: {X_test_patch.shape} labels: {y_test_patch.shape}")

    if all_dataset_splits:
        print(f"\n{'='*50}")
        print("OVERALL PROCESSING SUMMARY")
        print(f"{'='*50}")
        print(f"Total datasets processed: {len(all_dataset_splits)}")
        for dataset in all_dataset_splits:
            splits = all_dataset_splits[dataset]
            print(f"\n{dataset.upper()}:")
            print("Pixel-wise samples:")
            print(f"- Train: {splits['pixel_data']['train'][0].shape}")
            print(f"- Validation: {splits['pixel_data']['val'][0].shape}")
            print(f"- Test: {splits['pixel_data']['test'][0].shape}")

        processed_datasets = {
            dataset: {
                'pixel_data': {
                    'train': all_dataset_splits[dataset]['pixel_data']['train'],
                    'val': all_dataset_splits[dataset]['pixel_data']['val'],
                    'test': all_dataset_splits[dataset]['pixel_data']['test']
                },
                'patch_data': {
                    'train': all_dataset_splits[dataset]['patch_data']['train'],
                    'val': all_dataset_splits[dataset]['patch_data']['val'],
                    'test': all_dataset_splits[dataset]['patch_data']['test']
                }
            }
            for dataset in all_dataset_splits
        }

"""## Quality Assessment of Bands"""

class BandQualityAnalyzer:
    def __init__(self, data: np.ndarray, name: str):
        """
        Initialize the band quality analyzer

        Args:
            data: Hyperspectral data of shape (height, width, bands)
            name: Name of the dataset
        """
        self.data = data
        self.name = name
        self.height, self.width, self.num_bands = data.shape

        self.bands_2d = self.data.reshape(-1, self.num_bands)
        self.quality_metrics = {}

    def compute_snr(self) -> np.ndarray:
        """Compute Signal-to-Noise Ratio for each band"""
        print("Computing Signal-to-Noise Ratio...")
        band_means = np.mean(self.bands_2d, axis=0)
        band_stds = np.std(self.bands_2d, axis=0)
        snr = np.where(band_stds != 0, band_means / band_stds, 0)
        self.quality_metrics['snr'] = snr
        return snr

    def compute_entropy(self) -> np.ndarray:
        """Compute entropy for each band"""
        print("Computing Band Entropy...")
        entropies = np.zeros(self.num_bands)
        for i in range(self.num_bands):
            band = self.bands_2d[:, i]
            band_norm = (band - band.min()) / (band.max() - band.min() + 1e-10)
            hist, _ = np.histogram(band_norm, bins=50, density=True)
            hist = hist / hist.sum()
            entropies[i] = entropy(hist[hist > 0])
        self.quality_metrics['entropy'] = entropies
        return entropies

    def compute_correlation(self) -> np.ndarray:
        """Compute correlation between adjacent bands"""
        print("Computing Band Correlations...")
        correlations = np.zeros(self.num_bands)
        for i in range(1, self.num_bands-1):
            corr_prev = np.corrcoef(self.bands_2d[:, i], self.bands_2d[:, i-1])[0, 1]
            corr_next = np.corrcoef(self.bands_2d[:, i], self.bands_2d[:, i+1])[0, 1]
            correlations[i] = (corr_prev + corr_next) / 2

        correlations[0] = np.corrcoef(self.bands_2d[:, 0], self.bands_2d[:, 1])[0, 1]
        correlations[-1] = np.corrcoef(self.bands_2d[:, -1], self.bands_2d[:, -2])[0, 1]

        self.quality_metrics['correlation'] = correlations
        return correlations

    def compute_all_metrics(self):
        """Compute all quality metrics"""
        self.compute_snr()
        self.compute_entropy()
        self.compute_correlation()

    def identify_noisy_bands(self, threshold_percentile: int = 10) -> List[int]:
        """Identify potentially noisy bands"""
        print("\nIdentifying noisy bands...")

        if not self.quality_metrics:
            self.compute_all_metrics()

        snr_norm = StandardScaler().fit_transform(self.quality_metrics['snr'].reshape(-1, 1)).ravel()
        entropy_norm = StandardScaler().fit_transform(self.quality_metrics['entropy'].reshape(-1, 1)).ravel()
        correlation_norm = StandardScaler().fit_transform(self.quality_metrics['correlation'].reshape(-1, 1)).ravel()

        quality_score = snr_norm + entropy_norm + correlation_norm

        threshold = np.percentile(quality_score, threshold_percentile)
        noisy_bands = np.where(quality_score < threshold)[0]

        return noisy_bands.tolist()

    def plot_quality_metrics(self):
        """Plot quality metrics"""
        if not self.quality_metrics:
            self.compute_all_metrics()

        fig, axes = plt.subplots(3, 1, figsize=(12, 15))
        fig.suptitle(f'Band Quality Metrics - {self.name}', fontsize=16)

        axes[0].plot(self.quality_metrics['snr'], 'b-')
        axes[0].set_title('Signal-to-Noise Ratio')
        axes[0].set_xlabel('Band Index')
        axes[0].set_ylabel('SNR')
        axes[0].grid(True)

        axes[1].plot(self.quality_metrics['entropy'], 'g-')
        axes[1].set_title('Band Entropy')
        axes[1].set_xlabel('Band Index')
        axes[1].set_ylabel('Entropy')
        axes[1].grid(True)

        axes[2].plot(self.quality_metrics['correlation'], 'r-')
        axes[2].set_title('Band Correlation')
        axes[2].set_xlabel('Band Index')
        axes[2].set_ylabel('Correlation')
        axes[2].grid(True)

        plt.tight_layout()
        plt.show()

def get_spatial_shape(dataset_name: str) -> Tuple[int, int]:
    """Get spatial dimensions for each dataset"""
    dataset_shapes = {
        'indian_pines': (145, 145),
        'pavia_university': (610, 340),
        'salinas': (512, 217)
    }
    return dataset_shapes[dataset_name]

def analyze_band_quality(samples: Dict, dataset_name: str) -> Dict:
    """Analyze band quality for a dataset"""
    print(f"\nAnalyzing band quality for {dataset_name.upper()}")

    try:
        loader = HyperspectralDataLoader(dataset_name)
        data, ground_truth = loader.load_dataset()

        analyzer = BandQualityAnalyzer(data, dataset_name)

        analyzer.compute_all_metrics()
        noisy_bands = analyzer.identify_noisy_bands()

        analyzer.plot_quality_metrics()

        print(f"\nQuality Analysis Results for {dataset_name}:")
        print(f"Number of bands: {data.shape[2]}")
        print(f"Number of noisy bands identified: {len(noisy_bands)}")
        print(f"Noisy band indices: {sorted(noisy_bands)}")

        known_noisy = {
            'indian_pines': [104, 105, 150, 151, 152, 153, 154, 155],
            'pavia_university': [],
            'salinas': [108, 109, 110, 111, 112, 113, 114, 115]
        }

        if known_noisy[dataset_name]:
            known_noisy_zero = [x-1 for x in known_noisy[dataset_name]]
            print(f"\nKnown noisy bands (literature): {known_noisy[dataset_name]}")
            print(f"Overlap with identified bands: {set(noisy_bands).intersection(known_noisy_zero)}")

        print("\nBand Quality Statistics:")
        print(f"Average SNR: {np.mean(analyzer.quality_metrics['snr']):.2f}")
        print(f"Average Entropy: {np.mean(analyzer.quality_metrics['entropy']):.2f}")
        print(f"Average Band Correlation: {np.mean(analyzer.quality_metrics['correlation']):.2f}")

        return {
            'metrics': analyzer.quality_metrics,
            'noisy_bands': noisy_bands,
            'raw_data': data
        }

    except Exception as e:
        print(f"Error analyzing {dataset_name}: {str(e)}")
        return None

if __name__ == "__main__":
    AVAILABLE_DATASETS = ['indian_pines', 'pavia_university', 'salinas']

    quality_results = {}

    for dataset in SELECTED_DATASET:
        if dataset not in AVAILABLE_DATASETS:
            print(f"Warning: {dataset} is not in available datasets. Skipping...")
            continue

        print(f"\n{'='*50}")
        print(f"Processing {dataset.upper()}")
        print(f"{'='*50}")

        results = analyze_band_quality(None, dataset)

        if results is not None:
            quality_results[dataset] = results

            raw_data = results['raw_data']
            noisy_bands = results['noisy_bands']

            plt.figure(figsize=(15, 5))

            plt.subplot(131)
            good_band = 100
            plt.imshow(raw_data[:, :, good_band], cmap='gray')
            plt.title(f'Good Band ({good_band})')
            plt.axis('off')

            if noisy_bands:
                plt.subplot(132)
                noisy_band = noisy_bands[0]
                plt.imshow(raw_data[:, :, noisy_band], cmap='gray')
                plt.title(f'Noisy Band ({noisy_band})')
                plt.axis('off')

            plt.subplot(133)
            quality_scores = (results['metrics']['snr'] +
                            results['metrics']['entropy'] +
                            results['metrics']['correlation'])
            plt.plot(quality_scores)
            plt.title('Band Quality Scores')
            plt.xlabel('Band Index')
            plt.ylabel('Quality Score')

            plt.tight_layout()
            plt.show()

    print("\nOverall Analysis Summary:")
    print("="*50)
    for dataset, results in quality_results.items():
        print(f"\n{dataset.upper()}:")
        print(f"Total bands: {results['raw_data'].shape[2]}")
        print(f"Noisy bands identified: {len(results['noisy_bands'])}")
        if results['noisy_bands']:
            print(f"Noisy band indices: {sorted(results['noisy_bands'])}")

"""## Removing Noisy Bands"""

class BandNoiseRemover:
    def __init__(self, data: np.ndarray, noisy_bands: List[int], dataset_name: str):
        """
        Initialize the band noise remover
        """
        self.data = data
        self.noisy_bands = sorted(noisy_bands)
        self.dataset_name = dataset_name
        self.height, self.width, self.num_bands = data.shape

    def remove_noisy_bands(self, silent=False) -> np.ndarray:
        """Remove noisy bands from the data"""
        good_bands = list(set(range(self.num_bands)) - set(self.noisy_bands))

        cleaned_data = self.data[:, :, good_bands]

        if not silent:
          print(f"\nNoisy Band Removal Summary:")
          print(f"Original bands: {self.num_bands}")
          print(f"Bands removed: {len(self.noisy_bands)}")
          print(f"Remaining bands: {cleaned_data.shape[2]}")

        return cleaned_data

    def plot_band_comparison(self):
        """Plot comparison of data before and after noise removal"""
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(f'Band Comparison - {self.dataset_name.upper()}', fontsize=16)

        good_band_idx = list(set(range(self.num_bands)) - set(self.noisy_bands))[0]
        axes[0, 0].imshow(self.data[:, :, good_band_idx], cmap='gray')
        axes[0, 0].set_title(f'Original Good Band ({good_band_idx})')
        axes[0, 0].axis('off')

        if self.noisy_bands:
            noisy_band_idx = self.noisy_bands[0]
            axes[0, 1].imshow(self.data[:, :, noisy_band_idx], cmap='gray')
            axes[0, 1].set_title(f'Noisy Band ({noisy_band_idx})')
            axes[0, 1].axis('off')

        axes[0, 2].imshow(np.mean(self.data, axis=2), cmap='gray')
        axes[0, 2].set_title('Mean of All Bands (Original)')
        axes[0, 2].axis('off')

        cleaned_data = self.remove_noisy_bands()

        good_band_new_idx = list(set(range(cleaned_data.shape[2])))[0]
        axes[1, 0].imshow(cleaned_data[:, :, good_band_new_idx], cmap='gray')
        axes[1, 0].set_title(f'Cleaned Good Band ({good_band_new_idx})')
        axes[1, 0].axis('off')

        axes[1, 2].imshow(np.mean(cleaned_data, axis=2), cmap='gray')
        axes[1, 2].set_title('Mean of Cleaned Bands')
        axes[1, 2].axis('off')

        axes[1, 1].plot(np.mean(self.data.reshape(-1, self.num_bands), axis=0),
                       'b-', label='Original', alpha=0.7)
        cleaned_spectrum = np.mean(cleaned_data.reshape(-1, cleaned_data.shape[2]), axis=0)
        cleaned_x = np.array(list(set(range(self.num_bands)) - set(self.noisy_bands)))
        axes[1, 1].plot(cleaned_x, cleaned_spectrum, 'r-', label='Cleaned', alpha=0.7)
        axes[1, 1].set_title('Mean Spectral Profile')
        axes[1, 1].legend()

        plt.tight_layout()
        plt.show()

        return cleaned_data

def remove_noisy_bands_from_samples(samples: Dict, quality_results: Dict) -> Dict:
    """
    Remove noisy bands from sample data

    Args:
        samples: Dictionary containing the samples
        quality_results: Dictionary containing quality analysis results

    Returns:
        Updated samples with noisy bands removed
    """
    cleaned_samples = samples.copy()

    noisy_bands = quality_results['noisy_bands']

    num_bands = samples['pixels']['X'].shape[1]
    good_bands = list(set(range(num_bands)) - set(noisy_bands))

    cleaned_samples['pixels']['X'] = samples['pixels']['X'][:, good_bands]

    cleaned_samples['patches']['X'] = samples['patches']['X'][:, :, :, good_bands]

    return cleaned_samples

if __name__ == "__main__":
    cleaned_datasets = {}

    for dataset in SELECTED_DATASET:
        print(f"\n{'='*50}")
        print(f"Processing {dataset.upper()}")
        print(f"{'='*50}")

        if samples is not None:
            quality_results = analyze_band_quality(None, dataset)

            if quality_results is not None:
                remover = BandNoiseRemover(
                    quality_results['raw_data'],
                    quality_results['noisy_bands'],
                    dataset
                )

                cleaned_data = remover.plot_band_comparison()

                cleaned_samples = remove_noisy_bands_from_samples(samples, quality_results)

                cleaned_datasets[dataset] = {
                    'cleaned_data': cleaned_data,
                    'samples': cleaned_samples,
                    'removed_bands': quality_results['noisy_bands']
                }

                print(f"\nSummary for {dataset.upper()}:")
                print(f"Original bands: {quality_results['raw_data'].shape[2]}")
                print(f"Noisy bands removed: {len(quality_results['noisy_bands'])}")
                print(f"Remaining bands: {cleaned_data.shape[2]}")

    print("\nOverall Processing Summary:")
    print("="*50)
    for dataset, results in cleaned_datasets.items():
        print(f"\n{dataset.upper()}:")
        print(f"Original number of bands: {results['cleaned_data'].shape[2] + len(results['removed_bands'])}")
        print(f"Removed bands: {sorted(results['removed_bands'])}")
        print(f"Final number of bands: {results['cleaned_data'].shape[2]}")

"""# **2.Data Exploration and Visualization**

## Visualize Spectral Signatures
"""

class SpectralSignatureVisualizer:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, class_names: List[str], dataset_name: str):
        """Initialize spectral signature visualizer"""
        self.data = data
        self.ground_truth = ground_truth
        self.class_names = class_names
        self.dataset_name = dataset_name
        self.num_classes = len(class_names)

    def plot_class_signatures(self, classes: Optional[List[int]] = None,
                            std_dev: bool = True, figsize: tuple = (12, 6)):
        """Plot spectral signatures for selected classes"""
        signatures = {}
        std_devs = {}

        if classes is None:
            classes = list(range(1, self.num_classes))

        for class_idx in classes:
            mask = self.ground_truth == class_idx
            class_pixels = self.data[mask]
            signatures[class_idx] = np.mean(class_pixels, axis=0)
            if std_dev:
                std_devs[class_idx] = np.std(class_pixels, axis=0)

        plt.figure(figsize=figsize)
        bands = np.arange(self.data.shape[2])

        for class_idx in classes:
            plt.plot(bands, signatures[class_idx],
                    label=f'{self.class_names[class_idx]}',
                    alpha=0.8)

            if std_dev:
                plt.fill_between(bands,
                               signatures[class_idx] - std_devs[class_idx],
                               signatures[class_idx] + std_devs[class_idx],
                               alpha=0.2)

        plt.title(f'Spectral Signatures - {self.dataset_name.upper()}')
        plt.xlabel('Band Index')
        plt.ylabel('Reflectance')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

    def plot_signature_comparison(self, class1: int, class2: int):
        """Plot detailed comparison between two classes"""
        mask1 = self.ground_truth == class1
        mask2 = self.ground_truth == class2

        pixels1 = self.data[mask1]
        pixels2 = self.data[mask2]

        mean1 = np.mean(pixels1, axis=0)
        mean2 = np.mean(pixels2, axis=0)
        std1 = np.std(pixels1, axis=0)
        std2 = np.std(pixels2, axis=0)

        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        bands = np.arange(self.data.shape[2])

        ax1.plot(bands, mean1, label=self.class_names[class1])
        ax1.fill_between(bands, mean1 - std1, mean1 + std1, alpha=0.2)
        ax1.plot(bands, mean2, label=self.class_names[class2])
        ax1.fill_between(bands, mean2 - std2, mean2 + std2, alpha=0.2)
        ax1.set_title('Spectral Signatures Comparison')
        ax1.set_xlabel('Band Index')
        ax1.set_ylabel('Reflectance')
        ax1.grid(True, alpha=0.3)
        ax1.legend()

        difference = mean1 - mean2
        ax2.plot(bands, difference, 'g-', label='Difference')
        ax2.fill_between(bands, -np.sqrt(std1**2 + std2**2),
                        np.sqrt(std1**2 + std2**2),
                        color='g', alpha=0.2)
        ax2.set_title('Spectral Difference')
        ax2.set_xlabel('Band Index')
        ax2.set_ylabel('Difference in Reflectance')
        ax2.grid(True, alpha=0.3)
        ax2.axhline(y=0, color='r', linestyle='--', alpha=0.5)

        plt.tight_layout()
        plt.show()

def preprocess_silently(dataset_name: str) -> Dict:
    """Silently preprocess the data"""
    loader = HyperspectralDataLoader(dataset_name)
    data, ground_truth = loader.load_dataset()

    #samples = process_hyperspectral_data(dataset_name)

    if samples is not None:
        quality_results = analyze_band_quality(None, dataset_name)

        if quality_results is not None:
            remover = BandNoiseRemover(
                quality_results['raw_data'],
                quality_results['noisy_bands'],
                dataset_name
            )
            cleaned_data = remover.remove_noisy_bands()

            return {
                'cleaned_data': cleaned_data,
                'ground_truth': ground_truth,
                'class_names': get_dataset_info(dataset_name)['class_names']
            }
    return None

def visualize_spectral_signatures(dataset_name: str):
    """Visualize spectral signatures for a dataset"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        visualizer = SpectralSignatureVisualizer(
            data=processed_data['cleaned_data'],
            ground_truth=processed_data['ground_truth'],
            class_names=processed_data['class_names'],
            dataset_name=dataset_name
        )

        print(f"\nVisualizing Spectral Signatures for {dataset_name.upper()}")
        print("="*50)
        print("\nPlotting class spectral signatures...")
        visualizer.plot_class_signatures()

        class_counts = np.bincount(processed_data['ground_truth'].flatten())[1:]
        top_classes = np.argsort(class_counts)[-2:] + 1
        print(f"\nComparing top two classes: {processed_data['class_names'][top_classes[0]]} vs {processed_data['class_names'][top_classes[1]]}")
        visualizer.plot_signature_comparison(top_classes[0], top_classes[1])

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        visualize_spectral_signatures(dataset)

"""## Correlation Analysis between Bands"""

class BandCorrelationAnalyzer:
    def __init__(self, data: np.ndarray, dataset_name: str):
        """
        Initialize band correlation analyzer

        Args:
            data: Hyperspectral data cube (height, width, bands)
            dataset_name: Name of the dataset
        """
        self.data = data
        self.dataset_name = dataset_name
        self.height, self.width, self.num_bands = data.shape
        self.bands_2d = data.reshape(-1, self.num_bands)
        self.correlation_matrix = None

    def compute_correlation_matrix(self) -> np.ndarray:
        """Compute correlation matrix between all bands"""
        corr_matrix = np.zeros((self.num_bands, self.num_bands))

        for i in range(self.num_bands):
            for j in range(i, self.num_bands):
                corr = pearsonr(self.bands_2d[:, i], self.bands_2d[:, j])[0]
                corr_matrix[i, j] = corr
                corr_matrix[j, i] = corr

        self.correlation_matrix = corr_matrix
        return corr_matrix

    def plot_correlation_heatmap(self, figsize: tuple = (12, 10)):
        """Plot correlation matrix heatmap"""
        if self.correlation_matrix is None:
            self.compute_correlation_matrix()

        plt.figure(figsize=figsize)
        sns.heatmap(self.correlation_matrix,
                   cmap='RdBu_r',
                   center=0,
                   vmin=-1,
                   vmax=1,
                   xticklabels=50,
                   yticklabels=50)

        plt.title(f'Band Correlation Matrix - {self.dataset_name.upper()}')
        plt.xlabel('Band Index')
        plt.ylabel('Band Index')
        plt.tight_layout()
        plt.show()

    def plot_correlation_distribution(self, figsize: tuple = (10, 6)):
        """Plot distribution of correlation values"""
        if self.correlation_matrix is None:
            self.compute_correlation_matrix()

        upper_triangle = self.correlation_matrix[np.triu_indices(self.num_bands, k=1)]

        plt.figure(figsize=figsize)
        sns.histplot(upper_triangle, bins=50, kde=True)
        plt.title(f'Distribution of Band Correlations - {self.dataset_name.upper()}')
        plt.xlabel('Correlation Coefficient')
        plt.ylabel('Count')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

        print("\nCorrelation Statistics:")
        print(f"Mean correlation: {np.mean(upper_triangle):.3f}")
        print(f"Median correlation: {np.median(upper_triangle):.3f}")
        print(f"Std deviation: {np.std(upper_triangle):.3f}")
        print(f"Min correlation: {np.min(upper_triangle):.3f}")
        print(f"Max correlation: {np.max(upper_triangle):.3f}")

    def find_highly_correlated_bands(self, threshold: float = 0.95) -> list:
        """Find pairs of highly correlated bands"""
        if self.correlation_matrix is None:
            self.compute_correlation_matrix()

        high_corr_pairs = []
        for i in range(self.num_bands):
            for j in range(i+1, self.num_bands):
                if abs(self.correlation_matrix[i, j]) >= threshold:
                    high_corr_pairs.append((i, j, self.correlation_matrix[i, j]))

        high_corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)
        return high_corr_pairs

    def plot_band_correlation_examples(self, num_examples: int = 3):
        """Plot examples of highly correlated and uncorrelated bands"""
        if self.correlation_matrix is None:
            self.compute_correlation_matrix()

        high_corr_pairs = self.find_highly_correlated_bands(threshold=0.95)[:num_examples]

        uncorr_pairs = []
        for i in range(self.num_bands):
            for j in range(i+1, self.num_bands):
                corr = abs(self.correlation_matrix[i, j])
                if corr < 0.1:  # Threshold for "uncorrelated"
                    uncorr_pairs.append((i, j, self.correlation_matrix[i, j]))
        uncorr_pairs = sorted(uncorr_pairs, key=lambda x: abs(x[2]))[:num_examples]

        fig, axes = plt.subplots(2, num_examples, figsize=(15, 10))
        fig.suptitle(f'Band Correlation Examples - {self.dataset_name.upper()}', fontsize=16)

        for idx, (i, j, corr) in enumerate(high_corr_pairs):
            axes[0, idx].scatter(self.bands_2d[:, i], self.bands_2d[:, j],
                               alpha=0.1, s=1)
            axes[0, idx].set_title(f'High Correlation\nBands {i}-{j}\nr={corr:.3f}')
            axes[0, idx].grid(True, alpha=0.3)

        for idx, (i, j, corr) in enumerate(uncorr_pairs):
            axes[1, idx].scatter(self.bands_2d[:, i], self.bands_2d[:, j],
                               alpha=0.1, s=1)
            axes[1, idx].set_title(f'Low Correlation\nBands {i}-{j}\nr={corr:.3f}')
            axes[1, idx].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

def analyze_band_correlations(dataset_name: str):
    """Analyze band correlations for a dataset"""
    # Get preprocessed data silently
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        print(f"\nAnalyzing Band Correlations for {dataset_name.upper()}")
        print("="*50)

        analyzer = BandCorrelationAnalyzer(
            data=processed_data['cleaned_data'],
            dataset_name=dataset_name
        )

        print("\nPlotting correlation heatmap...")
        analyzer.plot_correlation_heatmap()

        print("\nAnalyzing correlation distribution...")
        analyzer.plot_correlation_distribution()

        print("\nShowing correlation examples...")
        analyzer.plot_band_correlation_examples()

        high_corr_pairs = analyzer.find_highly_correlated_bands()
        if high_corr_pairs:
            print("\nHighly correlated band pairs (correlation > 0.95):")
            for i, j, corr in high_corr_pairs[:10]:
                print(f"Bands {i}-{j}: r = {corr:.3f}")

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        analyze_band_correlations(dataset)

"""## Class Distribution Analysis

"""

class ClassDistributionAnalyzer:
    def __init__(self, ground_truth: np.ndarray, class_names: List[str], dataset_name: str):
        """
        Initialize class distribution analyzer

        Args:
            ground_truth: Ground truth labels
            class_names: List of class names
            dataset_name: Name of the dataset
        """
        self.ground_truth = ground_truth
        self.class_names = class_names
        self.dataset_name = dataset_name
        self.num_classes = len(class_names)
        self.class_counts = None
        self.class_percentages = None
        self.compute_distribution()

    def compute_distribution(self):
        """Compute class distribution statistics"""
        self.class_counts = np.bincount(self.ground_truth.flatten())

        total_pixels = np.sum(self.class_counts)
        self.class_percentages = (self.class_counts / total_pixels) * 100

    def plot_distribution_bar(self, figsize: tuple = (12, 6)):
        """Plot class distribution as bar chart"""
        plt.figure(figsize=figsize)

        plt.bar(range(1, self.num_classes),
                self.class_counts[1:],
                alpha=0.8)

        plt.title(f'Class Distribution - {self.dataset_name.upper()}')
        plt.xlabel('Class')
        plt.ylabel('Number of Pixels')

        plt.xticks(range(1, self.num_classes),
                  [self.class_names[i] for i in range(1, self.num_classes)],
                  rotation=45,
                  ha='right')

        for i, count in enumerate(self.class_counts[1:], 1):
            percentage = self.class_percentages[i]
            plt.text(i, count, f'{percentage:.1f}%',
                    ha='center', va='bottom')

        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

    def plot_distribution_pie(self, figsize: tuple = (10, 10)):
        """Plot class distribution as pie chart"""
        plt.figure(figsize=figsize)

        sizes = self.class_percentages[1:]
        labels = self.class_names[1:]

        colors = plt.cm.Set3(np.linspace(0, 1, len(sizes)))

        plt.pie(sizes, labels=labels, colors=colors,
                autopct='%1.1f%%', pctdistance=0.85,
                labeldistance=1.1)

        plt.title(f'Class Distribution (%) - {self.dataset_name.upper()}')
        plt.axis('equal')
        plt.show()

    def plot_spatial_distribution(self, figsize: tuple = (10, 10)):
        """Plot spatial distribution of classes"""
        plt.figure(figsize=figsize)

        colors = plt.cm.Set3(np.linspace(0, 1, self.num_classes))
        cmap = plt.cm.colors.ListedColormap(colors)

        plt.imshow(self.ground_truth, cmap=cmap)

        legend_elements = [Patch(facecolor=colors[i],
                               label=self.class_names[i])
                         for i in range(self.num_classes)]

        plt.legend(handles=legend_elements,
                  bbox_to_anchor=(1.05, 1),
                  loc='upper left')

        plt.title(f'Spatial Class Distribution - {self.dataset_name.upper()}')
        plt.axis('off')
        plt.tight_layout()
        plt.show()

    def plot_class_balance_analysis(self, figsize: tuple = (12, 6)):
        """Plot class balance analysis"""
        mean_samples = np.mean(self.class_counts[1:])
        imbalance_ratios = self.class_counts[1:] / mean_samples

        plt.figure(figsize=figsize)
        plt.plot(range(1, self.num_classes), imbalance_ratios,
                'bo-', alpha=0.7)
        plt.axhline(y=1, color='r', linestyle='--', alpha=0.5)

        plt.title(f'Class Imbalance Analysis - {self.dataset_name.upper()}')
        plt.xlabel('Class')
        plt.ylabel('Imbalance Ratio (samples/mean)')

        plt.xticks(range(1, self.num_classes),
                  [self.class_names[i] for i in range(1, self.num_classes)],
                  rotation=45,
                  ha='right')

        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()

        print("\nClass Balance Statistics:")
        print(f"Mean samples per class: {mean_samples:.0f}")
        print(f"Most frequent class: {self.class_names[np.argmax(self.class_counts[1:])+1]}")
        print(f"Least frequent class: {self.class_names[np.argmin(self.class_counts[1:])+1]}")
        print(f"Imbalance ratio (max/min): {np.max(self.class_counts[1:])/np.min(self.class_counts[1:]):.2f}")

def analyze_class_distribution(dataset_name: str):
    """Analyze class distribution for a dataset"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        print(f"\nAnalyzing Class Distribution for {dataset_name.upper()}")
        print("="*50)

        analyzer = ClassDistributionAnalyzer(
            ground_truth=processed_data['ground_truth'],
            class_names=processed_data['class_names'],
            dataset_name=dataset_name
        )

        print("\nPlotting class distribution bar chart...")
        analyzer.plot_distribution_bar()

        print("\nPlotting class distribution pie chart...")
        analyzer.plot_distribution_pie()

        print("\nPlotting spatial class distribution...")
        analyzer.plot_spatial_distribution()

        print("\nAnalyzing class balance...")
        analyzer.plot_class_balance_analysis()

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        analyze_class_distribution(dataset)

"""## Generate 3D Datacube Visualizations"""

class DatacubeVisualizer:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, dataset_name: str):
        """
        Initialize datacube visualizer

        Args:
            data: Hyperspectral data cube (height, width, bands)
            ground_truth: Ground truth labels
            dataset_name: Name of the dataset
        """
        self.data = data
        self.ground_truth = ground_truth
        self.dataset_name = dataset_name
        self.height, self.width, self.num_bands = data.shape

    def plot_datacube_matplotlib(self, slice_indices: Optional[List[int]] = None,
                               figsize: Tuple[int, int] = (12, 10)):
        """
        Plot 3D datacube using Matplotlib

        Args:
            slice_indices: List of band indices to highlight
            figsize: Figure size
        """
        if slice_indices is None:
            slice_indices = [self.num_bands//4, self.num_bands//2, 3*self.num_bands//4]

        fig = plt.figure(figsize=figsize)
        ax = fig.add_subplot(111, projection='3d')

        x, y = np.meshgrid(np.arange(self.width), np.arange(self.height))

        for band_idx in slice_indices:
            z = np.full_like(x, band_idx)
            ax.plot_surface(x, y, z, facecolors=plt.cm.viridis(self.data[:, :, band_idx]/np.max(self.data)),
                          alpha=0.5)

        ax.plot([0, self.width], [0, 0], [0, 0], 'k-', alpha=0.5)
        ax.plot([0, self.width], [self.height, self.height], [0, 0], 'k-', alpha=0.5)
        ax.plot([0, 0], [0, self.height], [0, 0], 'k-', alpha=0.5)
        ax.plot([self.width, self.width], [0, self.height], [0, 0], 'k-', alpha=0.5)

        ax.plot([0, 0], [0, 0], [0, self.num_bands], 'k-', alpha=0.5)
        ax.plot([self.width, self.width], [0, 0], [0, self.num_bands], 'k-', alpha=0.5)
        ax.plot([0, 0], [self.height, self.height], [0, self.num_bands], 'k-', alpha=0.5)
        ax.plot([self.width, self.width], [self.height, self.height], [0, self.num_bands], 'k-', alpha=0.5)

        ax.set_title(f'3D Datacube Visualization - {self.dataset_name.upper()}')
        ax.set_xlabel('Width')
        ax.set_ylabel('Height')
        ax.set_zlabel('Spectral Bands')

        plt.tight_layout()
        plt.show()

    def plot_datacube_plotly(self, band_interval: int = 20):
        """
        Plot interactive 3D datacube using Plotly

        Args:
            band_interval: Interval between displayed bands
        """
        selected_bands = range(0, self.num_bands, band_interval)

        fig = go.Figure()

        for band_idx in selected_bands:
            band_data = self.data[:, :, band_idx]
            norm_data = (band_data - np.min(band_data)) / (np.max(band_data) - np.min(band_data))

            surface = go.Surface(
                z=np.full((self.height, self.width), band_idx),
                x=np.arange(self.width),
                y=np.arange(self.height),
                surfacecolor=norm_data,
                opacity=0.6,
                colorscale='Viridis',
                showscale=False,
                name=f'Band {band_idx}'
            )
            fig.add_trace(surface)

        fig.update_layout(
            title=f'Interactive 3D Datacube - {self.dataset_name.upper()}',
            scene=dict(
                xaxis_title='Width',
                yaxis_title='Height',
                zaxis_title='Spectral Bands'
            ),
            width=800,
            height=800
        )

        fig.show()

    def plot_spectral_slices(self, num_slices: int = 3, figsize: Tuple[int, int] = (15, 5)):
        """
        Plot spectral slices of the datacube

        Args:
            num_slices: Number of spectral slices to show
            figsize: Figure size
        """
        slice_indices = [i * (self.num_bands // num_slices) for i in range(num_slices)]

        fig, axes = plt.subplots(1, num_slices, figsize=figsize)
        fig.suptitle(f'Spectral Slices - {self.dataset_name.upper()}')

        for i, band_idx in enumerate(slice_indices):
            im = axes[i].imshow(self.data[:, :, band_idx], cmap='viridis')
            axes[i].set_title(f'Band {band_idx}')
            axes[i].axis('off')
            plt.colorbar(im, ax=axes[i])

        plt.tight_layout()
        plt.show()

    def plot_spatial_slices(self, num_slices: int = 3, figsize: Tuple[int, int] = (15, 5)):
        """
        Plot spatial slices of the datacube

        Args:
            num_slices: Number of spatial slices to show
            figsize: Figure size
        """
        slice_indices = [i * (self.height // num_slices) for i in range(num_slices)]

        fig, axes = plt.subplots(1, num_slices, figsize=figsize)
        fig.suptitle(f'Spatial Slices - {self.dataset_name.upper()}')

        for i, row_idx in enumerate(slice_indices):
            im = axes[i].imshow(self.data[row_idx, :, :].T, cmap='viridis',
                              aspect='auto')
            axes[i].set_title(f'Row {row_idx}')
            axes[i].set_xlabel('Width')
            axes[i].set_ylabel('Bands')
            plt.colorbar(im, ax=axes[i])

        plt.tight_layout()
        plt.show()

def visualize_datacube(dataset_name: str):
    """Visualize datacube for a dataset"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        print(f"\nGenerating 3D Datacube Visualizations for {dataset_name.upper()}")
        print("="*50)

        visualizer = DatacubeVisualizer(
            data=processed_data['cleaned_data'],
            ground_truth=processed_data['ground_truth'],
            dataset_name=dataset_name
        )

        print("\nCreating static 3D datacube visualization...")
        visualizer.plot_datacube_matplotlib()

        print("\nCreating interactive 3D datacube visualization...")
        visualizer.plot_datacube_plotly()

        print("\nPlotting spectral slices...")
        visualizer.plot_spectral_slices()

        print("\nPlotting spatial slices...")
        visualizer.plot_spatial_slices()

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        visualize_datacube(dataset)

"""# **3.Dimensionality Reduction and Feature Selection**

## Analysis
* Principal Component Analysis (PCA)
*	Independent Component Analysis (ICA)
*	Linear Discriminant Analysis (LDA)
"""

class DimensionalityReducer:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, dataset_name: str):
        """
        Initialize dimensionality reduction analyzer

        Args:
            data: Hyperspectral data
            ground_truth: Ground truth labels
            dataset_name: Name of the dataset
        """
        self.dataset_name = dataset_name

        self.height, self.width, self.num_bands = data.shape
        self.data_2d = data.reshape(-1, self.num_bands)

        mask = ground_truth.flatten() != 0
        self.data_2d = self.data_2d[mask]
        self.labels = ground_truth.flatten()[mask] - 1

        self.scaler = StandardScaler()
        self.data_2d_scaled = self.scaler.fit_transform(self.data_2d)

        self.pca = None
        self.ica = None
        self.lda = None

    def apply_pca(self, n_components: int = None) -> Tuple[np.ndarray, float]:
        """Apply PCA"""
        if n_components is None:
            n_components = min(self.num_bands, 20)

        self.pca = PCA(n_components=n_components)
        transformed = self.pca.fit_transform(self.data_2d_scaled)

        explained_var_ratio = self.pca.explained_variance_ratio_
        cumulative_var_ratio = np.cumsum(explained_var_ratio)

        return transformed, cumulative_var_ratio

    def apply_ica(self, n_components: int) -> np.ndarray:
        """Apply ICA"""
        self.ica = FastICA(n_components=n_components, random_state=42)
        return self.ica.fit_transform(self.data_2d_scaled)

    def apply_lda(self, n_components: int = None) -> np.ndarray:
        """Apply LDA"""
        if n_components is None:
            n_components = min(len(np.unique(self.labels)) - 1, self.num_bands)

        self.lda = LDA(n_components=n_components)
        return self.lda.fit_transform(self.data_2d_scaled, self.labels)

    def plot_pca_analysis(self, n_components: int = None):
        """Plot PCA results"""
        transformed, var_ratio = self.apply_pca(n_components)

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'PCA Analysis - {self.dataset_name.upper()}', fontsize=16)

        axes[0, 0].plot(range(1, len(var_ratio) + 1), var_ratio * 100, 'bo-')
        axes[0, 0].set_xlabel('Number of Components')
        axes[0, 0].set_ylabel('Explained Variance Ratio (%)')
        axes[0, 0].set_title('Cumulative Explained Variance')
        axes[0, 0].grid(True)

        axes[0, 1].plot(range(1, len(self.pca.explained_variance_ratio_) + 1),
                       self.pca.explained_variance_ratio_ * 100, 'ro-')
        axes[0, 1].set_xlabel('Principal Component')
        axes[0, 1].set_ylabel('Individual Explained Variance (%)')
        axes[0, 1].set_title('Scree Plot')
        axes[0, 1].grid(True)

        scatter = axes[1, 0].scatter(transformed[:, 0], transformed[:, 1],
                                   c=self.labels, cmap='tab20', alpha=0.6)
        axes[1, 0].set_xlabel('First Principal Component')
        axes[1, 0].set_ylabel('Second Principal Component')
        axes[1, 0].set_title('First Two Principal Components')
        plt.colorbar(scatter, ax=axes[1, 0])

        im = axes[1, 1].imshow(self.pca.components_[:5].T, aspect='auto', cmap='RdBu_r')
        axes[1, 1].set_xlabel('Principal Component')
        axes[1, 1].set_ylabel('Original Band')
        axes[1, 1].set_title('Top 5 Component Loadings')
        plt.colorbar(im, ax=axes[1, 1])

        plt.tight_layout()
        plt.show()

        print("\nPCA Summary:")
        print(f"Number of components: {n_components}")
        print(f"Total explained variance: {var_ratio[-1]*100:.2f}%")
        print(f"Components for 95% variance: {np.sum(var_ratio < 0.95) + 1}")

    def plot_ica_analysis(self, n_components: int = 10):
        """Plot ICA results"""
        transformed = self.apply_ica(n_components)

        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        fig.suptitle(f'ICA Analysis - {self.dataset_name.upper()}', fontsize=16)

        scatter = axes[0].scatter(transformed[:, 0], transformed[:, 1],
                                c=self.labels, cmap='tab20', alpha=0.6)
        axes[0].set_xlabel('First Independent Component')
        axes[0].set_ylabel('Second Independent Component')
        axes[0].set_title('First Two Independent Components')
        plt.colorbar(scatter, ax=axes[0])

        im = axes[1].imshow(self.ica.mixing_.T, aspect='auto', cmap='RdBu_r')
        axes[1].set_xlabel('Independent Component')
        axes[1].set_ylabel('Original Band')
        axes[1].set_title('Mixing Matrix')
        plt.colorbar(im, ax=axes[1])

        plt.tight_layout()
        plt.show()

    def plot_lda_analysis(self, n_components: int = None):
        """Plot LDA results"""
        transformed = self.apply_lda(n_components)

        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        fig.suptitle(f'LDA Analysis - {self.dataset_name.upper()}', fontsize=16)

        scatter = axes[0].scatter(transformed[:, 0], transformed[:, 1],
                                c=self.labels, cmap='tab20', alpha=0.6)
        axes[0].set_xlabel('First Discriminant')
        axes[0].set_ylabel('Second Discriminant')
        axes[0].set_title('First Two Linear Discriminants')
        plt.colorbar(scatter, ax=axes[0])

        im = axes[1].imshow(self.lda.scalings_[:, :5].T, aspect='auto', cmap='RdBu_r')
        axes[1].set_xlabel('Discriminant')
        axes[1].set_ylabel('Original Band')
        axes[1].set_title('Top 5 Scaling Coefficients')
        plt.colorbar(im, ax=axes[1])

        plt.tight_layout()
        plt.show()

        print("\nLDA Summary:")
        print(f"Number of discriminants: {n_components}")
        explained_ratio = self.lda.explained_variance_ratio_
        print(f"Explained variance ratios: {[f'{r*100:.2f}%' for r in explained_ratio]}")

def analyze_dimensionality_reduction(dataset_name: str):
    """Analyze dimensionality reduction for a dataset"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        print(f"\nDimensionality Reduction Analysis for {dataset_name.upper()}")
        print("="*50)

        reducer = DimensionalityReducer(
            data=processed_data['cleaned_data'],
            ground_truth=processed_data['ground_truth'],
            dataset_name=dataset_name
        )

        print("\nPerforming PCA...")
        reducer.plot_pca_analysis()

        print("\nPerforming ICA...")
        reducer.plot_ica_analysis()

        print("\nPerforming LDA...")
        reducer.plot_lda_analysis()

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        analyze_dimensionality_reduction(dataset)

"""## Band Selection Methods
*		Mutual Information
*		ReliefF

"""

class BandSelector:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, dataset_name: str):
        """Initialize band selector"""
        self.dataset_name = dataset_name
        self.height, self.width, self.num_bands = data.shape

        self.data_2d = data.reshape(-1, self.num_bands)

        mask = ground_truth.flatten() != 0
        self.data_2d = self.data_2d[mask]
        self.labels = ground_truth.flatten()[mask] - 1

    def mutual_information(self, n_bands: int = 20) -> Tuple[List[int], np.ndarray]:
        """Compute mutual information scores"""
        print("\nComputing Mutual Information...")
        mi_scores = mutual_info_classif(self.data_2d, self.labels)
        selected_indices = np.argsort(mi_scores)[-n_bands:][::-1]
        return selected_indices, mi_scores

    def reliefF(self, n_bands: int = 20, n_neighbors: int = 5) -> Tuple[List[int], np.ndarray]:
        """Compute ReliefF scores"""
        print("\nComputing ReliefF scores...")

        num_samples = len(self.labels)
        weights = np.zeros(self.num_bands)

        for i in tqdm(range(num_samples)):
            current_sample = self.data_2d[i]
            current_class = self.labels[i]

            distances = distance.cdist(current_sample.reshape(1, -1),
                                    self.data_2d).flatten()

            same_class = self.labels == current_class
            diff_class = ~same_class

            hit_indices = np.argsort(distances[same_class])[:n_neighbors]
            miss_indices = np.argsort(distances[diff_class])[:n_neighbors]

            hits = self.data_2d[same_class][hit_indices]
            misses = self.data_2d[diff_class][miss_indices]

            weights += -np.mean(np.abs(current_sample - hits), axis=0) + \
                      np.mean(np.abs(current_sample - misses), axis=0)

        weights = weights / num_samples
        selected_indices = np.argsort(weights)[-n_bands:][::-1]

        return selected_indices, weights

    def plot_results(self, mi_scores: np.ndarray, relief_scores: np.ndarray,
                    mi_selected: List[int], relief_selected: List[int]):
        """Plot band selection results"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'Band Selection Analysis - {self.dataset_name.upper()}', fontsize=16)

        axes[0, 0].plot(range(self.num_bands), mi_scores, 'b-', alpha=0.6)
        axes[0, 0].scatter(mi_selected, mi_scores[mi_selected], c='r', label='Selected')
        axes[0, 0].set_title('Mutual Information Scores')
        axes[0, 0].set_xlabel('Band Index')
        axes[0, 0].set_ylabel('MI Score')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)

        axes[0, 1].plot(range(self.num_bands), relief_scores, 'g-', alpha=0.6)
        axes[0, 1].scatter(relief_selected, relief_scores[relief_selected],
                          c='r', label='Selected')
        axes[0, 1].set_title('ReliefF Scores')
        axes[0, 1].set_xlabel('Band Index')
        axes[0, 1].set_ylabel('ReliefF Weight')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)

        band_indices = np.arange(self.num_bands)
        mi_mask = np.isin(band_indices, mi_selected)
        relief_mask = np.isin(band_indices, relief_selected)

        axes[1, 0].plot(band_indices[mi_mask], np.ones(len(mi_selected)),
                       'bo', label='MI Selected')
        axes[1, 0].plot(band_indices[relief_mask], np.zeros(len(relief_selected)),
                       'go', label='ReliefF Selected')
        axes[1, 0].set_title('Selected Bands Comparison')
        axes[1, 0].set_xlabel('Band Index')
        axes[1, 0].set_yticks([0, 1])
        axes[1, 0].set_yticklabels(['ReliefF', 'MI'])
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        overlap = set(mi_selected) & set(relief_selected)
        mi_only = set(mi_selected) - overlap
        relief_only = set(relief_selected) - overlap

        overlap_data = [len(mi_only), len(relief_only), len(overlap)]
        axes[1, 1].bar(['MI Only', 'ReliefF Only', 'Overlap'], overlap_data)
        axes[1, 1].set_title('Selected Bands Overlap')
        axes[1, 1].set_ylabel('Number of Bands')

        plt.tight_layout()
        plt.show()

        print("\nBand Selection Summary:")
        print(f"Number of bands selected: {len(mi_selected)}")
        print(f"Mutual Information selected bands: {sorted(mi_selected)}")
        print(f"ReliefF selected bands: {sorted(relief_selected)}")
        print(f"Number of overlapping bands: {len(overlap)}")
        if overlap:
            print(f"Overlapping bands: {sorted(overlap)}")

def analyze_band_selection(dataset_name: str, n_bands: int = 20):
    """Analyze band selection for a dataset"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        print(f"\nBand Selection Analysis for {dataset_name.upper()}")
        print("="*50)

        selector = BandSelector(
            data=processed_data['cleaned_data'],
            ground_truth=processed_data['ground_truth'],
            dataset_name=dataset_name
        )

        mi_selected, mi_scores = selector.mutual_information(n_bands)

        relief_selected, relief_scores = selector.reliefF(n_bands)

        selector.plot_results(mi_scores, relief_scores, mi_selected, relief_selected)

        return {
            'mi_selected': mi_selected,
            'relief_selected': relief_selected,
            'mi_scores': mi_scores,
            'relief_scores': relief_scores
        }

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        results = analyze_band_selection(dataset)

"""## Compare and Evaluate Reduced Representations"""

class ReductionComparator:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, dataset_name: str):
        """
        Initialize reduction comparator

        Args:
            data: Original data
            ground_truth: Ground truth labels (1D array)
            dataset_name: Name of the dataset
        """
        self.dataset_name = dataset_name
        self.data = data
        self.ground_truth = ground_truth.ravel() if len(ground_truth.shape) > 1 else ground_truth
        self.reduction_results = {}

    def add_reduction(self, name: str, reduced_data: np.ndarray, computation_time: float):
        """Add a reduction result"""
        self.reduction_results[name] = {
            'data': reduced_data,
            'time': computation_time
        }

    def compute_metrics(self, n_neighbors: int = 5):
        """Compute evaluation metrics for each reduction"""
        metrics = {}

        for name, result in self.reduction_results.items():
            reduced_data = result['data']

            try:
                silhouette = silhouette_score(reduced_data, self.ground_truth)
                calinski = calinski_harabasz_score(reduced_data, self.ground_truth)
            except ValueError as e:
                print(f"Warning: Error computing clustering metrics for {name}: {e}")
                silhouette = 0
                calinski = 0

            try:
                knn = KNeighborsClassifier(n_neighbors=n_neighbors)
                cv_scores = cross_val_score(knn, reduced_data, self.ground_truth, cv=5)
                cv_mean = np.mean(cv_scores)
                cv_std = np.std(cv_scores)
            except ValueError as e:
                print(f"Warning: Error computing CV scores for {name}: {e}")
                cv_mean = 0
                cv_std = 0

            metrics[name] = {
                'silhouette': silhouette,
                'calinski_harabasz': calinski,
                'cv_accuracy_mean': cv_mean,
                'cv_accuracy_std': cv_std,
                'computation_time': result['time']
            }

        return metrics

    def plot_comparison(self, metrics: Dict):
        """Plot comparison of different reduction methods"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'Reduction Methods Comparison - {self.dataset_name.upper()}', fontsize=16)

        methods = list(metrics.keys())
        x = np.arange(len(methods))

        axes[0, 0].bar(x, [metrics[m]['silhouette'] for m in methods])
        axes[0, 0].set_title('Silhouette Score')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(methods, rotation=45, ha='right')
        axes[0, 0].grid(True, alpha=0.3)

        axes[0, 1].bar(x, [metrics[m]['calinski_harabasz'] for m in methods])
        axes[0, 1].set_title('Calinski-Harabasz Score')
        axes[0, 1].set_xticks(x)
        axes[0, 1].set_xticklabels(methods, rotation=45, ha='right')
        axes[0, 1].grid(True, alpha=0.3)

        acc_means = [metrics[m]['cv_accuracy_mean'] for m in methods]
        acc_stds = [metrics[m]['cv_accuracy_std'] for m in methods]
        axes[1, 0].bar(x, acc_means, yerr=acc_stds, capsize=5)
        axes[1, 0].set_title('5-Fold Cross-Validation Accuracy')
        axes[1, 0].set_xticks(x)
        axes[1, 0].set_xticklabels(methods, rotation=45, ha='right')
        axes[1, 0].grid(True, alpha=0.3)

        axes[1, 1].bar(x, [metrics[m]['computation_time'] for m in methods])
        axes[1, 1].set_title('Computation Time (seconds)')
        axes[1, 1].set_xticks(x)
        axes[1, 1].set_xticklabels(methods, rotation=45, ha='right')
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

        print("\nDetailed Metrics:")
        print("-" * 50)
        for method in methods:
            print(f"\n{method}:")
            print(f"Silhouette Score: {metrics[method]['silhouette']:.4f}")
            print(f"Calinski-Harabasz Score: {metrics[method]['calinski_harabasz']:.4f}")
            print(f"CV Accuracy: {metrics[method]['cv_accuracy_mean']:.4f} ± {metrics[method]['cv_accuracy_std']:.4f}")
            print(f"Computation Time: {metrics[method]['computation_time']:.4f} seconds")

def compare_reductions(dataset_name: str, n_components: int = 20):
    """Compare different reduction methods"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        print(f"\nComparing Reduction Methods for {dataset_name.upper()}")
        print("="*50)

        data_2d = processed_data['cleaned_data'].reshape(-1, processed_data['cleaned_data'].shape[-1])
        labels_1d = processed_data['ground_truth'].ravel()

        mask = labels_1d != 0
        X = data_2d[mask]
        y = labels_1d[mask] - 1

        comparator = ReductionComparator(
            data=X,
            ground_truth=y,
            dataset_name=dataset_name
        )

        try:
            start_time = time.time()
            pca = PCA(n_components=n_components)
            pca_result = pca.fit_transform(X)
            pca_time = time.time() - start_time
            comparator.add_reduction('PCA', pca_result, pca_time)
            print("PCA completed")

            start_time = time.time()
            ica = FastICA(n_components=n_components, random_state=42)
            ica_result = ica.fit_transform(X)
            ica_time = time.time() - start_time
            comparator.add_reduction('ICA', ica_result, ica_time)
            print("ICA completed")

            start_time = time.time()
            n_classes = len(np.unique(y))
            lda_components = min(n_components, n_classes-1)
            lda = LDA(n_components=lda_components)
            lda_result = lda.fit_transform(X, y)
            lda_time = time.time() - start_time
            comparator.add_reduction('LDA', lda_result, lda_time)
            print("LDA completed")

            start_time = time.time()
            mi_scores = mutual_info_classif(X, y)
            mi_indices = np.argsort(mi_scores)[-n_components:]
            mi_result = X[:, mi_indices]
            mi_time = time.time() - start_time
            comparator.add_reduction('MI', mi_result, mi_time)
            print("MI completed")

            start_time = time.time()
            n_samples = len(y)
            weights = np.zeros(X.shape[1])
            n_neighbors = 5

            for i in tqdm(range(n_samples), desc="Computing ReliefF"):
                current_sample = X[i]
                current_class = y[i]

                distances = distance.cdist(current_sample.reshape(1, -1), X).flatten()

                same_class = y == current_class
                diff_class = ~same_class

                hit_indices = np.argsort(distances[same_class])[:n_neighbors]
                miss_indices = np.argsort(distances[diff_class])[:n_neighbors]

                hits = X[same_class][hit_indices]
                misses = X[diff_class][miss_indices]

                weights += -np.mean(np.abs(current_sample - hits), axis=0) + \
                          np.mean(np.abs(current_sample - misses), axis=0)

            relief_indices = np.argsort(weights)[-n_components:]
            relief_result = X[:, relief_indices]
            relief_time = time.time() - start_time
            comparator.add_reduction('ReliefF', relief_result, relief_time)
            print("ReliefF completed")

            print("\nComputing comparison metrics...")
            metrics = comparator.compute_metrics()
            comparator.plot_comparison(metrics)

            return metrics

        except Exception as e:
            print(f"Error during reduction comparison: {str(e)}")
            raise

    return None

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        metrics = compare_reductions(dataset)

"""# **4.Data Augmentation Strategies**

## Spectral Augmentation
*		Band dropping
*		Spectral noise injection
"""

class SpectralAugmenter:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, dataset_name: str):
        """
        Initialize spectral augmenter

        Args:
            data: Hyperspectral data cube (height, width, bands)
            ground_truth: Ground truth labels
            dataset_name: Name of the dataset
        """
        self.data = data
        self.ground_truth = ground_truth
        self.dataset_name = dataset_name
        self.height, self.width, self.num_bands = data.shape

        if len(data.shape) == 4:  # If (N, H, W, C)
            self.height, self.width, self.num_bands = data.shape[1:]
        else:  # If (H, W, C)
            self.height, self.width, self.num_bands = data.shape

        self.original_data = data.copy()

    def band_dropping(self, drop_ratio: float = 0.1, random_state: Optional[int] = None) -> np.ndarray:
        """
        Randomly drop bands from the data

        Args:
            drop_ratio: Ratio of bands to drop (0 to 1)
            random_state: Random seed for reproducibility

        Returns:
            Augmented data with dropped bands
        """
        if random_state is not None:
            np.random.seed(random_state)

        n_drop = int(self.num_bands * drop_ratio)

        drop_indices = np.random.choice(self.num_bands, n_drop, replace=False)

        augmented_data = self.data.copy()

        augmented_data[:, :, drop_indices] = 0

        return augmented_data, drop_indices

    def spectral_noise_injection(self, noise_level: float = 0.05,
                               distribution: str = 'gaussian',
                               random_state: Optional[int] = None) -> np.ndarray:
        """
        Add noise to spectral bands

        Args:
            noise_level: Standard deviation or range of noise
            distribution: Type of noise ('gaussian' or 'uniform')
            random_state: Random seed for reproducibility

        Returns:
            Augmented data with added noise
        """
        if random_state is not None:
            np.random.seed(random_state)

        if distribution == 'gaussian':
            noise = np.random.normal(0, noise_level, self.data.shape)
        elif distribution == 'uniform':
            noise = np.random.uniform(-noise_level, noise_level, self.data.shape)
        else:
            raise ValueError(f"Unknown distribution: {distribution}")

        augmented_data = self.data + noise

        augmented_data = np.clip(augmented_data, 0, 1)

        return augmented_data

    def plot_augmentation_results(self, original_band: int = None,
                                drop_ratio: float = 0.1,
                                noise_level: float = 0.05):
        """Plot comparison of original and augmented data"""
        if original_band is None:
            original_band = self.num_bands // 2

        dropped_data, drop_indices = self.band_dropping(drop_ratio)
        noisy_data = self.spectral_noise_injection(noise_level)

        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(f'Spectral Augmentation Results - {self.dataset_name.upper()}', fontsize=16)

        axes[0, 0].imshow(self.data[:, :, original_band], cmap='viridis')
        axes[0, 0].set_title(f'Original Band {original_band}')
        axes[0, 0].axis('off')

        axes[0, 1].imshow(dropped_data[:, :, original_band], cmap='viridis')
        axes[0, 1].set_title(f'Band Dropping (ratio={drop_ratio})')
        axes[0, 1].axis('off')

        axes[0, 2].imshow(noisy_data[:, :, original_band], cmap='viridis')
        axes[0, 2].set_title(f'Noise Injection (level={noise_level})')
        axes[0, 2].axis('off')

        pixel_x, pixel_y = self.width//2, self.height//2

        axes[1, 0].plot(range(self.num_bands),
                       self.data[pixel_y, pixel_x, :],
                       'b-', label='Original')
        axes[1, 0].set_title('Original Spectral Profile')
        axes[1, 0].set_xlabel('Band Index')
        axes[1, 0].set_ylabel('Intensity')
        axes[1, 0].grid(True, alpha=0.3)

        axes[1, 1].plot(range(self.num_bands),
                       dropped_data[pixel_y, pixel_x, :],
                       'r-', label='Dropped')
        axes[1, 1].plot(drop_indices,
                       dropped_data[pixel_y, pixel_x, drop_indices],
                       'rx', label='Dropped Bands')
        axes[1, 1].set_title('Profile with Dropped Bands')
        axes[1, 1].set_xlabel('Band Index')
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].legend()

        axes[1, 2].plot(range(self.num_bands),
                       self.data[pixel_y, pixel_x, :],
                       'b-', label='Original', alpha=0.5)
        axes[1, 2].plot(range(self.num_bands),
                       noisy_data[pixel_y, pixel_x, :],
                       'g-', label='Noisy')
        axes[1, 2].set_title('Profile with Added Noise')
        axes[1, 2].set_xlabel('Band Index')
        axes[1, 2].grid(True, alpha=0.3)
        axes[1, 2].legend()

        plt.tight_layout()
        plt.show()

        print("\nAugmentation Summary:")
        print("-" * 50)
        print(f"Band Dropping:")
        print(f"- Number of bands dropped: {len(drop_indices)}")
        print(f"- Dropped band indices: {sorted(drop_indices)}")

        print(f"\nNoise Injection:")
        print(f"- Noise level: {noise_level}")
        print(f"- Mean absolute difference: {np.mean(np.abs(noisy_data - self.data)):.4f}")
        print(f"- Max absolute difference: {np.max(np.abs(noisy_data - self.data)):.4f}")

def augment_dataset(dataset_name: str):
    """Perform spectral augmentation on a dataset"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        augmenter = SpectralAugmenter(
            data=processed_data['cleaned_data'],
            ground_truth=processed_data['ground_truth'],
            dataset_name=dataset_name
        )

        print(f"\nSpectral Augmentation Analysis for {dataset_name.upper()}")
        print("="*50)

        print("\nMild Augmentation:")
        augmenter.plot_augmentation_results(drop_ratio=0.05, noise_level=0.02)

        print("\nModerate Augmentation:")
        augmenter.plot_augmentation_results(drop_ratio=0.1, noise_level=0.05)

        print("\nStrong Augmentation:")
        augmenter.plot_augmentation_results(drop_ratio=0.2, noise_level=0.1)

        return augmenter

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        augmenter = augment_dataset(dataset)

"""## Spatial Augmentation
*		Rotation
*		Flipping
*		Random crops

"""

class SpatialAugmenter:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, dataset_name: str):
        """
        Initialize spatial augmenter

        Args:
            data: Hyperspectral data cube (height, width, bands)
            ground_truth: Ground truth labels
            dataset_name: Name of the dataset
        """
        self.data = data
        self.ground_truth = ground_truth
        self.dataset_name = dataset_name
        self.height, self.width, self.num_bands = data.shape

        self.original_data = data.copy()

    def rotate_data(self, angle: float = 90, preserve_range: bool = True) -> Tuple[np.ndarray, np.ndarray]:
        """
        Rotate the hyperspectral data and ground truth

        Args:
            angle: Rotation angle in degrees
            preserve_range: Whether to preserve the data range after rotation

        Returns:
            Tuple of rotated data and ground truth
        """
        rotated_data = np.zeros_like(self.data)

        for band in range(self.num_bands):
            rotated_data[:,:,band] = rotate(self.data[:,:,band],
                                          angle,
                                          reshape=False,
                                          mode='reflect',
                                          prefilter=False)

        rotated_gt = rotate(self.ground_truth,
                          angle,
                          reshape=False,
                          mode='reflect',
                          prefilter=False,
                          order=0)


        if preserve_range:
            rotated_data = np.clip(rotated_data, 0, 1)
            rotated_gt = np.round(rotated_gt).astype(self.ground_truth.dtype)

        return rotated_data, rotated_gt

    def flip_data(self, mode: str = 'horizontal') -> Tuple[np.ndarray, np.ndarray]:
        """
        Flip the hyperspectral data and ground truth

        Args:
            mode: 'horizontal', 'vertical', or 'both'

        Returns:
            Tuple of flipped data and ground truth
        """
        if mode == 'horizontal':
            flipped_data = np.flip(self.data, axis=1)
            flipped_gt = np.flip(self.ground_truth, axis=1)
        elif mode == 'vertical':
            flipped_data = np.flip(self.data, axis=0)
            flipped_gt = np.flip(self.ground_truth, axis=0)
        elif mode == 'both':
            flipped_data = np.flip(np.flip(self.data, axis=0), axis=1)
            flipped_gt = np.flip(np.flip(self.ground_truth, axis=0), axis=1)
        else:
            raise ValueError(f"Unknown flip mode: {mode}")

        return flipped_data, flipped_gt

    def random_crop(self, crop_size: int = 64, n_crops: int = 1) -> List[Tuple[np.ndarray, np.ndarray]]:
        """
        Generate random crops from the data

        Args:
            crop_size: Size of square crop
            n_crops: Number of crops to generate

        Returns:
            List of (cropped_data, cropped_gt) tuples
        """
        if crop_size > min(self.height, self.width):
            raise ValueError("Crop size larger than image dimensions")

        crops = []
        for _ in range(n_crops):

            x = np.random.randint(0, self.width - crop_size)
            y = np.random.randint(0, self.height - crop_size)

            cropped_data = self.data[y:y+crop_size, x:x+crop_size, :]
            cropped_gt = self.ground_truth[y:y+crop_size, x:x+crop_size]

            crops.append((cropped_data, cropped_gt))

        return crops

    def plot_augmentation_results(self, band_idx: Optional[int] = None):
        """Plot comparison of original and augmented data"""
        if band_idx is None:
            band_idx = self.num_bands // 2

        rotated_data, rotated_gt = self.rotate_data(angle=45)
        flipped_h_data, flipped_h_gt = self.flip_data('horizontal')
        flipped_v_data, flipped_v_gt = self.flip_data('vertical')
        crops = self.random_crop(crop_size=min(64, min(self.height, self.width)//2), n_crops=1)

        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(f'Spatial Augmentation Results - {self.dataset_name.upper()}', fontsize=16)

        im = axes[0, 0].imshow(self.data[:,:,band_idx], cmap='viridis')
        axes[0, 0].set_title('Original')
        plt.colorbar(im, ax=axes[0, 0])

        im = axes[0, 1].imshow(rotated_data[:,:,band_idx], cmap='viridis')
        axes[0, 1].set_title('Rotated (45°)')
        plt.colorbar(im, ax=axes[0, 1])

        im = axes[0, 2].imshow(flipped_h_data[:,:,band_idx], cmap='viridis')
        axes[0, 2].set_title('Horizontal Flip')
        plt.colorbar(im, ax=axes[0, 2])

        im = axes[1, 0].imshow(flipped_v_data[:,:,band_idx], cmap='viridis')
        axes[1, 0].set_title('Vertical Flip')
        plt.colorbar(im, ax=axes[1, 0])

        crop_data, _ = crops[0]
        im = axes[1, 1].imshow(crop_data[:,:,band_idx], cmap='viridis')
        axes[1, 1].set_title('Random Crop')
        plt.colorbar(im, ax=axes[1, 1])

        axes[1, 2].imshow(self.ground_truth, cmap='tab20')
        axes[1, 2].imshow(rotated_gt, cmap='tab20', alpha=0.5)
        axes[1, 2].set_title('GT Overlay (Original + Rotated)')

        plt.tight_layout()
        plt.show()

        print("\nAugmentation Summary:")
        print("-" * 50)
        print("Rotation:")
        print(f"- Mean absolute change: {np.mean(np.abs(rotated_data - self.data)):.4f}")

        print("\nFlipping:")
        print(f"- Horizontal flip shape: {flipped_h_data.shape}")
        print(f"- Vertical flip shape: {flipped_v_data.shape}")

        print("\nRandom Crops:")
        print(f"- Crop shape: {crops[0][0].shape}")
        print(f"- Number of crops: {len(crops)}")

def augment_dataset_spatially(dataset_name: str):
    """Perform spatial augmentation on a dataset"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        augmenter = SpatialAugmenter(
            data=processed_data['cleaned_data'],
            ground_truth=processed_data['ground_truth'],
            dataset_name=dataset_name
        )

        print(f"\nSpatial Augmentation Analysis for {dataset_name.upper()}")
        print("="*50)

        augmenter.plot_augmentation_results()

        return augmenter

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        augmenter = augment_dataset_spatially(dataset)

"""## Combined Spectral-Spatial Augmentation"""

class CombinedAugmenter:
    def __init__(self, data: np.ndarray, ground_truth: np.ndarray, dataset_name: str):
        """
        Initialize combined augmenter

        Args:
            data: Hyperspectral data cube (height, width, bands)
            ground_truth: Ground truth labels
            dataset_name: Name of the dataset
        """
        self.data = data.astype(np.float32)
        self.ground_truth = ground_truth
        self.dataset_name = dataset_name
        self.height, self.width, self.num_bands = data.shape

    def combined_augmentation(self,
                       rotation_angle: float = 45,
                       flip_mode: str = 'horizontal',
                       crop_size: Optional[int] = None,
                       drop_ratio: float = 0.1,
                       noise_level: float = 0.05,
                       random_state: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray]:
      """
      Apply combined spectral and spatial augmentation

      Args:
          rotation_angle: Angle for rotation
          flip_mode: Type of flipping ('horizontal', 'vertical', 'both')
          crop_size: Size for random crop (if None, will be set based on data size)
          drop_ratio: Ratio of bands to drop
          noise_level: Level of noise to add
          random_state: Random seed for reproducibility
      """
      if random_state is not None:
          np.random.seed(random_state)

      augmented_data = self.data.copy().astype(np.float32)
      augmented_gt = self.ground_truth.copy()

      if crop_size is None:
          crop_size = min(self.height, self.width) // 2

      crop_size = min(crop_size, min(self.height, self.width))

      # 1. Spatial Augmentations
      # Rotation
      for band in range(self.num_bands):
          augmented_data[:,:,band] = rotate(augmented_data[:,:,band],
                                          rotation_angle,
                                          reshape=False,
                                          mode='reflect')
      augmented_gt = rotate(augmented_gt,
                          rotation_angle,
                          reshape=False,
                          mode='reflect',
                          order=0)

      # Flipping
      if flip_mode == 'horizontal':
          augmented_data = np.flip(augmented_data, axis=1)
          augmented_gt = np.flip(augmented_gt, axis=1)
      elif flip_mode == 'vertical':
          augmented_data = np.flip(augmented_data, axis=0)
          augmented_gt = np.flip(augmented_gt, axis=0)
      elif flip_mode == 'both':
          augmented_data = np.flip(np.flip(augmented_data, axis=0), axis=1)
          augmented_gt = np.flip(np.flip(augmented_gt, axis=0), axis=1)

      # Random crop
      x = np.random.randint(0, self.width - crop_size)
      y = np.random.randint(0, self.height - crop_size)
      augmented_data = augmented_data[y:y+crop_size, x:x+crop_size, :]
      augmented_gt = augmented_gt[y:y+crop_size, x:x+crop_size]

      # 2. Spectral Augmentations
      # Band dropping
      n_drop = int(self.num_bands * drop_ratio)
      drop_indices = np.random.choice(self.num_bands, n_drop, replace=False)
      augmented_data[:, :, drop_indices] = 0

      # Noise injection
      noise = np.random.normal(0, noise_level, augmented_data.shape).astype(np.float32)
      augmented_data = augmented_data + noise

      # Clip values to valid range
      augmented_data = np.clip(augmented_data, 0, 1)
      augmented_gt = np.round(augmented_gt).astype(self.ground_truth.dtype)

      return augmented_data, augmented_gt

    def plot_augmentation_sequence(self, band_idx: Optional[int] = None):
        """Plot the sequence of augmentations"""
        if band_idx is None:
            band_idx = self.num_bands // 2

        crop_size = min(self.height, self.width) // 2
        steps = [
            ('Original', self.data.copy(), self.ground_truth.copy()),
            ('After Rotation', *self.combined_augmentation(drop_ratio=0, noise_level=0, crop_size=crop_size)),
            ('After Flipping', *self.combined_augmentation(rotation_angle=0, noise_level=0, crop_size=crop_size)),
            ('After Spectral', *self.combined_augmentation(crop_size=crop_size)),
        ]

        fig, axes = plt.subplots(2, len(steps), figsize=(20, 10))
        fig.suptitle(f'Combined Augmentation Sequence - {self.dataset_name.upper()}', fontsize=16)

        for i, (title, data, gt) in enumerate(steps):
            im = axes[0, i].imshow(data[:,:,band_idx], cmap='viridis')
            axes[0, i].set_title(f'{title}\nData Shape: {data.shape[:2]}')
            plt.colorbar(im, ax=axes[0, i])

            im = axes[1, i].imshow(gt, cmap='tab20')
            axes[1, i].set_title(f'{title}\nGround Truth Shape: {gt.shape}')

            axes[0, i].axis('off')
            axes[1, i].axis('off')

        plt.tight_layout()
        plt.show()

        print("\nAugmentation Statistics:")
        for i, (title, data, _) in enumerate(steps[1:], 1):
            diff = np.mean(np.abs(data - steps[0][1][:data.shape[0], :data.shape[1], :]))
            print(f"{title} - Mean Absolute Change: {diff:.4f}")

    def generate_augmented_dataset(self, n_augmentations: int = 5) -> Dict:
        """Generate multiple augmented versions of the dataset"""
        augmented_dataset = {
            'original': (self.data, self.ground_truth)
        }

        print(f"\nGenerating {n_augmentations} augmented versions...")
        for i in tqdm(range(n_augmentations)):
            params = {
                'rotation_angle': np.random.uniform(0, 360),
                'flip_mode': np.random.choice(['horizontal', 'vertical', 'both']),
                'drop_ratio': np.random.uniform(0.05, 0.15),
                'noise_level': np.random.uniform(0.02, 0.08),
                'random_state': i
            }

            aug_data, aug_gt = self.combined_augmentation(**params)
            augmented_dataset[f'augmentation_{i+1}'] = (aug_data, aug_gt)

            print(f"\nAugmentation {i+1} parameters:")
            for param, value in params.items():
                print(f"- {param}: {value}")

        return augmented_dataset

def augment_dataset_combined(dataset_name: str):
    """Perform combined augmentation on a dataset"""
    processed_data = preprocess_silently(dataset_name)

    if processed_data is not None:
        try:
            augmenter = CombinedAugmenter(
                data=processed_data['cleaned_data'],
                ground_truth=processed_data['ground_truth'],
                dataset_name=dataset_name
            )

            print(f"\nCombined Augmentation Analysis for {dataset_name.upper()}")
            print("="*50)

            print("\nVisualizing augmentation sequence...")
            augmenter.plot_augmentation_sequence()

            print("\nGenerating augmented dataset...")
            augmented_dataset = augmenter.generate_augmented_dataset(n_augmentations=3)

            print("\nAugmentation Summary:")
            print("-" * 50)
            print(f"Original data shape: {augmenter.data.shape}")
            for name, (data, gt) in augmented_dataset.items():
                print(f"{name}:")
                print(f"- Data shape: {data.shape}")
                print(f"- Ground truth shape: {gt.shape}")
                print(f"- Data range: [{data.min():.2f}, {data.max():.2f}]")

            return augmented_dataset

        except Exception as e:
            print(f"Error during augmentation: {str(e)}")
            return None

    return None

def show_augmentation_examples(augmented_dataset: Dict, band_idx: Optional[int] = None):
    """Show examples from augmented dataset"""
    if augmented_dataset is None:
        print("No augmented dataset to display")
        return

    first_data = list(augmented_dataset.values())[0][0]
    if band_idx is None:
        band_idx = first_data.shape[-1] // 2

    n_examples = len(augmented_dataset)
    fig, axes = plt.subplots(2, n_examples, figsize=(5*n_examples, 10))
    fig.suptitle('Augmentation Examples', fontsize=16)

    for i, (name, (data, gt)) in enumerate(augmented_dataset.items()):
        im = axes[0, i].imshow(data[:,:,band_idx], cmap='viridis')
        axes[0, i].set_title(f'{name}\nData')
        plt.colorbar(im, ax=axes[0, i])

        im = axes[1, i].imshow(gt, cmap='tab20')
        axes[1, i].set_title(f'{name}\nGround Truth')

        axes[0, i].axis('off')
        axes[1, i].axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    for dataset in SELECTED_DATASET:
        augmented_dataset = augment_dataset_combined(dataset)

        if augmented_dataset is not None:
            show_augmentation_examples(augmented_dataset)

"""# **5.Model Architecture Design**

## Classification

### ResNet18
"""

@dataclass
class ModelConfig:
    """Configuration class for model hyperparameters"""
    in_channels: int  # Number of input spectral bands
    num_classes: int  # Number of output classes
    spatial_size: int = 13  # Default spatial size for input patches
    base_channels: int = 64  # Number of base channels
    dropout_rate: float = 0.6
    use_spatial_attention: bool = True
    use_spectral_attention: bool = True
    weight_decay: float = 2e-4    # Add L2 regularization
    label_smoothing: float = 0.1  # Add label smoothing
    path_dropout: float = 0.1   # Add stochastic depth
    mixup_alpha: float = 0.2      # Add mixup augmentation
    learning_rate: float = 0.001
    batch_size: int = 16
    num_epochs: int = 200
    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'

class SpectralAttention(nn.Module):
    """Fixed spectral attention module"""
    def __init__(self, in_channels: int, reduction_ratio: int = 16):
        super().__init__()
        self.attention = nn.Sequential(
            nn.Linear(in_channels, in_channels // reduction_ratio),
            nn.ReLU(inplace=True),
            nn.Linear(in_channels // reduction_ratio, in_channels),
            nn.Sigmoid()
        )
        self.avg_pool = nn.AdaptiveAvgPool2d(1)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.attention(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

class SpatialAttention(nn.Module):
    """
    Spatial Attention Module
    Learns spatial attention weights to focus on important regions
    """
    def __init__(self, kernel_size: int = 7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)

        y = torch.cat([avg_out, max_out], dim=1)
        y = self.conv(y)

        y = torch.sigmoid(y)
        return x * y

class BasicBlock(nn.Module):
    """Modified BasicBlock with spectral and spatial attention"""
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        use_spectral_attention: bool = True,
        use_spatial_attention: bool = True
    ) -> None:
        super().__init__()

        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3,
                              stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,
                              stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)

        self.spectral_attention = SpectralAttention(planes) if use_spectral_attention else None
        self.spatial_attention = SpatialAttention() if use_spatial_attention else None

        self.downsample = downsample
        self.stride = stride

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.spectral_attention is not None:
            out = self.spectral_attention(out)
        if self.spatial_attention is not None:
            out = self.spatial_attention(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out

class HyperspectralResNet(nn.Module):
    """Modified ResNet architecture with corrected dimensions"""
    def __init__(self, config: ModelConfig):
        super().__init__()

        self.config = config
        self.inplanes = config.base_channels

        self.current_spatial_size = config.spatial_size

        self.conv1 = nn.Conv2d(config.in_channels, self.inplanes, kernel_size=3,
                              stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(self.inplanes)
        self.relu = nn.ReLU(inplace=True)

        self.layer1 = self._make_layer(self.inplanes, stride=1)     # 64->64 channels, 13
        self.layer2 = self._make_layer(self.inplanes * 2, stride=2) # 64->128 channels, 7
        self.layer3 = self._make_layer(self.inplanes * 4, stride=2) # 128->256 channels, 4

        self.final_spatial_size = self.current_spatial_size
        self.final_channels = self.inplanes

        self.flattened_features = self.final_channels * self.final_spatial_size * self.final_spatial_size

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout(config.dropout_rate)

        self.fc = nn.Linear(self.final_channels, config.num_classes)

        self._initialize_weights()
        self._print_model_structure()

    def _make_layer(self, planes: int, stride: int = 1) -> nn.Sequential:
        """Create a ResNet layer with dimension tracking"""
        downsample = None
        if stride != 1 or self.inplanes != planes * BasicBlock.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * BasicBlock.expansion,
                         kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * BasicBlock.expansion),
            )

        if stride != 1:
            self.current_spatial_size = math.ceil(self.current_spatial_size / stride)

        layers = []
        layers.append(
            BasicBlock(
                self.inplanes, planes, stride, downsample,
                self.config.use_spectral_attention,
                self.config.use_spatial_attention
            )
        )
        self.inplanes = planes * BasicBlock.expansion
        layers.append(
            BasicBlock(
                self.inplanes, planes,
                use_spectral_attention=self.config.use_spectral_attention,
                use_spatial_attention=self.config.use_spatial_attention
            )
        )

        return nn.Sequential(*layers)

    def _print_model_structure(self):
        """Print detailed model structure information"""
        print(f"\nModel Structure Summary:")
        print(f"Input channels: {self.config.in_channels}")
        print(f"Initial spatial size: {self.config.spatial_size}x{self.config.spatial_size}")
        print(f"Final spatial size before pooling: {self.final_spatial_size}x{self.final_spatial_size}")
        print(f"Final channels: {self.final_channels}")
        print(f"Features after flattening: {self.flattened_features}")
        print(f"Features after pooling: {self.final_channels}")
        print(f"Output classes: {self.config.num_classes}")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        debug = self.training and hasattr(self, 'debug') and self.debug

        if x.dim() == 3:
            x = x.unsqueeze(1)

        if debug:
            print(f"\nInput shape: {x.shape}")

        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)

        if debug:
            print(f"After initial conv: {x.shape}")

        x = self.layer1(x)
        if debug:
            print(f"After layer1: {x.shape}")

        x = self.layer2(x)
        if debug:
            print(f"After layer2: {x.shape}")

        x = self.layer3(x)
        if debug:
            print(f"After layer3: {x.shape}")

        x = self.avgpool(x)
        if debug:
            print(f"After pooling: {x.shape}")

        x = torch.flatten(x, 1)
        if debug:
            print(f"After flatten: {x.shape}")

        x = self.dropout(x)
        x = self.fc(x)

        if debug:
            print(f"Final output: {x.shape}")

        return x

    def _initialize_weights(self):
        """Initialize model weights"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.normal_(m.weight, 0, 0.01)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

def create_model(dataset_name: str) -> HyperspectralResNet:
    """Create a model instance for a specific dataset"""
    dataset_configs = {
        'indian_pines': ModelConfig(
            in_channels=180,
            num_classes=16,
            spatial_size=13,
            base_channels=64
        ),
        'pavia_university': ModelConfig(
            in_channels=103,
            num_classes=9,
            spatial_size=13,
            base_channels=64
        ),
        'salinas': ModelConfig(
            in_channels=204,
            num_classes=16,
            spatial_size=13,
            base_channels=64
        )
    }

    if dataset_name.lower() not in dataset_configs:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    config = dataset_configs[dataset_name.lower()]
    return HyperspectralResNet(config)

def prepare_dataset_for_training(data: np.ndarray, task: str) -> torch.Tensor:
    """Prepare data for training based on task type"""
    if not isinstance(data, torch.Tensor):
        data = torch.from_numpy(data).float()

    if task == 'classification' or task == 'segmentation':
        if len(data.shape) == 2:  # [B, C]
            B, C = data.shape
            if math.sqrt(C) == int(math.sqrt(C)):
                H = W = int(math.sqrt(C))
                return data.reshape(B, 1, H, W)
            else:
                # [B, C, H, W]
                H = W = 13
                return data.reshape(B, C, 1, 1).repeat(1, 1, H, W)
        elif len(data.shape) == 3:  # [B, H, W]
            B, H, W = data.shape
            return data.unsqueeze(1)
        elif len(data.shape) == 4:  # [B, C, H, W]
            return data

    return data

class HyperspectralDataset(Dataset):
    def __init__(self, data: np.ndarray, labels: np.ndarray, dataset_name: str, task_type: str = 'classification'):
        """Initialize dataset with task-specific formatting"""
        self.data = data
        self.labels = labels
        self.dataset_name = dataset_name
        self.task_type = task_type
        self.ground_truth = labels
        self.class_names = get_dataset_config(dataset_name)['class_names']
        self.dataset_name = dataset_name.lower()
        print(f"Initial data shape: {data.shape}")
        print(f"Initial labels shape: {labels.shape}")

        self.data = torch.from_numpy(data).float()
        self.labels = torch.from_numpy(labels).long()

        channels_map = {
            'indian_pines': 180,
            'pavia_university': 103,
            'salinas': 204
        }
        num_channels = channels_map[self.dataset_name]

        if len(self.data.shape) == 2:
            B = self.data.shape[0]
            self.data = self.data[:, :num_channels].reshape(B, num_channels, 13, 13)

            if self.task_type == 'segmentation':
                self.labels = self.labels.unsqueeze(1).repeat(1, 13*13).reshape(B, 13, 13)

        elif len(self.data.shape) == 4:  # (samples, height, width, channels)
            self.data = self.data[..., :num_channels].permute(0, 3, 1, 2)

            if self.task_type == 'segmentation':
                B = self.data.shape[0]
                if len(self.labels.shape) == 1:
                    self.labels = self.labels.unsqueeze(1).repeat(1, 13*13).reshape(B, 13, 13)
                else:
                    self.labels = self.labels.reshape(B, 13, 13)

        print(f"Final data shape: {self.data.shape}")
        print(f"Final labels shape: {self.labels.shape}")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        """Get a sample from the dataset"""
        data = self.data[idx]
        target = self.labels[idx]

        if self.task_type == 'segmentation':
            target = target.reshape(13, 13) if target.dim() == 1 else target

        return data, target

def prepare_data_loaders(data: Dict, batch_size: int) -> Dict:
    """Prepare data loaders for training, validation, and testing"""
    loaders = {}
    for split in ['train', 'val', 'test']:
        X = data[f'{split}_data']['X']
        y = data[f'{split}_data']['y']

        dataset = HyperspectralDataset(X, y)

        loaders[split] = torch.utils.data.DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=(split == 'train'),
            num_workers=4,
            pin_memory=True
        )

    return loaders

def test_model():
    """Test the model architecture with sample data"""
    torch.set_printoptions(precision=4, sci_mode=False)

    for dataset_name in ['indian_pines', 'pavia_university', 'salinas']:
        print(f"\nTesting model for {dataset_name.upper()}")

        try:
            model = create_model(dataset_name)
            model.train()
            model.debug = True

            config = ModelConfig(
                in_channels={'indian_pines': 180, 'pavia_university': 103, 'salinas': 204}[dataset_name],
                num_classes={'indian_pines': 16, 'pavia_university': 9, 'salinas': 16}[dataset_name],
                spatial_size=13
            )

            batch_size = 4
            input_tensor = torch.randn(batch_size, config.in_channels, 13, 13)

            print("\nPerforming forward pass with shape tracking...")
            output = model(input_tensor)

            print(f"\nModel test successful:")
            print(f"Input shape: {input_tensor.shape}")
            print(f"Output shape: {output.shape}")

            expected_classes = config.num_classes
            assert output.shape == (batch_size, expected_classes), \
                f"Output shape {output.shape} doesn't match expected {(batch_size, expected_classes)}"

            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            print(f"\nModel Statistics:")
            print(f"Total parameters: {total_params:,}")
            print(f"Trainable parameters: {trainable_params:,}")

            if torch.cuda.is_available():
                model = model.cuda()
                input_tensor = input_tensor.cuda()
                output = model(input_tensor)
                print("GPU test successful")

        except Exception as e:
            print(f"Error: {str(e)}")
            import traceback
            traceback.print_exc()

        model.eval()
        model.debug = False

if __name__ == "__main__":
    print("Testing Hyperspectral Classification Model")
    print("=" * 50)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    BATCH_SIZE = 32
    SPATIAL_SIZE = 13

    for dataset_name in SELECTED_DATASET:
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 50)

        try:
            config = ModelConfig(
                in_channels={
                    'indian_pines': 180,
                    'pavia_university': 103,
                    'salinas': 204
                }[dataset_name],
                num_classes={
                    'indian_pines': 16,
                    'pavia_university': 9,
                    'salinas': 16
                }[dataset_name],
                spatial_size=SPATIAL_SIZE,
                batch_size=BATCH_SIZE,
                device=str(device)
            )

            model = create_model(dataset_name)
            model = model.to(device)
            print("Model created successfully")

            batch_size = 4
            dummy_input = torch.randn(batch_size, config.in_channels,
                                    SPATIAL_SIZE, SPATIAL_SIZE).to(device)

            model.eval()
            with torch.no_grad():
                try:
                    output = model(dummy_input)
                    print("\nForward pass successful")
                    print(f"Input shape: {dummy_input.shape}")
                    print(f"Output shape: {output.shape}")

                    expected_shape = (batch_size, config.num_classes)
                    assert output.shape == expected_shape, \
                        f"Output shape {output.shape} doesn't match expected {expected_shape}"

                except Exception as e:
                    print(f"Forward pass error: {str(e)}")
                    continue

            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

            print("\nModel Statistics:")
            print(f"Total parameters: {total_params:,}")
            print(f"Trainable parameters: {trainable_params:,}")

            print("\nMemory Usage:")
            if torch.cuda.is_available():
                print(f"GPU Memory Allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB")
                print(f"GPU Memory Cached: {torch.cuda.memory_reserved()/1024**2:.2f} MB")

            model.train()
            print("\nModel successfully switched to training mode")
            model.eval()
            print("Model successfully switched to evaluation mode")

            with torch.no_grad():
                logits = model(dummy_input)
                probs = F.softmax(logits, dim=1)
                print("\nExample output probabilities shape:", probs.shape)

            print("\nTesting different input sizes:")
            test_sizes = [11, 13, 15]
            for size in test_sizes:
                try:
                    test_input = torch.randn(1, config.in_channels, size, size).to(device)
                    with torch.no_grad():
                        test_output = model(test_input)
                    print(f"Input size {size}x{size} - Success")
                except Exception as e:
                    print(f"Input size {size}x{size} - Failed: {str(e)}")

            print("\nModel Layer Information:")
            print(f"First conv layer weight shape: {model.conv1.weight.shape}")
            print(f"Final FC layer weight shape: {model.fc.weight.shape}")

            del model, dummy_input, output
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            print("\nMemory cleaned up")

        except Exception as e:
            print(f"\nError testing {dataset_name}: {str(e)}")
            import traceback
            traceback.print_exc()

    print("\nModel Testing Complete!")
    print("=" * 50)

    print("\nTesting model saving and loading...")
    try:
        example_model = create_model('indian_pines')
        torch.save(example_model.state_dict(), 'hyperspectral_model.pth')
        print("Model saved successfully")

        loaded_model = create_model('indian_pines')
        loaded_model.load_state_dict(torch.load('hyperspectral_model.pth'))
        loaded_model.eval()
        print("Model loaded successfully")

        import os
        os.remove('hyperspectral_model.pth')
        print("Cleanup completed")

    except Exception as e:
        print(f"Error in save/load test: {str(e)}")

"""### Vision Transformer adaptation"""

dataset_configs = {
    'indian_pines': {
        'in_channels': 180,
        'num_classes': 16,
        'spatial_size': 13,
        'patch_size': 1,
        'dim': 256,
        'heads': 8,
        'depth': 6
    },
    'pavia_university': {
        'in_channels': 103,
        'num_classes': 9,
        'spatial_size': 13,
        'patch_size': 1,
        'dim': 256,
        'heads': 8,
        'depth': 6
    },
    'salinas': {
        'in_channels': 204,
        'num_classes': 16,
        'spatial_size': 13,
        'patch_size': 1,
        'dim': 256,
        'heads': 8,
        'depth': 6
    }
}

@dataclass
class ViTConfig:
    """Configuration for Hyperspectral Vision Transformer"""
    in_channels: int          # Number of input spectral bands
    num_classes: int          # Number of output classes
    spatial_size: int = 13    # Input spatial dimensions
    patch_size: int = 1       # Patch size for spatial dimension
    dim: int = 256           # Transformer embedding dimension
    depth: int = 6           # Number of transformer layers
    heads: int = 8           # Number of attention heads
    mlp_dim: int = 1024       # Dimension of feed-forward network

    weight_decay: float = 2e-4
    label_smoothing: float = 0.1
    mixup_alpha: float = 0.2

    dropout: float = 0.1     # General dropout rate
    emb_dropout: float = 0.2 # Embedding dropout rate
    pool: str = 'cls'        # Pooling type ('cls' or 'mean')
    dropout_rate: float = 0.6 # Additional dropout rate for regularization

    attention_dropout: float = 0.2
    path_dropout: float = 0.1
    learning_rate: float = 1e-4
    warmup_steps: int = 1000

    def __post_init__(self):
      self.transformer_dim = self.dim
      self.transformer_heads = self.heads
      self.transformer_depth = self.depth

class SpectralPatchEmbedding(nn.Module):
    """
    Custom patch embedding that handles both spatial and spectral dimensions
    """
    def __init__(self, config: ViTConfig):
        super().__init__()

        self.patch_size = config.patch_size
        self.in_channels = config.in_channels
        self.dim = config.dim

        self.num_patches = (config.spatial_size // config.patch_size) ** 2

        self.projection = nn.Sequential(
            nn.Conv2d(config.in_channels,
                     config.dim,
                     kernel_size=config.patch_size,
                     stride=config.patch_size),
            nn.LayerNorm([config.dim,
                         config.spatial_size // config.patch_size,
                         config.spatial_size // config.patch_size])
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Input shape: (batch_size, in_channels, height, width)
        batch_size = x.shape[0]

        # Project and reshape
        x = self.projection(x)  # (batch_size, dim, h', w')
        x = x.flatten(2)        # (batch_size, dim, h'*w')
        x = x.transpose(1, 2)   # (batch_size, h'*w', dim)

        return x

class SpectralAttention(nn.Module):
    """
    Spectral Attention Module
    """
    def __init__(self, channels: int, num_heads: int = 8, reduction_ratio: int = 16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        reduced_channels = max(channels // reduction_ratio, 8)

        self.attention = nn.Sequential(
            nn.Linear(channels, reduced_channels),
            nn.ReLU(inplace=True),
            nn.Linear(reduced_channels, channels),
            nn.Sigmoid()
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.attention(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

class FeedForward(nn.Module):
    """
    MLP block in transformer
    """
    def __init__(self, config: ViTConfig):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(config.dim, config.mlp_dim),
            nn.GELU(),
            nn.Dropout(config.dropout),
            nn.Linear(config.mlp_dim, config.dim),
            nn.Dropout(config.dropout)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x)

class TransformerBlock(nn.Module):
    """Transformer block with spectral attention"""
    def __init__(self, config: ViTConfig):
        super().__init__()
        self.norm1 = nn.LayerNorm(config.dim)
        self.norm2 = nn.LayerNorm(config.dim)

        self.attention = nn.MultiheadAttention(
            embed_dim=config.dim,
            num_heads=config.heads,
            dropout=config.dropout,
            batch_first=True
        )

        self.mlp = nn.Sequential(
            nn.Linear(config.dim, config.mlp_dim),
            nn.GELU(),
            nn.Dropout(config.dropout),
            nn.Linear(config.mlp_dim, config.dim),
            nn.Dropout(config.dropout)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        normed = self.norm1(x)
        attended, _ = self.attention(normed, normed, normed)
        x = x + attended

        x = x + self.mlp(self.norm2(x))
        return x

class HyperspectralViT(nn.Module):
    """
    Vision Transformer adapted for hyperspectral image classification
    """
    def __init__(self, config: ViTConfig):
        super().__init__()
        self.config = config

        self.patch_embedding = SpectralPatchEmbedding(config)

        self.cls_token = nn.Parameter(torch.randn(1, 1, config.dim))
        self.pos_embedding = nn.Parameter(
            torch.randn(1, self.patch_embedding.num_patches + 1, config.dim)
        )
        self.dropout = nn.Dropout(config.emb_dropout)

        self.transformer = nn.ModuleList([
            TransformerBlock(config) for _ in range(config.depth)
        ])

        self.mlp_head = nn.Sequential(
            nn.LayerNorm(config.dim),
            nn.Linear(config.dim, config.num_classes)
        )

        self.apply(self._init_weights)

        self._print_model_structure()

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            torch.nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)

    def _print_model_structure(self):
        """Print model structure details"""
        print(f"\nHyperspectral ViT Structure:")
        print(f"Input channels: {self.config.in_channels}")
        print(f"Spatial size: {self.config.spatial_size}x{self.config.spatial_size}")
        print(f"Patch size: {self.config.patch_size}")
        print(f"Number of patches: {self.patch_embedding.num_patches}")
        print(f"Embedding dimension: {self.config.dim}")
        print(f"Number of heads: {self.config.heads}")
        print(f"Number of layers: {self.config.depth}")
        print(f"MLP dimension: {self.config.mlp_dim}")
        print(f"Output classes: {self.config.num_classes}")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Input shape: (batch_size, in_channels, height, width)
        batch_size = x.shape[0]

        if x.dim() == 3:
            x = x.unsqueeze(1)

        x = self.patch_embedding(x)

        cls_tokens = self.cls_token.expand(batch_size, -1, -1)
        x = torch.cat((cls_tokens, x), dim=1)

        x = x + self.pos_embedding
        x = self.dropout(x)

        for transformer in self.transformer:
            x = transformer(x)

        if self.config.pool == 'mean':
            x = x.mean(dim=1)
        else:
            x = x[:, 0]

        x = self.mlp_head(x)
        return x

def create_vit_model(dataset_name: str) -> HyperspectralViT:
    """Create a ViT model instance for a specific dataset"""
    dataset_configs = {
        'indian_pines': ViTConfig(
            in_channels=180,
            num_classes=16,
            spatial_size=13,
            dropout_rate=0.1,
            mlp_dim=1024
        ),
        'pavia_university': ViTConfig(
            in_channels=103,
            num_classes=9,
            spatial_size=13,
            dropout_rate=0.1,
            mlp_dim=1024
        ),
        'salinas': ViTConfig(
            in_channels=204,
            num_classes=16,
            spatial_size=13,
            dropout_rate=0.1,
            mlp_dim=1024
        )
    }

    if dataset_name.lower() not in dataset_configs:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    return HyperspectralViT(dataset_configs[dataset_name.lower()])

if __name__ == "__main__":
    torch.set_printoptions(precision=4, sci_mode=False)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    test_configs = {
        'indian_pines': {
            'in_channels': 180,
            'num_classes': 16,
            'spatial_size': 13
        },
        'pavia_university': {
            'in_channels': 103,
            'num_classes': 9,
            'spatial_size': 13
        },
        'salinas': {
            'in_channels': 204,
            'num_classes': 16,
            'spatial_size': 13
        }
    }

    for dataset_name in SELECTED_DATASET:
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 50)

        try:
            dataset_config = test_configs[dataset_name]

            vit_config = ViTConfig(
                in_channels=dataset_config['in_channels'],
                num_classes=dataset_config['num_classes'],
                spatial_size=dataset_config['spatial_size']
            )

            model = HyperspectralViT(vit_config).to(device)
            print("Model created successfully")

            batch_size = 4
            dummy_input = torch.randn(batch_size, vit_config.in_channels,
                                    vit_config.spatial_size,
                                    vit_config.spatial_size).to(device)

            model.eval()
            with torch.no_grad():
                output = model(dummy_input)
                print(f"\nForward pass successful")
                print(f"Input shape: {dummy_input.shape}")
                print(f"Output shape: {output.shape}")

            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters()
                                 if p.requires_grad)
            print(f"\nModel Statistics:")
            print(f"Total parameters: {total_params:,}")
            print(f"Trainable parameters: {trainable_params:,}")

            del model, dummy_input, output
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        except Exception as e:
            print(f"Error: {str(e)}")
            import traceback
            traceback.print_exc()

"""### ResNet18 & Vision Transformer Summary"""

def print_model_summary(model: nn.Module, input_shape: tuple):
    """Print detailed model summary with parameter counts and output shapes"""
    def get_layer_info(layer):
        params = sum(p.numel() for p in layer.parameters())
        trainable_params = sum(p.numel() for p in layer.parameters() if p.requires_grad)
        return params, trainable_params

    print("\nModel Layer Summary")
    print("=================================================================")
    print(f"{'Layer (type)':<25} {'Output Shape':<25} {'Param #':<10}")
    print("=================================================================")

    x = torch.randn(input_shape)

    total_params = 0
    activation = x

    # For ResNet
    if isinstance(model, HyperspectralResNet):
        print(f"{'input':<25} {str(list(x.shape)):<25} {0:<10}")

        activation = model.conv1(activation)
        params, _ = get_layer_info(model.conv1)
        total_params += params
        print(f"{'conv1':<25} {str(list(activation.shape)):<25} {params:<10}")

        activation = model.bn1(activation)
        params, _ = get_layer_info(model.bn1)
        total_params += params
        print(f"{'bn1':<25} {str(list(activation.shape)):<25} {params:<10}")

        activation = model.relu(activation)

        for i, layer in enumerate([model.layer1, model.layer2, model.layer3]):
            activation = layer(activation)
            params, _ = get_layer_info(layer)
            total_params += params
            print(f"{'layer'+str(i+1):<25} {str(list(activation.shape)):<25} {params:<10}")

        activation = model.avgpool(activation)
        print(f"{'avgpool':<25} {str(list(activation.shape)):<25} {0:<10}")

        activation = torch.flatten(activation, 1)
        print(f"{'flatten':<25} {str(list(activation.shape)):<25} {0:<10}")

        activation = model.fc(activation)
        params, _ = get_layer_info(model.fc)
        total_params += params
        print(f"{'fc':<25} {str(list(activation.shape)):<25} {params:<10}")

    elif isinstance(model, HyperspectralViT):
        print(f"{'input':<25} {str(list(x.shape)):<25} {0:<10}")

        activation = model.patch_embedding(activation)
        params, _ = get_layer_info(model.patch_embedding)
        total_params += params
        print(f"{'patch_embedding':<25} {str(list(activation.shape)):<25} {params:<10}")

        cls_tokens = model.cls_token.expand(x.shape[0], -1, -1)
        activation = torch.cat((cls_tokens, activation), dim=1)
        print(f"{'cls_token':<25} {str(list(activation.shape)):<25} {model.cls_token.numel():<10}")

        activation = activation + model.pos_embedding
        print(f"{'pos_embedding':<25} {str(list(activation.shape)):<25} {model.pos_embedding.numel():<10}")

        for i, block in enumerate(model.transformer):
            activation = block(activation)
            params, _ = get_layer_info(block)
            total_params += params
            print(f"{'transformer_block_'+str(i):<25} {str(list(activation.shape)):<25} {params:<10}")

        activation = activation[:, 0]
        print(f"{'cls_token_select':<25} {str(list(activation.shape)):<25} {0:<10}")

        activation = model.mlp_head(activation)
        params, _ = get_layer_info(model.mlp_head)
        total_params += params
        print(f"{'mlp_head':<25} {str(list(activation.shape)):<25} {params:<10}")

    print("=================================================================")
    print(f"Total params: {total_params:,}")
    print(f"Trainable params: {total_params:,}")
    print("=================================================================")

if __name__ == "__main__":
    input_shapes = {
        'indian_pines': (4, 180, 13, 13),
        'pavia_university': (4, 103, 13, 13),
        'salinas': (4, 204, 13, 13)
    }

    for dataset_name in SELECTED_DATASET:
        input_shape = input_shapes[dataset_name]

        try:
            print(f"\nResNet18 Architecture Summary for {dataset_name.upper()}")
            model_resnet = create_model(dataset_name)
            print_model_summary(model_resnet, input_shape)

            print(f"\nVision Transformer Architecture Summary for {dataset_name.upper()}")
            model_vit = create_vit_model(dataset_name)
            print_model_summary(model_vit, input_shape)

            del model_resnet, model_vit
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            #print("\n" + "="*70 + "\n")

        except Exception as e:
            print(f"Error for dataset {dataset_name}: {str(e)}")
            import traceback
            traceback.print_exc()
            continue

"""### 3D CNN"""

@dataclass
class CNNConfig:
    """Configuration for 3D-CNN"""
    in_channels: int          # Number of input spectral bands
    num_classes: int          # Number of output classes
    spatial_size: int = 13    # Input spatial dimensions (assumed square)
    base_filters: int = 8     # Number of base filters
    spatial_kernel_size: int = 3  # Spatial kernel dimensions
    spectral_kernel_size: int = 7 # Spectral kernel dimension
    dropout_rate: float = 0.6
    use_batch_norm: bool = True

class Hyperspectral3DCNN(nn.Module):
    """
    3D-CNN Architecture for Hyperspectral Image Classification
    Processes both spatial and spectral dimensions using 3D convolutions
    """
    def __init__(self, config: CNNConfig):
        super().__init__()

        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        spectral_size = config.in_channels
        spatial_size = config.spatial_size

        self.conv3d_1 = nn.Sequential(
            nn.Conv3d(1, config.base_filters,
                     kernel_size=(config.spectral_kernel_size,
                                config.spatial_kernel_size,
                                config.spatial_kernel_size),
                     padding=(config.spectral_kernel_size//2,
                            config.spatial_kernel_size//2,
                            config.spatial_kernel_size//2)),
            nn.BatchNorm3d(config.base_filters) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(),
            nn.MaxPool3d(kernel_size=(2, 1, 1))
        )

        spectral_size = spectral_size // 2

        self.conv3d_2 = nn.Sequential(
            nn.Conv3d(config.base_filters, config.base_filters * 2,
                     kernel_size=(config.spectral_kernel_size,
                                config.spatial_kernel_size,
                                config.spatial_kernel_size),
                     padding=(config.spectral_kernel_size//2,
                            config.spatial_kernel_size//2,
                            config.spatial_kernel_size//2),
                     stride=(2, 1, 1)),
            nn.BatchNorm3d(config.base_filters * 2) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(),
            nn.MaxPool3d(kernel_size=(2, 2, 2))
        )

        spectral_size = spectral_size // 4
        spatial_size = spatial_size // 2

        self.conv3d_3 = nn.Sequential(
            nn.Conv3d(config.base_filters * 2, config.base_filters * 4,
                     kernel_size=(config.spectral_kernel_size,
                                config.spatial_kernel_size,
                                config.spatial_kernel_size),
                     padding=(config.spectral_kernel_size//2,
                            config.spatial_kernel_size//2,
                            config.spatial_kernel_size//2)),
            nn.BatchNorm3d(config.base_filters * 4) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(),
            nn.MaxPool3d(kernel_size=(2, 2, 2))
        )

        spectral_size = spectral_size // 2
        spatial_size = spatial_size // 2

        self.flatten_size = (config.base_filters * 4) * spectral_size * spatial_size * spatial_size

        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(self.flatten_size, 512),
            nn.ReLU(),
            nn.Dropout(config.dropout_rate),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(config.dropout_rate),
            nn.Linear(256, config.num_classes)
        )

        self.apply(self._init_weights)

        self.shapes = {}

        self.to(self.device)

    def _init_weights(self, m):
        if isinstance(m, (nn.Conv3d, nn.Linear)):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.BatchNorm3d):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass that handles 4D input (B,C,H,W)
        Args:
            x: Input tensor of shape (batch_size, channels, height, width)
        Returns:
            Output tensor of shape (batch_size, num_classes)
        """
        x = x.to(self.device)

        #  (B,C,H,W) -> (B,1,C,H,W)
        if x.dim() == 4:
            x = x.unsqueeze(1)

        self.shapes = {}
        self.shapes['input'] = x.shape

        x = self.conv3d_1(x)
        self.shapes['conv3d_1'] = x.shape

        x = self.conv3d_2(x)
        self.shapes['conv3d_2'] = x.shape

        x = self.conv3d_3(x)
        self.shapes['conv3d_3'] = x.shape

        x = x.flatten(1)
        self.shapes['flatten'] = x.shape

        x = self.fc_layers(x)
        self.shapes['output'] = x.shape

        return x

def create_3dcnn_model(dataset_name: str) -> Hyperspectral3DCNN:
    """Create a 3D-CNN model instance for a specific dataset"""
    dataset_configs = {
        'indian_pines': CNNConfig(
            in_channels=180,
            num_classes=16,
            spatial_size=13
        ),
        'pavia_university': CNNConfig(
            in_channels=103,
            num_classes=9,
            spatial_size=13
        ),
        'salinas': CNNConfig(
            in_channels=204,
            num_classes=16,
            spatial_size=13
        )
    }

    if dataset_name.lower() not in dataset_configs:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    config = dataset_configs[dataset_name.lower()]
    return Hyperspectral3DCNN(config)

def print_layer_summary(model: nn.Module, input_shape: tuple):
    """Print detailed layer-by-layer summary with shapes and parameters"""
    print("\nLayer-wise Summary")
    print("=================================================================")
    print(f"{'Layer (type)':<20} {'Output Shape':<20} {'Param #':<10}")
    print("=================================================================")

    def count_params(module):
        """Helper function to count parameters in a module"""
        return sum(p.numel() for p in module.parameters())

    try:
        # [B, 1, C, H, W]
        x = torch.randn(input_shape).to(model.device)
        x = x.unsqueeze(1)
        _ = model(x)

        print(f"{'Input':<20} {str(list(x.shape)):<20} {0:<10}")

        for name, shape in model.shapes.items():
            if name == 'input':
                continue

            if name.startswith('conv3d'):
                if name == 'conv3d_1':
                    module = model.conv3d_1
                elif name == 'conv3d_2':
                    module = model.conv3d_2
                elif name == 'conv3d_3':
                    module = model.conv3d_3
            elif name == 'flatten':
                module = model.fc_layers[0]
            elif name == 'output':
                module = model.fc_layers[-1]
            else:
                continue

            params = count_params(module)
            print(f"{name:<20} {str(list(shape)):<20} {params:<10}")

        total_params = count_params(model)
        print("=================================================================")
        print(f"Total params: {total_params:,}")
        print(f"Trainable params: {total_params:,}")
        print("=================================================================")

    except Exception as e:
        print(f"Error during layer summary: {str(e)}")
        traceback.print_exc()

def test_3dcnn():
    """Test function for the 3D-CNN model"""
    print("Testing 3D-CNN Model")
    print(f"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")

    for dataset_name in SELECTED_DATASET:
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 50)

        try:
            model = create_3dcnn_model(dataset_name)
            print(f"Model created on device: {next(model.parameters()).device}")

            input_shapes = {
                'indian_pines': (4, 180, 13, 13),
                'pavia_university': (4, 103, 13, 13),
                'salinas': (4, 204, 13, 13)
            }
            input_shape = input_shapes[dataset_name]

            print_layer_summary(model, input_shape)

            print("\nTesting forward pass...")
            dummy_input = torch.randn(input_shape).to(model.device)
            # [B, 1, C, H, W]
            dummy_input = dummy_input.unsqueeze(1)

            with torch.no_grad():
                output = model(dummy_input)
                print("Forward pass successful!")
                print(f"Input shape: {dummy_input.shape}")
                print(f"Output shape: {output.shape}")

            del model, dummy_input, output
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("Memory cleaned up")

        except Exception as e:
            print(f"Error testing {dataset_name}: {str(e)}")
            traceback.print_exc()

if __name__ == "__main__":
    test_3dcnn()

"""### Hybrid CNN Transformer"""

@dataclass
class HybridConfig:
    """Configuration for Hybrid CNN-Transformer"""
    in_channels: int
    num_classes: int
    spatial_size: int = 13
    cnn_base_filters: int = 32
    transformer_dim: int = 256
    transformer_heads: int = 8
    transformer_layers: int = 4
    dropout_rate: float = 0.5
    use_batch_norm: bool = True
    base_learning_rate: float = 2e-4
    weight_decay: float = 1e-4
    batch_size: int = 32
    num_epochs: int = 100
    patience: int = 15

    def __post_init__(self):
        """Additional initialization after dataclass creation"""
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.dim = self.transformer_dim

class CNNFeatureExtractor(nn.Module):
    """CNN module for local feature extraction"""
    def __init__(self, config: HybridConfig):
        super().__init__()

        self.config = config

        self.conv1 = nn.Sequential(
            nn.Conv2d(config.in_channels, config.cnn_base_filters,
                     kernel_size=3, padding=1),
            nn.BatchNorm2d(config.cnn_base_filters) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        self.conv2 = nn.Sequential(
            nn.Conv2d(config.cnn_base_filters, config.cnn_base_filters * 2,
                     kernel_size=3, padding=1),
            nn.BatchNorm2d(config.cnn_base_filters * 2) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

        self.output_size = (config.cnn_base_filters * 2,
                           config.spatial_size // 4,
                           config.spatial_size // 4)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.conv1(x)
        x = self.conv2(x)
        return x

class TransformerBlock(nn.Module):
    """Transformer block for global context modeling"""
    def __init__(self, config: HybridConfig):
        super().__init__()

        self.norm1 = nn.LayerNorm(config.transformer_dim)
        self.attention = nn.MultiheadAttention(
            embed_dim=config.transformer_dim,
            num_heads=config.transformer_heads,
            dropout=config.dropout_rate,
            batch_first=True
        )

        self.norm2 = nn.LayerNorm(config.transformer_dim)
        self.mlp = nn.Sequential(
            nn.Linear(config.transformer_dim, config.transformer_dim * 4),
            nn.GELU(),
            nn.Dropout(config.dropout_rate),
            nn.Linear(config.transformer_dim * 4, config.transformer_dim),
            nn.Dropout(config.dropout_rate)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        normed = self.norm1(x)
        attended, _ = self.attention(normed, normed, normed)
        x = x + attended

        x = x + self.mlp(self.norm2(x))
        return x

class HybridCNNTransformer(nn.Module):
    """
    Hybrid CNN-Transformer Architecture for Hyperspectral Classification
    Combines CNN for local feature extraction with Transformer for global context
    """
    def __init__(self, config: HybridConfig):
        super().__init__()
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        self.cnn = CNNFeatureExtractor(config)

        cnn_features = (config.cnn_base_filters * 2 *
                       (config.spatial_size // 4) *
                       (config.spatial_size // 4))

        self.projection = nn.Linear(cnn_features, config.transformer_dim)

        self.pos_embedding = nn.Parameter(
            torch.randn(1, 1, config.transformer_dim)
        )

        self.transformer_layers = nn.ModuleList([
            TransformerBlock(config) for _ in range(config.transformer_layers)
        ])

        self.mlp_head = nn.Sequential(
            nn.LayerNorm(config.transformer_dim),
            nn.Linear(config.transformer_dim, config.transformer_dim // 2),
            nn.GELU(),
            nn.Dropout(config.dropout_rate),
            nn.Linear(config.transformer_dim // 2, config.num_classes)
        )

        self.apply(self._init_weights)

        self.shapes = {}

        self.to(self.device)

    def _init_weights(self, m):
        if isinstance(m, (nn.Conv2d, nn.Linear)):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, (nn.BatchNorm2d, nn.LayerNorm)):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = x.to(self.device)

        batch_size = x.shape[0]
        self.shapes['input'] = x.shape

        x = self.cnn(x)
        self.shapes['cnn_features'] = x.shape

        x = x.flatten(1)
        x = self.projection(x)
        x = x.unsqueeze(1)
        self.shapes['projected'] = x.shape

        x = x + self.pos_embedding
        self.shapes['pos_embedded'] = x.shape

        for i, transformer in enumerate(self.transformer_layers):
            x = transformer(x)
            self.shapes[f'transformer_{i}'] = x.shape

        x = x.squeeze(1)
        x = self.mlp_head(x)
        self.shapes['output'] = x.shape

        return x


def create_hybrid_model(dataset_name: str) -> HybridCNNTransformer:
    """Create a Hybrid CNN-Transformer model for a specific dataset"""
    configs = {
        'indian_pines': {
            'in_channels': 180,
            'num_classes': 16
        },
        'pavia_university': {
            'in_channels': 103,
            'num_classes': 9
        },
        'salinas': {
            'in_channels': 204,
            'num_classes': 16
        }
    }

    if dataset_name.lower() not in configs:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    config = configs[dataset_name.lower()]
    return HybridCNNTransformer(HybridConfig(**config))

def print_layer_summary(model: nn.Module, input_shape: tuple):
    """Print detailed layer-by-layer summary with shapes and parameters"""
    print("\nLayer-wise Summary")
    print("=================================================================")
    print(f"{'Layer (type)':<20} {'Output Shape':<30} {'Param #':<10}")
    print("=================================================================")

    def count_params(module):
        return sum(p.numel() for p in module.parameters())

    try:
        x = torch.randn(input_shape).to(model.device)
        _ = model(x)

        print(f"{'input_1':<20} {str(list(input_shape)):<30} {0:<10}")

        cnn_params = count_params(model.cnn.conv1)
        print(f"{'cnn_block1':<20} {str(list(model.shapes['cnn_features'])):<30} {cnn_params:<10}")

        proj_params = count_params(model.projection)
        print(f"{'projection':<20} {str(list(model.shapes['projected'])):<30} {proj_params:<10}")

        for i in range(model.config.transformer_layers):
            transformer_params = count_params(model.transformer_layers[i])
            print(f"{'transformer_'+str(i):<20} {str(list(model.shapes[f'transformer_{i}'])):<30} {transformer_params:<10}")

        mlp_params = count_params(model.mlp_head)
        print(f"{'mlp_head':<20} {str(list(model.shapes['output'])):<30} {mlp_params:<10}")

        total_params = count_params(model)
        print("=================================================================")
        print(f"Total params: {total_params:,}")
        print(f"Trainable params: {total_params:,}")
        print("=================================================================")

    except Exception as e:
        print(f"Error during layer summary: {str(e)}")
        traceback.print_exc()

def test_hybrid_model():
    """Test function for the Hybrid CNN-Transformer model"""
    print("Testing Hybrid CNN-Transformer Model")
    print(f"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")

    for dataset_name in SELECTED_DATASET:
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 50)

        try:
            model = create_hybrid_model(dataset_name)
            print(f"Model created on device: {next(model.parameters()).device}")

            input_shapes = {
                'indian_pines': (4, 180, 13, 13),
                'pavia_university': (4, 103, 13, 13),
                'salinas': (4, 204, 13, 13)
            }
            input_shape = input_shapes[dataset_name]

            print_layer_summary(model, input_shape)

            print("\nTesting forward pass...")
            dummy_input = torch.randn(input_shape).to(model.device)
            with torch.no_grad():
                output = model(dummy_input)
                print("Forward pass successful!")
                print(f"Input shape: {dummy_input.shape}")
                print(f"Output shape: {output.shape}")

            del model, dummy_input, output
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("Memory cleaned up")

        except Exception as e:
            print(f"Error testing {dataset_name}: {str(e)}")
            traceback.print_exc()

if __name__ == "__main__":
    test_hybrid_model()

"""## Segmentation

### U-Net
"""

@dataclass
class UNetConfig:
    """Configuration for Modified U-Net"""
    in_channels: int          # Number of input spectral bands
    num_classes: int          # Number of output classes
    spatial_size: int = 13    # Input spatial dimensions
    base_filters: int = 64    # Number of base filters
    num_levels: int = 2       # Reduced from 4 to 2 for small spatial size
    use_spectral_attention: bool = True
    use_spatial_attention: bool = True
    dropout_rate: float = 0.5
    use_batch_norm: bool = True

    use_deep_supervision: bool = True
    skip_connections: str = 'concat'  # or 'add'
    activation: str = 'relu'  # or 'leaky_relu'

class SpectralAttention(nn.Module):
    """Spectral attention module for hyperspectral features"""
    def __init__(self, channels: int):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // 8),
            nn.ReLU(inplace=True),
            nn.Linear(channels // 8, channels),
            nn.Sigmoid()
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

class SpatialAttention(nn.Module):
    """Spatial attention module"""
    def __init__(self, kernel_size: int = 7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        y = torch.cat([avg_out, max_out], dim=1)
        y = torch.sigmoid(self.conv(y))
        return x * y

class DoubleConv(nn.Module):
    """Modified double convolution block with same padding"""
    def __init__(self, in_channels: int, out_channels: int, config: UNetConfig):
        super().__init__()
        self.debug_mode = False

        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding='same'),
            nn.BatchNorm2d(out_channels) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding='same'),
            nn.BatchNorm2d(out_channels) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(inplace=True)
        )

        self.spectral_attention = (SpectralAttention(out_channels)
                                 if config.use_spectral_attention else None)
        self.spatial_attention = (SpatialAttention()
                                if config.use_spatial_attention else None)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.conv(x)
        if self.spectral_attention:
            x = self.spectral_attention(x)
        if self.spatial_attention:
            x = self.spatial_attention(x)
        return x

class Down(nn.Module):
    """Modified downsampling block"""
    def __init__(self, in_channels: int, out_channels: int, config: UNetConfig):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2, stride=2),
            DoubleConv(in_channels, out_channels, config)
        )
        self.debug_mode = False

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.maxpool_conv(x)
        if self.debug_mode:
            print(f"Down block output shape: {x.shape}")
        return x

class Up(nn.Module):
    """Modified upsampling block with proper size handling"""
    def __init__(self, in_channels: int, out_channels: int, config: UNetConfig):
        super().__init__()
        self.debug_mode = False
        self.up = nn.Upsample(size=None, scale_factor=2, mode='bilinear', align_corners=True)
        self.conv = DoubleConv(in_channels + out_channels, out_channels, config)

    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:
        x1 = self.up(x1)

        if self.debug_mode:
            print(f"\nUp layer input shapes:")
            print(f"x1 (from previous layer): {x1.shape}")
            print(f"x2 (skip connection): {x2.shape}")
            print(f"After upsampling: {x1.shape}")

        if x1.shape[-2:] != x2.shape[-2:]:
            x1 = F.interpolate(x1, size=x2.shape[-2:],
                             mode='bilinear', align_corners=True)
            if self.debug_mode:
                print(f"After resizing: {x1.shape}")

        x = torch.cat([x2, x1], dim=1)
        if self.debug_mode:
            print(f"After concatenation: {x.shape}")

        return self.conv(x)

    def print_debug_shapes(self, x1: torch.Tensor, x2: torch.Tensor, layer_name: str):
        """Debug helper to print shapes during forward pass"""
        if hasattr(self, 'debug') and self.debug:
            print(f"\n{layer_name} shapes:")
            print(f"x1 shape: {x1.shape}")
            print(f"x2 shape: {x2.shape}")

class HyperspectralUNet(nn.Module):
    """Modified U-Net for Hyperspectral Image Segmentation"""
    def __init__(self, config: UNetConfig):
        super().__init__()
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.shapes = {}

        self.spectral_reduction = nn.Sequential(
            nn.Conv2d(config.in_channels, config.base_filters,
                    kernel_size=1, padding=0),
            nn.BatchNorm2d(config.base_filters) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(inplace=True)
        )

        self.inc = DoubleConv(config.base_filters, config.base_filters, config)

        channels = [config.base_filters]

        self.down_layers = nn.ModuleList()
        current_channels = config.base_filters
        for _ in range(config.num_levels):
            out_channels = current_channels * 2
            self.down_layers.append(
                Down(current_channels, out_channels, config)
            )
            current_channels = out_channels
            channels.append(current_channels)

        self.up_layers = nn.ModuleList()
        for i in range(config.num_levels):
            in_ch = channels[-1-i]
            out_ch = channels[-2-i]
            self.up_layers.append(
                Up(in_ch, out_ch, config)
            )

        self.outc = nn.Conv2d(config.base_filters, config.num_classes,
                            kernel_size=1, padding=0)

        self.apply(self._init_weights)

        self.to(self.device)

        self.debug_mode = False

    def _init_weights(self, m):
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.BatchNorm2d):
            nn.init.constant_(m.weight, 1)
            nn.init.constant_(m.bias, 0)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass with shape tracking"""
        x = x.to(self.device)

        self.shapes['input'] = x.shape

        x = self.spectral_reduction(x)
        self.shapes['spectral_reduction'] = x.shape

        x = self.inc(x)
        self.shapes['initial_conv'] = x.shape

        encoder_features = []
        for i, down in enumerate(self.down_layers):
            encoder_features.append(x)
            x = down(x)
            self.shapes[f'down_{i}'] = x.shape

        for i, up in enumerate(self.up_layers):
            x = up(x, encoder_features[-i-1])
            self.shapes[f'up_{i}'] = x.shape

        x = self.outc(x)
        self.shapes['output'] = x.shape

        return x

def create_unet_model(dataset_name: str) -> HyperspectralUNet:
    """Create a U-Net model instance for a specific dataset"""
    dataset_configs = {
        'indian_pines': UNetConfig(
            in_channels=180,
            num_classes=16,
            spatial_size=13
        ),
        'pavia_university': UNetConfig(
            in_channels=103,
            num_classes=9,
            spatial_size=13
        ),
        'salinas': UNetConfig(
            in_channels=204,
            num_classes=16,
            spatial_size=13
        )
    }

    if dataset_name.lower() not in dataset_configs:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    return HyperspectralUNet(dataset_configs[dataset_name.lower()])

def print_layer_summary(model: nn.Module, input_shape: tuple):
    """Print detailed layer-by-layer summary with shapes and parameters"""
    try:
        x = torch.randn(input_shape).to(model.device)

        model.shapes = {}
        model.shapes['input'] = input_shape

        with torch.no_grad():
            _ = model(x)

        name_width = 45
        shape_width = 30
        params_width = 15
        total_width = name_width + shape_width + params_width

        print("\nLayer-wise Summary")
        print("=" * total_width)
        header = (f"{'Layer (type)':<{name_width}}"
                 f"{'Output Shape':<{shape_width}}"
                 f"{'Param #':>{params_width}}")
        print(header)
        print("=" * total_width)

        def count_params(module):
            return sum(p.numel() for p in module.parameters())

        layer_info = []

        layer_info.append(('Input Layer', 'Input', model.shapes['input'], 0))

        if 'spectral_reduction' in model.shapes:
            layer_info.append((
                'Spectral Reduction',
                'Conv2d',
                model.shapes['spectral_reduction'],
                count_params(model.spectral_reduction)
            ))

        if 'initial_conv' in model.shapes:
            layer_info.append((
                'Initial Conv Block',
                'DoubleConv',
                model.shapes['initial_conv'],
                count_params(model.inc)
            ))

        for i in range(len(model.down_layers)):
            if f'down_{i}' in model.shapes:
                layer_info.append((
                    f'Encoder Block {i+1}',
                    'MaxPool+DoubleConv',
                    model.shapes[f'down_{i}'],
                    count_params(model.down_layers[i])
                ))

        for i in range(len(model.up_layers)):
            if f'up_{i}' in model.shapes:
                layer_info.append((
                    f'Decoder Block {i+1}',
                    'Upsample+DoubleConv',
                    model.shapes[f'up_{i}'],
                    count_params(model.up_layers[i])
                ))

        if 'output' in model.shapes:
            layer_info.append((
                'Output Layer',
                'Conv2d',
                model.shapes['output'],
                count_params(model.outc)
            ))

        for name, type_name, shape, params in layer_info:
            layer_name = f"{name} ({type_name})"
            shape_str = str(list(shape))
            print(f"{layer_name:<{name_width}}{shape_str:<{shape_width}}{params:>{params_width},}")

        print("=" * total_width)
        total_params = sum(params for _, _, _, params in layer_info)
        print(f"Total Parameters:{total_params:>{total_width-17},}")
        print(f"Trainable Parameters:{total_params:>{total_width-21},}")
        print(f"Non-trainable Parameters:{0:>{total_width-25},}")
        print("=" * total_width)

        info_width = total_width
        print("\nModel Information:")
        print("-" * info_width)
        info = [
            ("Number of Encoder Blocks:", len(model.down_layers)),
            ("Number of Decoder Blocks:", len(model.up_layers)),
            ("Input Channels:", model.config.in_channels),
            ("Output Classes:", model.config.num_classes),
            ("Base Filters:", model.config.base_filters),
            ("Using Batch Norm:", model.config.use_batch_norm),
            ("Using Spectral Attention:", model.config.use_spectral_attention),
            ("Using Spatial Attention:", model.config.use_spatial_attention)
        ]

        max_label_width = max(len(label) for label, _ in info)

        for label, value in info:
            print(f"{label:<{max_label_width + 5}}{value}")
        print("=" * info_width)

    except Exception as e:
        print(f"Error in print_layer_summary: {str(e)}")
        traceback.print_exc()

def test_unet_model():
    """Test function for the U-Net model"""
    print("Testing U-Net Model")
    print(f"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")

    for dataset_name in SELECTED_DATASET:
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 50)

        try:
            model = create_unet_model(dataset_name)
            print(f"Model created on device: {next(model.parameters()).device}")

            input_shapes = {
                'indian_pines': (4, 180, 13, 13),
                'pavia_university': (4, 103, 13, 13),
                'salinas': (4, 204, 13, 13)
            }
            input_shape = input_shapes[dataset_name]

            print_layer_summary(model, input_shape)

            print("\nTesting forward pass...")
            dummy_input = torch.randn(input_shape).to(model.device)
            with torch.no_grad():
                output = model(dummy_input)
                print("Forward pass successful!")
                print(f"Input shape: {dummy_input.shape}")
                print(f"Output shape: {output.shape}")

            del model, dummy_input, output
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("Memory cleaned up")

        except Exception as e:
            print(f"Error testing {dataset_name}: {str(e)}")
            traceback.print_exc()

if __name__ == "__main__":
    test_unet_model()

"""### 3D U-Net"""

@dataclass
class UNet3DConfig:
    """Configuration for 3D U-Net Architecture"""
    in_channels: int          # Number of input spectral bands
    num_classes: int          # Number of output classes
    spatial_size: int = 13    # Input spatial dimensions (assumed square)
    base_filters: int = 16    # Number of base filters (reduced for memory efficiency)
    num_levels: int = 2       # Number of down/up-sampling levels
    dropout_rate: float = 0.3
    use_batch_norm: bool = True
    use_spectral_attention: bool = True
    spectral_kernel_size: int = 3  # Kernel size for spectral dimension

class SpectralAttention3D(nn.Module):
    """
    3D Spectral Attention Module
    Learns channel-wise attention weights for spectral bands
    """
    def __init__(self, channels: int):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool3d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // 8),
            nn.ReLU(inplace=True),
            nn.Linear(channels // 8, channels),
            nn.Sigmoid()
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        b, c, d, h, w = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1, 1)
        return x * y.expand_as(x)

class DoubleConv3D(nn.Module):
    """
    Double 3D Convolution Block
    Two sequential 3D convolutions with optional batch normalization and attention
    """
    def __init__(self, in_channels: int, out_channels: int, config: UNet3DConfig):
        super().__init__()

        self.conv = nn.Sequential(
            nn.Conv3d(in_channels, out_channels,
                     kernel_size=3, padding=1),
            nn.BatchNorm3d(out_channels) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(inplace=True),
            nn.Conv3d(out_channels, out_channels,
                     kernel_size=3, padding=1),
            nn.BatchNorm3d(out_channels) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(inplace=True)
        )

        self.attention = (SpectralAttention3D(out_channels)
                         if config.use_spectral_attention else None)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.conv(x)
        if self.attention is not None:
            x = self.attention(x)
        return x

class Down3D(nn.Module):
    """
    3D Downsampling Block
    Max pooling followed by double convolution
    """
    def __init__(self, in_channels: int, out_channels: int, config: UNet3DConfig):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool3d(2),
            DoubleConv3D(in_channels, out_channels, config)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.maxpool_conv(x)

class Up3D(nn.Module):
    """
    3D Upsampling Block
    Upsampling followed by double convolution
    """
    def __init__(self, in_channels: int, out_channels: int, config: UNet3DConfig):
        super().__init__()

        self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)

        self.conv = DoubleConv3D(in_channels + out_channels, out_channels, config)

    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:
        x1 = self.up(x1)

        diff_z = x2.size()[2] - x1.size()[2]
        diff_y = x2.size()[3] - x1.size()[3]
        diff_x = x2.size()[4] - x1.size()[4]

        x1 = F.pad(x1, [diff_x // 2, diff_x - diff_x // 2,
                       diff_y // 2, diff_y - diff_y // 2,
                       diff_z // 2, diff_z - diff_z // 2])

        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)

class HyperspectralUNet3D(nn.Module):
    """
    3D U-Net Architecture for Hyperspectral Image Segmentation
    Processes data in full 3D (spectral + spatial dimensions)
    """
    def __init__(self, config: UNet3DConfig):
        super().__init__()
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.shapes = {}

        self.inc = DoubleConv3D(1, config.base_filters, config)

        self.down_layers = nn.ModuleList()
        current_filters = config.base_filters
        for _ in range(config.num_levels):
            out_filters = current_filters * 2
            self.down_layers.append(Down3D(current_filters, out_filters, config))
            current_filters = out_filters

        self.up_layers = nn.ModuleList()
        for _ in range(config.num_levels):
            self.up_layers.append(Up3D(current_filters, current_filters // 2, config))
            current_filters //= 2

        self.outc = nn.Conv3d(config.base_filters, config.num_classes, kernel_size=1)

        self._initialize_weights()

        self.to(self.device)

    def _initialize_weights(self):
        """Initialize model weights using Kaiming initialization"""
        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm3d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass with shape tracking
        Args:
            x: Input tensor of shape (batch_size, channels, depth, height, width)
        """
        x = x.to(self.device)

        self.shapes = {}

        self.shapes['input'] = x.shape

        x = x.unsqueeze(1)  # (batch, 1, channels, height, width)
        self.shapes['input_3d'] = x.shape

        x = self.inc(x)
        self.shapes['initial_conv'] = x.shape

        encoder_features = []
        for i, down in enumerate(self.down_layers):
            encoder_features.append(x)
            self.shapes[f'encoder_{i}'] = x.shape
            x = down(x)
            self.shapes[f'down_{i}'] = x.shape

        for i, up in enumerate(self.up_layers):
            x = up(x, encoder_features[-i-1])
            self.shapes[f'up_{i}'] = x.shape

        x = self.outc(x)
        self.shapes['output'] = x.shape

        x = x.squeeze(2)
        self.shapes['final_output'] = x.shape

        return x

def create_3dunet_model(dataset_name: str) -> HyperspectralUNet3D:
    """Create a 3D U-Net model instance for a specific dataset"""
    dataset_configs = {
        'indian_pines': UNet3DConfig(
            in_channels=180,
            num_classes=16,
            spatial_size=13
        ),
        'pavia_university': UNet3DConfig(
            in_channels=103,
            num_classes=9,
            spatial_size=13
        ),
        'salinas': UNet3DConfig(
            in_channels=204,
            num_classes=16,
            spatial_size=13
        )
    }

    if dataset_name.lower() not in dataset_configs:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    return HyperspectralUNet3D(dataset_configs[dataset_name.lower()])

def print_3dunet_summary(model: nn.Module, input_shape: tuple):
    """Print detailed layer-by-layer summary of 3D U-Net"""
    def count_params(module):
        return sum(p.numel() for p in module.parameters())

    try:
        x = torch.randn(input_shape).to(model.device)
        _ = model(x)

        print("\n3D U-Net Architecture Summary")
        print("=" * 80)
        print(f"{'Layer (type)':<30} {'Output Shape':<30} {'Param #':<10}")
        print("=" * 80)

        print(f"{'Input':<30} {str(list(model.shapes['input'])):<30} {0:<10}")

        print(f"{'Initial Conv (DoubleConv3D)':<30} "
              f"{str(list(model.shapes['initial_conv'])):<30} "
              f"{count_params(model.inc):<10}")

        for i in range(len(model.down_layers)):
            print(f"{'Encoder Block '+str(i+1):<30} "
                  f"{str(list(model.shapes[f'down_{i}'])):<30} "
                  f"{count_params(model.down_layers[i]):<10}")

        for i in range(len(model.up_layers)):
            print(f"{'Decoder Block '+str(i+1):<30} "
                  f"{str(list(model.shapes[f'up_{i}'])):<30} "
                  f"{count_params(model.up_layers[i]):<10}")

        print(f"{'Output Conv':<30} "
              f"{str(list(model.shapes['final_output'])):<30} "
              f"{count_params(model.outc):<10}")

        total_params = count_params(model)
        print("=" * 80)
        print(f"Total Parameters: {total_params:,}")
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"Trainable Parameters: {trainable_params:,}")
        print("=" * 80)

    except Exception as e:
        print(f"Error during summary generation: {str(e)}")
        traceback.print_exc()


def test_3dunet_model():
    """Test function for the 3D U-Net model"""
    print("Testing 3D U-Net Model")
    print(f"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")

    for dataset_name in SELECTED_DATASET:
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 50)

        try:
            model = create_3dunet_model(dataset_name)
            print(f"Model created on device: {next(model.parameters()).device}")

            input_shapes = {
                'indian_pines': (4, 180, 13, 13),
                'pavia_university': (4, 103, 13, 13),
                'salinas': (4, 204, 13, 13)
            }
            input_shape = input_shapes[dataset_name]

            print_3dunet_summary(model, input_shape)

            print("\nTesting forward pass...")
            dummy_input = torch.randn(input_shape).to(model.device)
            with torch.no_grad():
                output = model(dummy_input)
                print("Forward pass successful!")
                print(f"Input shape: {dummy_input.shape}")
                print(f"Output shape: {output.shape}")

            if torch.cuda.is_available():
                print("\nGPU Memory Usage:")
                print(f"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
                print(f"Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB")

            del model, dummy_input, output
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("Memory cleaned up")

        except Exception as e:
            print(f"Error testing {dataset_name}: {str(e)}")
            traceback.print_exc()

if __name__ == "__main__":
    test_3dunet_model()

"""### FCN with spectral attention"""

@dataclass
class FCNConfig:
    """Configuration for FCN with Spectral Attention"""
    in_channels: int          # Number of input spectral bands
    num_classes: int          # Number of output classes
    spatial_size: int = 13    # Input spatial dimensions (assumed square)
    base_filters: int = 64    # Number of base filters
    dropout_rate: float = 0.3
    use_batch_norm: bool = True
    use_spectral_attention: bool = True
    backbone: str = 'resnet18'  # Backbone network type
    pretrained: bool = False    # Whether to use pretrained backbone

class SpectralAttentionModule(nn.Module):
    """
    Spectral Attention Module for FCN
    Learns attention weights for different spectral bands
    """
    def __init__(self, in_channels: int, reduction_ratio: int = 16):
        super().__init__()

        reduced_channels = max(in_channels // reduction_ratio, 8)

        self.attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(in_channels, reduced_channels, 1, bias=False),
            nn.BatchNorm2d(reduced_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(reduced_channels, in_channels, 1, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.Sigmoid()
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        att = self.attention(x)
        return x * att

class ConvBlock(nn.Module):
    """
    Modified convolutional block with spatial dimension preservation
    """
    def __init__(self, in_channels: int, out_channels: int, config: FCNConfig):
        super().__init__()

        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels,
                     kernel_size=3, padding=1, stride=1),
            nn.BatchNorm2d(out_channels) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(inplace=True)
        )

        self.attention = (SpectralAttentionModule(out_channels)
                         if config.use_spectral_attention else None)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.conv(x)
        if self.attention is not None:
            x = self.attention(x)
        return x

class EncoderBlock(nn.Module):
    """
    Modified Encoder block with spatial dimension handling
    """
    def __init__(self, in_channels: int, out_channels: int, config: FCNConfig):
        super().__init__()

        self.block = nn.Sequential(
            ConvBlock(in_channels, out_channels, config),
            ConvBlock(out_channels, out_channels, config),
            nn.Conv2d(out_channels, out_channels, kernel_size=3,
                     stride=2, padding=1, bias=False),
            nn.BatchNorm2d(out_channels) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(inplace=True)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.block(x)

class DecoderBlock(nn.Module):
    """
    Modified Decoder block with improved spatial handling
    """
    def __init__(self, in_channels: int, out_channels: int, config: FCNConfig):
        super().__init__()

        self.upsample = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=1),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        )

        self.conv = ConvBlock(out_channels * 2, out_channels, config)

    def forward(self, x: torch.Tensor, skip: torch.Tensor) -> torch.Tensor:
        x = self.upsample(x)

        target_size = skip.shape[-2:]
        if x.shape[-2:] != target_size:
            x = F.interpolate(x, size=target_size,
                            mode='bilinear', align_corners=True)

        x = torch.cat([x, skip], dim=1)
        return self.conv(x)

class SpectralFCN(nn.Module):
    """
    Revised FCN with careful spatial dimension handling
    """
    def __init__(self, config: FCNConfig):
        super().__init__()
        self.config = config
        self.shapes = {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        self.spectral_conv = nn.Sequential(
            nn.Conv2d(config.in_channels, config.base_filters,
                     kernel_size=1, bias=False),
            nn.BatchNorm2d(config.base_filters) if config.use_batch_norm else nn.Identity(),
            nn.ReLU(inplace=True)
        )

        self.enc1 = nn.Sequential(
            ConvBlock(config.base_filters, config.base_filters * 2, config),
            nn.Conv2d(config.base_filters * 2, config.base_filters * 2,
                     kernel_size=3, padding=1, stride=1)
        )

        self.enc2 = nn.Sequential(
            ConvBlock(config.base_filters * 2, config.base_filters * 4, config),
            nn.Conv2d(config.base_filters * 4, config.base_filters * 4,
                     kernel_size=3, padding=1, stride=1)
        )

        self.bridge = ConvBlock(config.base_filters * 4, config.base_filters * 8, config)

        self.dec2 = nn.Sequential(
            nn.Conv2d(config.base_filters * 8, config.base_filters * 4,
                     kernel_size=1),
            ConvBlock(config.base_filters * 4, config.base_filters * 4, config)
        )

        self.dec1 = nn.Sequential(
            nn.Conv2d(config.base_filters * 4, config.base_filters * 2,
                     kernel_size=1),
            ConvBlock(config.base_filters * 2, config.base_filters * 2, config)
        )

        self.final_conv = nn.Sequential(
            nn.Conv2d(config.base_filters * 2, config.num_classes,
                     kernel_size=1),
            nn.Dropout2d(config.dropout_rate)
        )

        self._initialize_weights()

        self.to(self.device)

    def _initialize_weights(self):
        """Initialize network weights"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass with shape tracking"""
        x = x.to(self.device)

        self.shapes = {}
        self.shapes['input'] = x.shape

        x = self.spectral_conv(x)
        self.shapes['spectral_conv'] = x.shape

        skip1 = self.enc1(x)
        self.shapes['enc1'] = skip1.shape

        skip2 = self.enc2(skip1)
        self.shapes['enc2'] = skip2.shape

        x = self.bridge(skip2)
        self.shapes['bridge'] = x.shape

        x = self.dec2(x)
        self.shapes['dec2'] = x.shape

        x = self.dec1(x)
        self.shapes['dec1'] = x.shape

        x = self.final_conv(x)
        self.shapes['output'] = x.shape

        return x

def create_fcn_model(dataset_name: str) -> SpectralFCN:
    """Create an FCN model instance for a specific dataset"""
    dataset_configs = {
        'indian_pines': FCNConfig(
            in_channels=180,
            num_classes=16,
            spatial_size=13
        ),
        'pavia_university': FCNConfig(
            in_channels=103,
            num_classes=9,
            spatial_size=13
        ),
        'salinas': FCNConfig(
            in_channels=204,
            num_classes=16,
            spatial_size=13
        )
    }

    if dataset_name.lower() not in dataset_configs:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    return SpectralFCN(dataset_configs[dataset_name.lower()])

def print_fcn_summary(model: nn.Module, input_shape: tuple):
    """Print concise layer-by-layer summary of FCN"""
    def count_params(module):
        return sum(p.numel() for p in module.parameters())

    try:
        x = torch.randn(input_shape).to(model.device)
        _ = model(x)

        print("\nFCN with Spectral Attention Architecture Summary")
        print("=" * 80)
        print(f"{'Layer (type)':<30} {'Output Shape':<30} {'Param #':<10}")
        print("=" * 80)

        layers_info = [
            ('Input', model.shapes['input'], 0),
            ('Spectral Conv', model.shapes['spectral_conv'], count_params(model.spectral_conv)),
            ('Encoder Block 1', model.shapes['enc1'], count_params(model.enc1)),
            ('Encoder Block 2', model.shapes['enc2'], count_params(model.enc2)),
            ('Bridge Block', model.shapes['bridge'], count_params(model.bridge)),
            ('Decoder Block 2', model.shapes['dec2'], count_params(model.dec2)),
            ('Decoder Block 1', model.shapes['dec1'], count_params(model.dec1)),
            ('Output Conv', model.shapes['output'], count_params(model.final_conv))
        ]

        for name, shape, params in layers_info:
            print(f"{name:<30} {str(list(shape)):<30} {params:>10}")

        print("=" * 80)
        total_params = count_params(model)
        print(f"Total Parameters: {total_params:,}")
        print(f"Trainable Parameters: {total_params:,}")
        print("=" * 80)

    except Exception as e:
        print(f"Error during summary generation: {str(e)}")
        traceback.print_exc()

def test_fcn_model():
    """Test function for FCN model"""
    print("Testing FCN with Spectral Attention")
    print(f"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")

    for dataset_name in SELECTED_DATASET:
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 55)

        try:
            model = create_fcn_model(dataset_name)
            print(f"Model created on device: {next(model.parameters()).device}")

            input_shapes = {
                'indian_pines': (4, 180, 13, 13),
                'pavia_university': (4, 103, 13, 13),
                'salinas': (4, 204, 13, 13)
            }
            input_shape = input_shapes[dataset_name]

            print_fcn_summary(model, input_shape)

            print("\nTesting forward pass...")
            dummy_input = torch.randn(input_shape).to(model.device)
            with torch.no_grad():
                output = model(dummy_input)
                print("Forward pass successful!")
                print(f"Input shape: {dummy_input.shape}")
                print(f"Output shape: {output.shape}")

            if torch.cuda.is_available():
                print("\nGPU Memory Usage:")
                print(f"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
                print(f"Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB")

            del model, dummy_input, output
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                print("Memory cleaned up")

        except Exception as e:
            print(f"Error testing {dataset_name}: {str(e)}")
            traceback.print_exc()

if __name__ == "__main__":
    test_fcn_model()

"""# **6.Training Pipeline Implementation**

## Loss Functions

### Cross-entropy with class weights
"""

class WeightedCrossEntropyLoss(nn.Module):
    """
    Cross Entropy Loss with class weights for handling class imbalance
    in hyperspectral image classification/segmentation
    """
    def __init__(self,
                 num_classes: int,
                 weight_mode: str = 'balanced',
                 weight_power: float = 1.0,
                 ignore_index: int = -100,
                 reduction: str = 'mean',
                 device: Optional[torch.device] = None):
        """Initialize weighted cross entropy loss"""
        super().__init__()
        self.num_classes = num_classes
        self.weight_mode = weight_mode
        self.weight_power = weight_power
        self.ignore_index = ignore_index
        self.reduction = reduction
        self.device = device if device is not None else torch.device('cpu')
        self.register_buffer('class_weights', None)
        self.reset_metrics()

    def compute_class_weights(self, target: torch.Tensor) -> torch.Tensor:
        """Compute class weights based on class frequencies"""
        target = target.view(-1)
        valid_mask = target != self.ignore_index
        valid_target = target[valid_mask]

        class_counts = torch.bincount(valid_target.long(), minlength=self.num_classes)
        class_counts = class_counts.float()
        class_counts[class_counts == 0] = 1

        if self.weight_mode == 'balanced':
            weights = 1.0 / class_counts
        elif self.weight_mode == 'sqrt_balanced':
            weights = 1.0 / torch.sqrt(class_counts)
        elif self.weight_mode == 'log_balanced':
            weights = 1.0 / torch.log1p(class_counts)
        else:
            raise ValueError(f"Unknown weight mode: {self.weight_mode}")

        weights = weights ** self.weight_power
        weights = weights / weights.sum() * self.num_classes

        return weights.to(self.device)


    def update_class_weights(self, target: torch.Tensor):
        """Update class weights using current batch"""
        self.class_weights = self.compute_class_weights(target)

    def reset_metrics(self):
        """Reset tracking metrics"""
        self.total_loss = 0.0
        self.num_batches = 0
        self.class_losses = torch.zeros(self.num_classes, device=self.device)
        self.class_counts = torch.zeros(self.num_classes, device=self.device)

    def update_metrics(self, loss: torch.Tensor, target: torch.Tensor, logits: torch.Tensor):
        """Update metrics with current batch results"""
        batch_loss = loss.item() if self.reduction == 'mean' else loss.item() / target.numel()
        self.total_loss += batch_loss
        self.num_batches += 1

        if len(target.shape) > 1:
            target = target.argmax(dim=1)
        target = target.long()

        probs = F.softmax(logits, dim=1)
        log_probs = F.log_softmax(logits, dim=1)

        for c in range(self.num_classes):
            class_mask = target == c
            if class_mask.any():
                class_loss = -(probs[:, c] * log_probs[:, c])[class_mask].mean()
                self.class_losses[c] += class_loss.item()
                self.class_counts[c] += class_mask.sum().item()

    def get_metrics(self) -> Dict[str, Union[float, torch.Tensor]]:
        """Get current metrics"""
        metrics = {
            'avg_loss': self.total_loss / max(self.num_batches, 1)
        }

        for c in range(self.num_classes):
            count = self.class_counts[c].item()
            if count > 0:
                metrics[f'class_{c}_loss'] = self.class_losses[c].item() / count
            else:
                metrics[f'class_{c}_loss'] = 0.0

        if self.class_weights is not None:
            metrics['class_weights'] = self.class_weights

        return metrics

    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """Forward pass with proper shape handling"""
        if logits.device != target.device:
            target = target.to(logits.device)

        if self.class_weights is None or self.training:
            self.update_class_weights(target)
            self.class_weights = self.class_weights.to(logits.device)

        target = target.view(-1) if target.dim() > 1 else target
        target = target.long()

        if target.numel() == 0:
            return torch.tensor(0.0, device=logits.device, requires_grad=True)

        if logits.dim() == 4:  # [N, C, H, W]
            logits = logits.permute(0, 2, 3, 1).reshape(-1, logits.size(1))

        loss = F.cross_entropy(
            logits,
            target,
            weight=self.class_weights,
            ignore_index=self.ignore_index,
            reduction=self.reduction
        )

        if self.training:
            self.update_metrics(loss, target, logits)

        return loss

def get_dataset_weights(dataset_name: str) -> torch.Tensor:
    """
    Get predefined class weights for specific datasets

    Args:
        dataset_name: Name of the dataset

    Returns:
        Tensor of class weights
    """
    weights = {
        'indian_pines': torch.tensor([
            1.0, 2.0, 1.5, 1.5, 2.0, 1.5, 1.5, 2.0,
            1.5, 2.0, 1.5, 1.5, 2.0, 2.0, 1.5, 2.0
        ]),
        'pavia_university': torch.tensor([
            1.0, 1.5, 1.0, 2.0, 2.0, 2.0, 1.5, 2.0, 2.0
        ]),
        'salinas': torch.tensor([
            1.0, 2.0, 2.0, 1.5, 2.0, 1.5, 1.5, 1.5,
            1.5, 1.5, 2.0, 2.0, 2.0, 2.0, 1.5, 2.0
        ])
    }

    if dataset_name.lower() not in weights:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    return weights[dataset_name.lower()]

def print_metrics_table(metrics: Dict[str, float], weights: torch.Tensor, dataset_name: str):
    """
    Print metrics and weights in a formatted table

    Args:
        metrics: Dictionary of metrics
        weights: Class weights tensor
        dataset_name: Name of the dataset
    """
    print(f"\nResults for {dataset_name.upper()}")
    print("=" * 80)
    print(f"Overall Cross Entropy Loss: {metrics['avg_loss']:.4f}")
    print("=" * 80)

    print(f"{'Class':<8} {'Class Loss':<15} {'Class Weight':<15} {'Weighted Loss':<15}")
    print("-" * 80)

    for class_idx in range(len(weights)):
        class_loss = metrics[f'class_{class_idx}_loss']
        weight = weights[class_idx].item()
        weighted_loss = class_loss * weight

        print(f"{class_idx:<8} "
              f"{class_loss:>12.4f}   "
              f"{weight:>12.4f}   "
              f"{weighted_loss:>12.4f}")

    print("-" * 80)

def test_weighted_loss():
    """Test the weighted cross entropy loss implementation"""
    print("Testing Weighted Cross Entropy Loss Implementation")
    print("=" * 80)

    test_configs = {
        'indian_pines': {'num_classes': 16, 'shape': (4, 16, 13, 13)},
        'pavia_university': {'num_classes': 9, 'shape': (4, 9, 13, 13)},
        'salinas': {'num_classes': 16, 'shape': (4, 16, 13, 13)}
    }

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    for dataset_name, config in test_configs.items():
        try:
            print(f"\nTesting {dataset_name.upper()}")
            print("-" * 50)

            criterion = WeightedCrossEntropyLoss(
                num_classes=config['num_classes'],
                weight_mode='balanced',
                device=device
            ).to(device)

            batch_size, num_classes, height, width = config['shape']

            logits = torch.randn(batch_size, num_classes, height, width).to(device)

            target = torch.randint(0, num_classes, (batch_size, height, width)).to(device)

            print(f"Logits shape: {logits.shape}")
            print(f"Target shape: {target.shape}")

            loss = criterion(logits, target)
            print(f"Loss value: {loss.item():.4f}")

            metrics = criterion.get_metrics()
            print_metrics_table(metrics, criterion.class_weights, dataset_name)

        except Exception as e:
            print(f"\nError testing {dataset_name}: {str(e)}")
            traceback.print_exc()

if __name__ == "__main__":
    test_weighted_loss()

"""### Dice loss for segmentation"""

class DiceLoss(nn.Module):
    """Dice Loss for segmentation with proper tensor type handling"""
    def __init__(self,
                 num_classes: int,
                 smooth: float = 1.0,
                 weight_mode: str = 'balanced',
                 ignore_index: int = -100,
                 reduction: str = 'mean',
                 device: Optional[torch.device] = None):
        super().__init__()
        self.num_classes = num_classes
        self.smooth = smooth
        self.weight_mode = weight_mode
        self.ignore_index = ignore_index
        self.reduction = reduction
        self.device = device if device is not None else torch.device('cpu')
        self.register_buffer('class_weights', None)
        self.reset_metrics()

    def compute_weights(self, target: torch.Tensor) -> torch.Tensor:
        """Compute class weights with proper tensor type conversion"""
        valid_mask = target != self.ignore_index
        valid_target = target[valid_mask].long()

        class_counts = torch.bincount(valid_target.view(-1), minlength=self.num_classes)
        class_counts = class_counts.float()
        class_counts[class_counts == 0] = 1

        if self.weight_mode == 'balanced':
            weights = 1.0 / class_counts
        elif self.weight_mode == 'sqrt_balanced':
            weights = 1.0 / torch.sqrt(class_counts)
        else:  # 'uniform'
            weights = torch.ones_like(class_counts)

        weights = weights / weights.sum() * self.num_classes
        return weights.to(self.device)

    def compute_dice_coefficient(self, pred: torch.Tensor, target: torch.Tensor, class_idx: int) -> torch.Tensor:
        """Fixed Dice coefficient computation"""
        pred_mask = pred[:, class_idx]  # [B, H, W]
        target_mask = (target == class_idx).float()

        if pred_mask.shape != target_mask.shape:
            target_mask = target_mask.view(pred_mask.shape)

        intersection = (pred_mask * target_mask).sum()
        cardinality_pred = pred_mask.sum()
        cardinality_target = target_mask.sum()

        dice = (2. * intersection + self.smooth) / (cardinality_pred + cardinality_target + self.smooth)
        return dice

    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """Fixed forward pass"""
        target = target.long()

        if self.class_weights is None or self.training:
            self.class_weights = self.compute_weights(target)

        pred = F.softmax(logits, dim=1)

        dice_loss = 0.0
        n_valid_classes = 0

        for class_idx in range(self.num_classes):
            target_reshaped = target.view(target.size(0), -1)
            if (target_reshaped == class_idx).any():
                dice_coeff = self.compute_dice_coefficient(pred, target, class_idx)
                weighted_dice = self.class_weights[class_idx] * (1 - dice_coeff)
                dice_loss += weighted_dice
                n_valid_classes += 1

                if self.training:
                    self.update_class_metrics(class_idx, dice_coeff.item())

        if n_valid_classes > 0 and self.reduction == 'mean':
            dice_loss = dice_loss / n_valid_classes

        if self.training:
            self.total_loss += dice_loss.item()
            self.num_batches += 1

        return dice_loss

    def reset_metrics(self):
        """Reset tracking metrics"""
        self.total_loss = 0.0
        self.num_batches = 0
        self.class_dice = torch.zeros(self.num_classes, device=self.device)
        self.class_counts = torch.zeros(self.num_classes, device=self.device)

    def update_class_metrics(self, class_idx: int, dice_coeff: float):
        """Update metrics for a specific class"""
        self.class_dice[class_idx] += dice_coeff
        self.class_counts[class_idx] += 1

    def get_metrics(self) -> Dict[str, Union[float, torch.Tensor]]:
        """Get current metrics"""
        metrics = {
            'avg_loss': self.total_loss / max(self.num_batches, 1)
        }

        for c in range(self.num_classes):
            count = self.class_counts[c].item()
            if count > 0:
                metrics[f'class_{c}_dice'] = self.class_dice[c].item() / count
            else:
                metrics[f'class_{c}_dice'] = 0.0

        valid_dice = [v for k, v in metrics.items() if k.startswith('class_') and v > 0]
        if valid_dice:
            metrics['mean_dice'] = sum(valid_dice) / len(valid_dice)
        else:
            metrics['mean_dice'] = 0.0

        return metrics

def print_metrics_table(metrics: Dict[str, float], weights: torch.Tensor, dataset_name: str):
    """
    Print metrics and weights in a formatted table

    Args:
        metrics: Dictionary of metrics
        weights: Class weights tensor
        dataset_name: Name of the dataset
    """
    print(f"\nResults for {dataset_name.upper()}")
    print("=" * 75)
    print(f"Overall Dice Loss: {metrics['avg_loss']:.4f}")
    print(f"Mean Dice Coefficient: {metrics['mean_dice']:.4f}")
    print("=" * 75)

    print(f"{'Class':<8} {'Dice Coefficient':<20} {'Class Weight':<15} {'Loss Contribution':<15}")
    print("-" * 75)

    for class_idx in range(len(weights)):
        dice_coeff = metrics[f'class_{class_idx}_dice']
        weight = weights[class_idx].item()
        loss_contribution = (1 - dice_coeff) * weight

        print(f"{class_idx:<8} "
              f"{dice_coeff:>15.4f}     "
              f"{weight:>10.4f}     "
              f"{loss_contribution:>12.4f}")

    print("-" * 75)

def test_dice_loss():
    """Test the Dice loss implementation with improved output formatting"""
    print("Testing Dice Loss Implementation")
    print("=" * 75)

    test_configs = {
        'indian_pines': {'num_classes': 16, 'shape': (4, 16, 13, 13)},
        'pavia_university': {'num_classes': 9, 'shape': (4, 9, 13, 13)},
        'salinas': {'num_classes': 16, 'shape': (4, 16, 13, 13)}
    }

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    for dataset_name, config in test_configs.items():
        try:
            criterion = DiceLoss(
                num_classes=config['num_classes'],
                weight_mode='balanced',
                device=device
            ).to(device)

            batch_size = 4
            spatial_size = 13
            logits = torch.randn(config['shape']).to(device)
            target = torch.randint(0, config['num_classes'],
                                 (batch_size, spatial_size, spatial_size)).to(device)


            loss = criterion(logits, target)

            metrics = criterion.get_metrics()
            print_metrics_table(metrics, criterion.class_weights, dataset_name)

        except Exception as e:
            print(f"\nError testing {dataset_name}: {str(e)}")
            print("\nDetailed traceback:")
            traceback.print_exc()
            print("\n")

if __name__ == "__main__":
    test_dice_loss()

"""## Optimization

### Adam optimizer
"""

@dataclass
class OptimizerConfig:
    """Configuration for Adam optimizer"""
    learning_rate: float = 1e-3
    weight_decay: float = 1e-4
    beta1: float = 0.9
    beta2: float = 0.999
    epsilon: float = 1e-8
    amsgrad: bool = False
    lr_schedule: str = 'cosine'  # 'cosine', 'step', 'linear', 'constant'
    warmup_epochs: int = 5
    total_epochs: int = 100
    min_lr: float = 1e-6
    decay_steps: List[int] = None  # For step schedule

class CustomLRScheduler(_LRScheduler):
    """
    Custom learning rate scheduler with warmup and different decay options
    """
    def __init__(self,
                 optimizer: optim.Optimizer,
                 config: OptimizerConfig):
        """Initialize scheduler"""
        self.config = config
        self.warmup_steps = config.warmup_epochs
        self.total_steps = config.total_epochs
        self.decay_steps = config.decay_steps or []
        super().__init__(optimizer)

    def get_lr(self) -> List[float]:
        """Calculate learning rate based on current epoch"""
        step = self.last_epoch
        total_steps = self.total_steps
        warmup_steps = self.warmup_steps
        initial_lrs = [group['initial_lr'] for group in self.optimizer.param_groups]
        min_lr = self.config.min_lr

        if step < warmup_steps:
            return [lr * (step + 1) / warmup_steps for lr in initial_lrs]

        step_after_warmup = step - warmup_steps
        total_steps_after_warmup = total_steps - warmup_steps

        if self.config.lr_schedule == 'cosine':
            progress = step_after_warmup / total_steps_after_warmup
            cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))
            return [min_lr + (lr - min_lr) * cosine_decay for lr in initial_lrs]

        elif self.config.lr_schedule == 'step':
            decay_factor = 0.1 ** sum(step >= decay_step for decay_step in self.decay_steps)
            return [lr * decay_factor for lr in initial_lrs]

        elif self.config.lr_schedule == 'linear':
            progress = step_after_warmup / total_steps_after_warmup
            return [min_lr + (lr - min_lr) * (1 - progress) for lr in initial_lrs]

        else:
            return initial_lrs

def create_optimizer(model: torch.nn.Module,
                    config: OptimizerConfig) -> Tuple[optim.Optimizer, _LRScheduler]:
    """
    Create optimizer and scheduler for model training

    Args:
        model: Neural network model
        config: Optimizer configuration

    Returns:
        Tuple of (optimizer, scheduler)
    """
    param_groups = [
        {
            'params': [p for n, p in model.named_parameters()
                      if 'bias' not in n and 'bn' not in n],
            'weight_decay': config.weight_decay
        },
        {
            'params': [p for n, p in model.named_parameters()
                      if 'bias' in n or 'bn' in n],
            'weight_decay': 0.0
        }
    ]

    optimizer = optim.Adam(
        param_groups,
        lr=config.learning_rate,
        betas=(config.beta1, config.beta2),
        eps=config.epsilon,
        amsgrad=config.amsgrad
    )

    scheduler = CustomLRScheduler(optimizer, config)

    return optimizer, scheduler

def print_optimizer_config(config: OptimizerConfig):
    """Print optimizer configuration with parameter descriptions"""
    print("\nOptimizer Configuration")
    print("=" * 80)
    print(f"{'Parameter':<20} {'Value':<15} {'Description':<45}")
    print("-" * 80)

    config_dict = {
        'Learning Rate': (
            config.learning_rate,
            'Base learning rate'
        ),
        'Weight Decay': (
            config.weight_decay,
            'L2 regularization'
        ),
        'Beta1': (
            config.beta1,
            'Adam momentum parameter'
        ),
        'Beta2': (
            config.beta2,
            'Adam RMSprop parameter'
        ),
        'Epsilon': (
            config.epsilon,
            'Numerical stability'
        ),
        'AMSGrad': (
            config.amsgrad,
            'AMSGrad variant of Adam'
        ),
        'LR Schedule': (
            config.lr_schedule,
            'Learning rate decay type'
        ),
        'Warmup Epochs': (
            config.warmup_epochs,
            'Gradual LR warmup period'
        ),
        'Total Epochs': (
            config.total_epochs,
            'Total training epochs'
        ),
        'Min LR': (
            config.min_lr,
            'Minimum learning rate'
        )
    }

    for param, (value, description) in config_dict.items():
        print(f"{param:<20} {str(value):<15} {description:<45}")

    if config.decay_steps:
        print(f"Decay Steps: {config.decay_steps}")
    print("=" * 80)

def get_lr_description(epoch: int, warmup_epochs: int) -> str:
    """Get descriptive comment for learning rate at given epoch"""
    if epoch == 0:
        return "20% of base LR - warmup"
    elif epoch == 1:
        return "40% of base LR - warmup"
    elif epoch == warmup_epochs:
        return "Full base LR - warmup complete"
    elif epoch == 25:
        return "Cosine decay begins"
    elif epoch == 50:
        return "Middle of training"
    elif epoch == 75:
        return "Later stage"
    elif epoch == 99:
        return "Final epoch - reached min_lr"
    return ""

def test_optimizer():
    """Test optimizer and scheduler implementation"""
    print("Testing Adam Optimizer and LR Scheduler")
    print("=" * 80)

    test_configs = {
        'indian_pines': {'input_channels': 180, 'num_classes': 16},
        'pavia_university': {'input_channels': 103, 'num_classes': 9},
        'salinas': {'input_channels': 204, 'num_classes': 16}
    }

    for dataset_name, dataset_config in test_configs.items():
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 80)

        try:
            model = torch.nn.Sequential(
                torch.nn.Conv2d(dataset_config['input_channels'], 64, 3, padding=1),
                torch.nn.BatchNorm2d(64),
                torch.nn.ReLU(),
                torch.nn.Conv2d(64, dataset_config['num_classes'], 1)
            )

            optimizer_config = OptimizerConfig(
                learning_rate=1e-3,
                weight_decay=1e-4,
                lr_schedule='cosine',
                warmup_epochs=5,
                total_epochs=100
            )

            print_optimizer_config(optimizer_config)

            optimizer, scheduler = create_optimizer(model, optimizer_config)

            print("\nLearning Rate Schedule:")
            print("-" * 70)
            print(f"{'Epoch':<8} {'Learning Rate':<15} {'Description':<40}")
            print("-" * 70)

            test_epochs = [0, 1, 5, 25, 50, 75, 99]
            for epoch in test_epochs:
                scheduler.step(epoch)
                current_lr = optimizer.param_groups[0]['lr']
                description = get_lr_description(epoch, optimizer_config.warmup_epochs)
                print(f"{epoch:<8} {current_lr:<15.6f} {description:<40}")

            print("-" * 70)

        except Exception as e:
            print(f"\nError testing {dataset_name}: {str(e)}")
            traceback.print_exc()

if __name__ == "__main__":
    test_optimizer()

"""### Basic learning rate scheduling"""

@dataclass
class SchedulerConfig:
    """Configuration for learning rate schedulers"""
    initial_lr: float = 1e-3
    min_lr: float = 1e-6
    total_epochs: int = 100
    warmup_epochs: int = 5
    scheduler_type: str = 'step'  # 'step', 'cosine', 'linear', 'exponential'
    step_size: int = 30
    gamma: float = 0.1
    steps: List[int] = None  # For multi-step scheduler

class LRSchedulers:
    """Learning rate scheduler implementations"""

    @staticmethod
    def step_scheduler(epoch: int, config: SchedulerConfig) -> float:
        """Step decay learning rate scheduler"""
        if epoch < config.warmup_epochs:
            return config.initial_lr * (epoch + 1) / config.warmup_epochs

        decay = config.gamma ** ((epoch - config.warmup_epochs) // config.step_size)
        return max(config.initial_lr * decay, config.min_lr)

    @staticmethod
    def cosine_scheduler(epoch: int, config: SchedulerConfig) -> float:
        """Cosine decay learning rate scheduler"""
        if epoch < config.warmup_epochs:
            return config.initial_lr * (epoch + 1) / config.warmup_epochs

        progress = (epoch - config.warmup_epochs) / (config.total_epochs - config.warmup_epochs)
        cosine_decay = 0.5 * (1 + math.cos(math.pi * progress))
        return max(config.min_lr + (config.initial_lr - config.min_lr) * cosine_decay, config.min_lr)

    @staticmethod
    def linear_scheduler(epoch: int, config: SchedulerConfig) -> float:
        """Linear decay learning rate scheduler"""
        if epoch < config.warmup_epochs:
            return config.initial_lr * (epoch + 1) / config.warmup_epochs

        progress = (epoch - config.warmup_epochs) / (config.total_epochs - config.warmup_epochs)
        return max(config.initial_lr * (1 - progress), config.min_lr)

    @staticmethod
    def exponential_scheduler(epoch: int, config: SchedulerConfig) -> float:
        """Exponential decay learning rate scheduler"""
        if epoch < config.warmup_epochs:
            return config.initial_lr * (epoch + 1) / config.warmup_epochs

        decay = math.exp(-0.1 * (epoch - config.warmup_epochs))
        return max(config.initial_lr * decay, config.min_lr)

def visualize_schedules(config: SchedulerConfig):
    """Visualize different learning rate schedules"""
    epochs = range(config.total_epochs)
    schedules = {
        'Step': LRSchedulers.step_scheduler,
        'Cosine': LRSchedulers.cosine_scheduler,
        'Linear': LRSchedulers.linear_scheduler,
        'Exponential': LRSchedulers.exponential_scheduler
    }

    plt.figure(figsize=(12, 6))
    for name, scheduler in schedules.items():
        lrs = [scheduler(epoch, config) for epoch in epochs]
        plt.plot(epochs, lrs, label=name)

    plt.xlabel('Epoch')
    plt.ylabel('Learning Rate')
    plt.title('Learning Rate Schedules Comparison')
    plt.legend()
    plt.grid(True)
    plt.show()

def print_schedule_table(schedule_name: str, scheduler, config: SchedulerConfig):
    """Print learning rate schedule table"""
    print(f"\n{schedule_name} Learning Rate Schedule")
    print("=" * 80)
    print(f"{'Epoch':<10} {'Learning Rate':<15} {'Phase':<20} {'Description':<35}")
    print("-" * 80)

    key_epochs = [
        0,
        config.warmup_epochs // 2,
        config.warmup_epochs - 1,
        config.warmup_epochs,
        config.total_epochs // 4,
        config.total_epochs // 2,
        3 * config.total_epochs // 4,
        config.total_epochs - 1
    ]

    for epoch in key_epochs:
        lr = scheduler(epoch, config)

        if epoch < config.warmup_epochs:
            phase = "Warmup"
            progress = (epoch + 1) / config.warmup_epochs * 100
            description = f"Warmup progress: {progress:.1f}%"
        else:
            phase = "Decay"
            progress = (epoch - config.warmup_epochs) / (config.total_epochs - config.warmup_epochs) * 100
            description = f"Decay progress: {progress:.1f}%"

        print(f"{epoch:<10} {lr:<15.6f} {phase:<20} {description:<35}")

    print("-" * 80)

def test_schedulers():
    """Test and demonstrate learning rate schedulers"""
    print("Testing Learning Rate Schedulers")
    print("=" * 80)

    config = SchedulerConfig(
        initial_lr=1e-3,
        min_lr=1e-6,
        total_epochs=100,
        warmup_epochs=5,
        step_size=30,
        gamma=0.1
    )

    print("\nScheduler Configuration:")
    print("-" * 40)
    print(f"Initial LR: {config.initial_lr}")
    print(f"Minimum LR: {config.min_lr}")
    print(f"Total Epochs: {config.total_epochs}")
    print(f"Warmup Epochs: {config.warmup_epochs}")
    print(f"Step Size: {config.step_size}")
    print(f"Gamma: {config.gamma}")
    print("-" * 40)

    schedulers = {
        'Step': LRSchedulers.step_scheduler,
        'Cosine': LRSchedulers.cosine_scheduler,
        'Linear': LRSchedulers.linear_scheduler,
        'Exponential': LRSchedulers.exponential_scheduler
    }

    for name, scheduler in schedulers.items():
        print_schedule_table(name, scheduler, config)

    visualize_schedules(config)

if __name__ == "__main__":
    test_schedulers()

"""## Regularization

### Spectral dropout
"""

class SpectralDropout(nn.Module):
    """
    Spectral Dropout layer for hyperspectral data regularization
    Randomly drops entire spectral bands during training
    """
    def __init__(self,
                 drop_rate: float = 0.2,
                 band_groups: Optional[List[Tuple[int, int]]] = None,
                 contiguous: bool = True,
                 min_bands: int = 10):
        """
        Initialize Spectral Dropout

        Args:
            drop_rate: Probability of dropping a spectral band
            band_groups: List of (start, end) tuples for grouped band dropping
            contiguous: Whether to drop contiguous bands
            min_bands: Minimum number of bands to keep
        """
        super().__init__()
        self.drop_rate = drop_rate
        self.band_groups = band_groups
        self.contiguous = contiguous
        self.min_bands = min_bands
        self.drop_mask = None

    def _create_band_mask(self, num_bands: int) -> torch.Tensor:
        """Create dropout mask for spectral bands"""
        if self.training:
            if self.contiguous:
                mask = torch.ones(num_bands, dtype=torch.bool)
                if self.band_groups:
                    for start, end in self.band_groups:
                        if torch.rand(1) < self.drop_rate:
                            mask[start:end] = 0
                else:
                    section_size = max(1, int(num_bands * self.drop_rate))
                    max_start = num_bands - section_size
                    if max_start > 0:
                        start = torch.randint(0, max_start, (1,))
                        mask[start:start+section_size] = 0
            else:
                mask = torch.bernoulli(torch.full((num_bands,), 1 - self.drop_rate)).bool()

            if mask.sum() < self.min_bands:
                indices = torch.randperm(num_bands)[:self.min_bands]
                mask = torch.zeros(num_bands, dtype=torch.bool)
                mask[indices] = True

            return mask
        return torch.ones(num_bands, dtype=torch.bool)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass

        Args:
            x: Input tensor of shape (batch_size, channels, height, width)

        Returns:
            Output tensor with dropped spectral bands
        """
        if not self.training or self.drop_rate == 0:
            return x

        mask = self._create_band_mask(x.size(1))
        self.drop_mask = mask

        scale = 1 / (1 - self.drop_rate)

        mask = mask.to(x.device)
        return x * mask.view(1, -1, 1, 1) * scale

    def get_active_bands(self) -> torch.Tensor:
        """Get indices of active (non-dropped) bands"""
        if self.drop_mask is None:
            return None
        return torch.where(self.drop_mask)[0]

class SpectralDropoutVisualization:
    """Utility class for visualizing spectral dropout effects"""

    @staticmethod
    def plot_band_mask(dropout: SpectralDropout, num_bands: int):
        """Plot band dropout pattern"""
        mask = dropout._create_band_mask(num_bands)

        plt.figure(figsize=(12, 4))
        plt.imshow(mask.numpy().reshape(1, -1),
                  aspect='auto',
                  cmap='RdYlGn')
        plt.title('Spectral Band Mask (Green: Active, Red: Dropped)')
        plt.xlabel('Band Index')
        plt.colorbar(label='Band Status')
        plt.show()

    @staticmethod
    def plot_spectral_signatures(original: torch.Tensor,
                               dropped: torch.Tensor,
                               dropout: SpectralDropout):
        """Plot original vs dropped spectral signatures"""
        plt.figure(figsize=(12, 6))

        plt.plot(range(original.size(1)),
                original[0].mean(-1).mean(-1).cpu(),
                label='Original', alpha=0.7)

        plt.plot(range(dropped.size(1)),
                dropped[0].mean(-1).mean(-1).cpu(),
                label='After Dropout', alpha=0.7)

        if dropout.drop_mask is not None:
            dropped_idx = torch.where(~dropout.drop_mask)[0].cpu()
            plt.scatter(dropped_idx,
                       original[0, dropped_idx].mean(-1).mean(-1).cpu(),
                       color='red', alpha=0.5, label='Dropped Bands')

        plt.title('Spectral Signatures Before and After Dropout')
        plt.xlabel('Band Index')
        plt.ylabel('Average Intensity')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.show()

def test_spectral_dropout():
    """Test and visualize spectral dropout"""
    print("Testing Spectral Dropout")
    print("=" * 60)

    test_configs = {
        'indian_pines': {'bands': 180},
        'pavia_university': {'bands': 103},
        'salinas': {'bands': 204}
    }

    for dataset_name, config in test_configs.items():
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 60)

        batch_size = 4
        spatial_size = 13
        x = torch.randn(batch_size, config['bands'], spatial_size, spatial_size)

        dropouts = {
            'Regular': SpectralDropout(drop_rate=0.2),
            'Contiguous': SpectralDropout(drop_rate=0.2, contiguous=True),
            'Grouped': SpectralDropout(
                drop_rate=0.2,
                band_groups=[(0, 20), (40, 60), (80, 100)]
            )
        }

        for name, dropout in dropouts.items():
            print(f"\nTesting {name} Spectral Dropout:")
            dropout.train()

            y = dropout(x)

            active_bands = dropout.get_active_bands()

            print(f"Input shape: {x.shape}")
            print(f"Output shape: {y.shape}")
            print(f"Active bands: {len(active_bands)}/{config['bands']} "
                  f"({len(active_bands)/config['bands']*100:.1f}%)")

            SpectralDropoutVisualization.plot_band_mask(dropout, config['bands'])
            SpectralDropoutVisualization.plot_spectral_signatures(x, y, dropout)

if __name__ == "__main__":
    test_spectral_dropout()

"""### L1/L2 regularization"""

@dataclass
class RegularizationConfig:
    """Configuration for L1/L2 regularization"""
    l1_lambda: float = 1e-5     # L1 regularization strength
    l2_lambda: float = 1e-4     # L2 regularization strength
    exclude_bias: bool = True   # Whether to exclude bias terms
    exclude_bn: bool = True     # Whether to exclude batch norm parameters
    per_layer_config: Optional[Dict[str, Dict[str, float]]] = None  # Layer-specific config

class ModelRegularization:
    """
    L1 and L2 regularization implementation for neural networks
    """
    def __init__(self, model: nn.Module, config: RegularizationConfig):
        """
        Initialize regularization

        Args:
            model: Neural network model
            config: Regularization configuration
        """
        self.model = model
        self.config = config
        self.regularization_loss = 0.0
        self.layer_losses = {}

    def _get_layer_config(self, name: str) -> Dict[str, float]:
        """Get layer-specific regularization configuration"""
        if self.config.per_layer_config and name in self.config.per_layer_config:
            return self.config.per_layer_config[name]
        return {'l1': self.config.l1_lambda, 'l2': self.config.l2_lambda}

    def _should_regularize_parameter(self, name: str, param: nn.Parameter) -> bool:
        """Check if parameter should be regularized"""
        if self.config.exclude_bias and 'bias' in name:
            return False
        if self.config.exclude_bn and ('bn' in name or 'batch_norm' in name):
            return False
        return True

    def compute_regularization(self) -> torch.Tensor:
        """
        Compute L1 and L2 regularization losses

        Returns:
            Combined regularization loss
        """
        total_l1_loss = 0.0
        total_l2_loss = 0.0
        self.layer_losses = {}

        for name, param in self.model.named_parameters():
            if param.requires_grad and self._should_regularize_parameter(name, param):
                config = self._get_layer_config(name)

                l1_loss = config['l1'] * torch.sum(torch.abs(param))

                l2_loss = config['l2'] * torch.sum(param.pow(2))

                total_l1_loss += l1_loss
                total_l2_loss += l2_loss

                self.layer_losses[name] = {
                    'l1': l1_loss.item(),
                    'l2': l2_loss.item()
                }

        self.regularization_loss = total_l1_loss + total_l2_loss
        return self.regularization_loss

    def get_regularization_summary(self) -> Dict[str, float]:
        """Get summary of regularization losses"""
        return {
            'total_loss': self.regularization_loss.item(),
            'layer_losses': self.layer_losses
        }

def print_regularization_summary(summary: Dict[str, float]):
    """Print regularization summary in a formatted table with descriptions"""
    print("\nRegularization Summary")
    print("=" * 100)
    print(f"{'Layer':<15} {'Description':<32} {'L1 Loss':<15} {'L2 Loss':<15} {'Total':<15}")
    print("-" * 100)

    descriptions = {
        '0.weight': 'First Conv2D',         # Input to 64 channels
        '1.weight': 'First BatchNorm',      # BatchNorm after first conv
        '3.weight': 'Second Conv2D',        # 64 to 128 channels
        '4.weight': 'Second BatchNorm',     # BatchNorm after second conv
        '6.weight': 'Output Conv2D'         # Final classification layer
    }

    total_l1 = 0.0
    total_l2 = 0.0

    for layer_name, losses in summary['layer_losses'].items():
        l1_loss = losses['l1']
        l2_loss = losses['l2']
        total = l1_loss + l2_loss
        description = descriptions.get(layer_name, 'Unknown Layer')
        print(f"{layer_name:<15} {description:<25} {l1_loss:>15.6f} {l2_loss:>15.6f} {total:>15.6f}")
        total_l1 += l1_loss
        total_l2 += l2_loss

    print("-" * 100)
    print(f"{'Total':<40} {total_l1:>15.6f} {total_l2:>15.6f} {total_l1+total_l2:>15.6f}")
    print("=" * 100)

def test_regularization():
    """Test regularization implementation"""
    print("Testing L1/L2 Regularization")
    print("=" * 80)

    test_configs = {
        'indian_pines': {
            'input_channels': 180,
            'num_classes': 16,
            'config': RegularizationConfig(
                l1_lambda=1e-5,
                l2_lambda=1e-4
            )
        },
        'pavia_university': {
            'input_channels': 103,
            'num_classes': 9,
            'config': RegularizationConfig(
                l1_lambda=2e-5,
                l2_lambda=2e-4
            )
        },
        'salinas': {
            'input_channels': 204,
            'num_classes': 16,
            'config': RegularizationConfig(
                l1_lambda=1e-5,
                l2_lambda=1e-4
            )
        }
    }

    for dataset_name, config in test_configs.items():
        print(f"\nTesting {dataset_name.upper()}")
        print("-" * 80)

        try:
            model = nn.Sequential(
                nn.Conv2d(config['input_channels'], 64, 3, padding=1),
                nn.BatchNorm2d(64),
                nn.ReLU(),
                nn.Conv2d(64, 128, 3, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(),
                nn.Conv2d(128, config['num_classes'], 1)
            )

            print("\nRegularization Configuration:")
            print(f"L1 Lambda: {config['config'].l1_lambda}")
            print(f"L2 Lambda: {config['config'].l2_lambda}")
            print(f"Exclude Bias: {config['config'].exclude_bias}")
            print(f"Exclude BatchNorm: {config['config'].exclude_bn}")

            regularizer = ModelRegularization(model, config['config'])

            reg_loss = regularizer.compute_regularization()

            summary = regularizer.get_regularization_summary()
            print_regularization_summary(summary)

        except Exception as e:
            print(f"Error testing {dataset_name}: {str(e)}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    test_regularization()

"""# **7.Model Training and Monitoring**

## MODEL SELECTION
"""

models = [
    # 'resnet',    # ResNet18 with spectral attention
    # 'vit',       # Vision Transformer
    # '3dcnn',     # 3D CNN
    # 'hybrid',    # Hybrid CNN-Transformer
    # 'unet',      # U-Net with spectral attention
    'fcn'        # FCN with spectral attention
]

"""## Train, Validate, Save Checkpoint and Core Metric's Base Classes"""

def get_dataset_config(dataset_name: str) -> Dict:
    """Get configuration for specific dataset"""
    dataset_configs = {
        'indian_pines': {
            'in_channels': 180,
            'num_classes': 16,
            'spatial_size': 13,
            'class_names': [
                'Background', 'Alfalfa', 'Corn-notill', 'Corn-mintill',
                'Corn', 'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed',
                'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',
                'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives'
            ]
        },
        'pavia_university': {
            'in_channels': 103,
            'num_classes': 9,
            'spatial_size': 13,
            'class_names': [
                'Background', 'Asphalt', 'Meadows', 'Gravel', 'Trees',
                'Painted metal sheets', 'Bare Soil', 'Bitumen',
                'Self-Blocking Bricks', 'Shadows'
            ]
        },
        'salinas': {
            'in_channels': 204,
            'num_classes': 16,
            'spatial_size': 13,
            'class_names': [
                'Background', 'Brocoli_green_weeds_1', 'Brocoli_green_weeds_2',
                'Fallow', 'Fallow_rough_plow', 'Fallow_smooth', 'Stubble',
                'Celery', 'Grapes_untrained', 'Soil_vinyard_develop',
                'Corn_senesced_weeds', 'Lettuce_romaine_4wk',
                'Lettuce_romaine_5wk', 'Lettuce_romaine_6wk',
                'Lettuce_romaine_7wk', 'Vinyard_untrained'
            ]
        }
    }

    if dataset_name.lower() not in dataset_configs:
        raise ValueError(f"Unknown dataset: {dataset_name}")

    return dataset_configs[dataset_name.lower()]

def verify_dataset_config(dataset_name: str):
    """Verify dataset configuration and print details"""
    try:
        config = get_dataset_config(dataset_name)
        print(f"\nConfiguration for {dataset_name.upper()}:")
        print(f"Input channels: {config['in_channels']}")
        print(f"Number of classes: {config['num_classes']}")
        print(f"Spatial size: {config['spatial_size']}")
        print(f"Number of class names: {len(config['class_names'])}")
        return True
    except Exception as e:
        print(f"Error verifying {dataset_name} config: {str(e)}")
        return False

@dataclass
class TaskConfig:
    """Configuration for task-specific parameters"""
    task_type: str  # 'classification' or 'segmentation'
    in_channels: int
    num_classes: int
    spatial_size: int = 13
    model_type: str = 'resnet'
    dataset_name: str = 'indian_pines'

    classification_params: Dict[str, Any] = field(default_factory=dict)
    segmentation_params: Dict[str, Any] = field(default_factory=dict)

@dataclass
class TrainingConfig:
    """Training configuration with spatial size"""
    dataset_name: str
    in_channels: int
    num_classes: int
    batch_size: int = 32
    num_epochs: int = 200
    learning_rate: float = 1e-4
    weight_decay: float = 1e-4
    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'
    dropout_rate: float = 0.6
    use_spectral_dropout: bool = True
    spectral_dropout_rate: float = 0.2
    use_class_weights: bool = True
    use_regularization: bool = True
    warmup_epochs: int = 5
    patience: int = 10
    min_delta: float = 1e-4
    spatial_size: int = 13

class ClassificationMetrics:
    """
    Comprehensive metrics for hyperspectral image classification
    Includes accuracy, precision, recall, F1-score, ROC curves, and confusion matrices
    """
    def __init__(self, num_classes: int, class_names: Optional[List[str]] = None):
        """
        Initialize classification metrics tracker

        Args:
            num_classes: Number of classes in the dataset
            class_names: Optional list of class names
        """
        self.num_classes = num_classes
        self.class_names = class_names or [f"Class {i}" for i in range(num_classes)]
        self.reset()

    def reset(self):
        """Reset all metrics"""
        self.predictions = []
        self.targets = []
        self.probabilities = []

    def update(self, logits: torch.Tensor, targets: torch.Tensor):
        """
        Update metrics with new predictions

        Args:
            logits: Raw model outputs [B, C, H, W]
            targets: Ground truth labels [B, H, W]
        """
        probs = torch.softmax(logits, dim=1)

        preds = torch.argmax(logits, dim=1)

        self.predictions.extend(preds.cpu().numpy().flatten())
        self.targets.extend(targets.cpu().numpy().flatten())
        self.probabilities.extend(probs.cpu().numpy())

    def compute_metrics(self) -> Dict[str, float]:
        """
        Compute all classification metrics

        Returns:
            Dictionary containing all metrics
        """
        metrics = {}

        precision, recall, f1, _ = precision_recall_fscore_support(
            self.targets, self.predictions,
            average='weighted'
        )

        metrics['accuracy'] = np.mean(np.array(self.targets) == np.array(self.predictions))
        metrics['precision'] = precision
        metrics['recall'] = recall
        metrics['f1_score'] = f1

        precision_per_class, recall_per_class, f1_per_class, _ = \
            precision_recall_fscore_support(self.targets, self.predictions)

        for i in range(self.num_classes):
            metrics[f'class_{i}_precision'] = precision_per_class[i]
            metrics[f'class_{i}_recall'] = recall_per_class[i]
            metrics[f'class_{i}_f1'] = f1_per_class[i]

        return metrics

    def plot_confusion_matrix(self, normalize: bool = True):
        """Plot confusion matrix"""
        cm = confusion_matrix(self.targets, self.predictions)

        if normalize:
            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd',
                   xticklabels=self.class_names,
                   yticklabels=self.class_names)
        plt.title('Normalized Confusion Matrix' if normalize else 'Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.show()

    def plot_roc_curves(self):
        """Plot ROC curves for each class"""
        plt.figure(figsize=(10, 8))

        for i in range(self.num_classes):
            y_true = (np.array(self.targets) == i).astype(int)
            y_score = np.array(self.probabilities)[:, i]

            fpr, tpr, _ = roc_curve(y_true, y_score)
            roc_auc = auc(fpr, tpr)

            plt.plot(fpr, tpr, label=f'{self.class_names[i]} (AUC = {roc_auc:.2f})')

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves per Class')
        plt.legend(loc="lower right")
        plt.tight_layout()
        plt.show()

class SegmentationLoss(nn.Module):
    def __init__(self, num_classes, alpha=0.5):
        super().__init__()
        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')
        self.dice_loss = DiceLoss(num_classes)
        self.alpha = alpha

    def forward(self, pred, target):
        ce_loss = self.cross_entropy(pred, target)
        dice_loss = self.dice_loss(pred, target)
        return self.alpha * ce_loss + (1-self.alpha) * dice_loss

class SegmentationMetrics:
    """
    Core metrics for hyperspectral image segmentation
    Includes IoU (Intersection over Union) and Dice coefficient
    """
    def __init__(self, num_classes: int, class_names: Optional[List[str]] = None):
        """
        Initialize segmentation metrics tracker

        Args:
            num_classes: Number of classes in dataset
            class_names: Optional list of class names
        """
        self.num_classes = num_classes
        self.class_names = class_names or [f"Class {i}" for i in range(num_classes)]
        self.reset()

    def reset(self):
        """Reset all metrics"""
        self.predictions = []
        self.targets = []
        self.intersection = np.zeros(self.num_classes)
        self.union = np.zeros(self.num_classes)
        self.dice_scores = np.zeros(self.num_classes)
        self.total_pixels = 0

    def update(self, logits: torch.Tensor, target: torch.Tensor):
        """
        Update metrics with new predictions

        Args:
            logits: Model outputs [B, C, H, W]
            target: Ground truth masks [B, H, W]
        """
        preds = torch.argmax(logits, dim=1).cpu().numpy()
        target = target.cpu().numpy()

        self.predictions.append(preds)
        self.targets.append(target)

        self.total_pixels += target.size

        for class_idx in range(self.num_classes):
            pred_mask = (preds == class_idx)
            target_mask = (target == class_idx)

            intersection = np.logical_and(pred_mask, target_mask).sum()
            union = np.logical_or(pred_mask, target_mask).sum()

            self.intersection[class_idx] += intersection
            self.union[class_idx] += union

            dice_numerator = 2 * intersection
            dice_denominator = pred_mask.sum() + target_mask.sum()
            if dice_denominator > 0:
                self.dice_scores[class_idx] += dice_numerator / dice_denominator

    def compute_metrics(self) -> Dict[str, float]:
        """
        Compute all segmentation metrics

        Returns:
            Dictionary containing all metrics
        """
        metrics = {}

        iou_scores = np.zeros(self.num_classes)
        for i in range(self.num_classes):
            if self.union[i] > 0:
                iou_scores[i] = self.intersection[i] / self.union[i]

        valid_classes = self.union > 0
        mean_iou = np.mean(iou_scores[valid_classes])
        metrics['mean_iou'] = mean_iou

        for i in range(self.num_classes):
            metrics[f'class_{i}_iou'] = iou_scores[i]

        mean_dice = np.mean(self.dice_scores[valid_classes])
        metrics['mean_dice'] = mean_dice

        for i in range(self.num_classes):
            metrics[f'class_{i}_dice'] = self.dice_scores[i]

        return metrics

    def plot_metrics_comparison(self):
        """Plot comparison of IoU and Dice scores for each class"""
        metrics = self.compute_metrics()

        iou_scores = [metrics[f'class_{i}_iou'] for i in range(self.num_classes)]
        dice_scores = [metrics[f'class_{i}_dice'] for i in range(self.num_classes)]

        x = np.arange(self.num_classes)
        width = 0.35

        fig, ax = plt.subplots(figsize=(12, 6))
        rects1 = ax.bar(x - width/2, iou_scores, width, label='IoU')
        rects2 = ax.bar(x + width/2, dice_scores, width, label='Dice')

        ax.set_ylabel('Score')
        ax.set_title('IoU vs Dice Coefficient by Class')
        ax.set_xticks(x)
        ax.set_xticklabels(self.class_names, rotation=45, ha='right')
        ax.legend()

        plt.tight_layout()
        plt.show()

    def plot_confusion_matrix(self, normalize: bool = True):
        """Plot segmentation confusion matrix"""
        all_preds = np.concatenate([p.flatten() for p in self.predictions])
        all_targets = np.concatenate([t.flatten() for t in self.targets])

        cm = confusion_matrix(all_targets, all_preds)

        if normalize:
            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd',
                   xticklabels=self.class_names,
                   yticklabels=self.class_names)
        plt.title('Normalized Segmentation Confusion Matrix' if normalize else 'Segmentation Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.show()

    def visualize_predictions(self, num_samples: int = 5):
        """Visualize random prediction samples"""
        if len(self.predictions) == 0:
            print("No predictions available")
            return

        total_samples = len(self.predictions)
        indices = np.random.choice(total_samples, min(num_samples, total_samples), replace=False)

        fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))
        if num_samples == 1:
            axes = axes[np.newaxis, :]

        for i, idx in enumerate(indices):
            pred = self.predictions[idx]
            target = self.targets[idx]

            axes[i, 0].imshow(target)
            axes[i, 0].set_title('Ground Truth')
            axes[i, 0].axis('off')

            axes[i, 1].imshow(pred)
            axes[i, 1].set_title('Prediction')
            axes[i, 1].axis('off')

            diff = (pred != target).astype(np.float32)
            axes[i, 2].imshow(diff, cmap='red')
            axes[i, 2].set_title('Differences')
            axes[i, 2].axis('off')

        plt.tight_layout()
        plt.show()

class TrainingMonitor:
    """
    Monitor and track training progress, metrics and visualizations
    """
    def __init__(self, model_name: str, dataset_name: str, task_type: str = 'classification'):
        self.model_name = model_name
        self.dataset_name = dataset_name
        self.task_type = task_type

        if task_type == 'classification':
            self.metrics = ClassificationMetrics(
                num_classes=get_dataset_config(dataset_name)['num_classes'],
                class_names=get_dataset_config(dataset_name)['class_names']
            )
        else:
            self.metrics = SegmentationMetrics(
                num_classes=get_dataset_config(dataset_name)['num_classes'],
                class_names=get_dataset_config(dataset_name)['class_names']
            )

        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_metrics': [],
            'val_metrics': [],
            'learning_rates': []
        }

    def update_metrics(self,
                      outputs: torch.Tensor,
                      targets: torch.Tensor,
                      phase: str = 'train'):
        """Update metrics for current batch"""
        self.metrics.update(outputs, targets)

        batch_metrics = self.metrics.compute_metrics()

        if phase == 'train':
            self.history['train_metrics'].append(batch_metrics)
        else:
            self.history['val_metrics'].append(batch_metrics)

    def update_loss(self, loss: float, phase: str = 'train'):
        """Update loss history"""
        if phase == 'train':
            self.history['train_loss'].append(loss)
        else:
            self.history['val_loss'].append(loss)

    def update_learning_rate(self, lr: float):
        """Update learning rate history"""
        self.history['learning_rates'].append(lr)

    def plot_training_progress(self):
        """Plot training curves"""
        epochs = range(len(self.history['train_loss']))

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'Training Progress - {self.model_name} on {self.dataset_name}')

        axes[0,0].plot(epochs, self.history['train_loss'], label='Train')
        axes[0,0].plot(epochs, self.history['val_loss'], label='Validation')
        axes[0,0].set_title('Loss')
        axes[0,0].set_xlabel('Epoch')
        axes[0,0].set_ylabel('Loss')
        axes[0,0].legend()
        axes[0,0].grid(True, alpha=0.3)

        main_metric = 'accuracy' if self.task_type == 'classification' else 'mean_iou'
        train_metric = [m[main_metric] for m in self.history['train_metrics']]
        val_metric = [m[main_metric] for m in self.history['val_metrics']]

        axes[0,1].plot(epochs, train_metric, label='Train')
        axes[0,1].plot(epochs, val_metric, label='Validation')
        axes[0,1].set_title(main_metric.capitalize())
        axes[0,1].set_xlabel('Epoch')
        axes[0,1].set_ylabel(main_metric)
        axes[0,1].legend()
        axes[0,1].grid(True, alpha=0.3)

        axes[1,0].plot(epochs, self.history['learning_rates'])
        axes[1,0].set_title('Learning Rate')
        axes[1,0].set_xlabel('Epoch')
        axes[1,0].set_ylabel('Learning Rate')
        axes[1,0].grid(True, alpha=0.3)

        if self.task_type == 'classification':
            train_f1 = [m['f1_score'] for m in self.history['train_metrics']]
            val_f1 = [m['f1_score'] for m in self.history['val_metrics']]
            axes[1,1].plot(epochs, train_f1, label='Train')
            axes[1,1].plot(epochs, val_f1, label='Validation')
            axes[1,1].set_title('F1 Score')
        else:
            train_dice = [m['mean_dice'] for m in self.history['train_metrics']]
            val_dice = [m['mean_dice'] for m in self.history['val_metrics']]
            axes[1,1].plot(epochs, train_dice, label='Train')
            axes[1,1].plot(epochs, val_dice, label='Validation')
            axes[1,1].set_title('Dice Coefficient')

        axes[1,1].set_xlabel('Epoch')
        axes[1,1].legend()
        axes[1,1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

    def plot_final_metrics(self):
        """Plot final metrics visualization"""
        if self.task_type == 'classification':
            self.metrics.plot_confusion_matrix()

            self.metrics.plot_roc_curves()
        else:
            self.metrics.plot_metrics_comparison()

            self.metrics.visualize_predictions()


class BaseTrainer:
    """Base trainer class with common functionality"""
    def __init__(self, config: TrainingConfig, task_config: TaskConfig):
        self.config = config
        self.task_config = task_config
        self.device = torch.device(config.device)
        self.current_epoch = 0
        self.best_metric = float('inf')
        self.patience_counter = 0
        self.is_segmentation = task_config.task_type == 'segmentation'

        self.train_metrics = []
        self.val_metrics = []
        self.learning_rates = []

        self._initialize_data()
        self._initialize_model()
        self._initialize_criterion()
        self.optimizer, self.scheduler = self._initialize_optimizer()

        self.model = self.model.to(self.device)

    def _initialize_data(self):
        """Initialize dataloaders with task-specific datasets"""
        try:
            #samples = process_hyperspectral_data(self.config.dataset_name, silent=True)
            if samples is None:
                raise ValueError(f"Failed to process data for {self.config.dataset_name}")

            #splits = split_dataset(samples)

            task_type = 'segmentation' if self.is_segmentation else 'classification'

            self.train_loader = DataLoader(
                HyperspectralDataset(
                    splits['patch_data']['train'][0],
                    splits['patch_data']['train'][1],
                    self.config.dataset_name,
                    task_type=task_type
                ),
                batch_size=self.config.batch_size,
                shuffle=True,
                num_workers=2,
                pin_memory=True
            )

            self.val_loader = DataLoader(
                HyperspectralDataset(
                    splits['patch_data']['val'][0],
                    splits['patch_data']['val'][1],
                    self.config.dataset_name,
                    task_type=task_type
                ),
                batch_size=self.config.batch_size,
                shuffle=False,
                num_workers=2,
                pin_memory=True
            )

            self.test_loader = DataLoader(
                HyperspectralDataset(
                    splits['patch_data']['test'][0],
                    splits['patch_data']['test'][1],
                    self.config.dataset_name,
                    task_type=task_type
                ),
                batch_size=self.config.batch_size,
                shuffle=False,
                num_workers=2,
                pin_memory=True
            )

        except Exception as e:
            print(f"Error initializing data: {str(e)}")
            traceback.print_exc()
            raise

    def _initialize_model(self):
        """Initialize model based on task type"""
        if self.is_segmentation:
            if self.task_config.model_type == 'unet':
                self.model = create_unet_model(self.config.dataset_name)
            else:  # fcn
                self.model = create_fcn_model(self.config.dataset_name)
        else:
            if self.task_config.model_type == 'resnet':
                self.model = create_model(self.config.dataset_name)
            elif self.task_config.model_type == 'vit':
                self.model = create_vit_model(self.config.dataset_name)
            elif self.task_config.model_type == '3dcnn':
                self.model = create_3dcnn_model(self.config.dataset_name)
            else:
                self.model = create_hybrid_model(self.config.dataset_name)

    def _initialize_criterion(self):
        """Initialize loss function"""
        if self.is_segmentation:
            self.criterion = DiceLoss(
                num_classes=self.config.num_classes,
                device=self.device
            )
        else:
            self.criterion = WeightedCrossEntropyLoss(
                num_classes=self.config.num_classes,
                device=self.device
            )

    def _initialize_optimizer(self):
        """Initialize optimizer and scheduler"""
        optimizer = optim.Adam(
            self.model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )

        scheduler = CustomLRScheduler(
            optimizer,
            OptimizerConfig(
                learning_rate=self.config.learning_rate,
                total_epochs=self.config.num_epochs,
                warmup_epochs=self.config.warmup_epochs
            )
        )

        return optimizer, scheduler

    def _should_stop_early(self, metric: float) -> bool:
        """Check early stopping criteria"""
        if metric < self.best_metric - self.config.min_delta:
            self.best_metric = metric
            self.patience_counter = 0
            return False

        self.patience_counter += 1
        return self.patience_counter >= self.config.patience

    def test(self):
        """Evaluate model on test set"""
        return self.validate(self.test_loader)

    def load_checkpoint(self, filename: str):
        """Load model checkpoint"""
        if not os.path.exists(filename):
            raise FileNotFoundError(f"No checkpoint found at {filename}")

        checkpoint = torch.load(filename, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])

        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        self.current_epoch = checkpoint['epoch']
        self.training_history = checkpoint['metrics']

        print(f"Checkpoint loaded from {filename}")
        return checkpoint['metrics']

class Trainer(BaseTrainer):
    """Main trainer class with task-specific handling"""

    def __init__(self, config: TrainingConfig, task_config: TaskConfig):
        super().__init__(config, task_config)
        # Initialize metrics dictionary
        self.training_history = {
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'learning_rates': [],
            'val_f1': [],
            'val_precision': [],
            'val_recall': []
        } if not self.is_segmentation else {
            'train_loss': [],
            'val_loss': [],
            'train_iou': [],
            'val_iou': [],
            'val_dice': [],
            'val_mean_iou': [],
            'learning_rates': []
        }


    def train_epoch(self):
        """Training loop with fixed segmentation handling"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0

        pbar = tqdm(self.train_loader, desc=f'Epoch {self.current_epoch}')

        for batch_idx, (data, target) in enumerate(pbar):
            try:
                data = data.to(self.device)  # [B, C, H, W]
                target = target.to(self.device).long()

                outputs = self.model(data)  # [B, num_classes, H, W]

                if self.is_segmentation:
                    B, C, H, W = outputs.shape
                    #  [B, H, W]
                    if target.dim() != 3:
                        target = target.view(B, H, W)
                    loss = self.criterion(outputs, target)

                    _, predicted = outputs.max(1)  # [B, H, W]
                    correct += (predicted == target).float().sum().item()
                    total += target.numel()
                else:
                    loss = self.criterion(outputs, target)
                    _, predicted = outputs.max(1)
                    correct += predicted.eq(target).sum().item()
                    total += target.size(0)

                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()

                total_loss += loss.item()

                pbar.set_postfix({
                    'loss': total_loss / (batch_idx + 1),
                    'acc': 100. * correct / total if total > 0 else 0
                })

            except Exception as e:
                print(f"\nError in batch {batch_idx}: {str(e)}")
                print(f"Data shape: {data.shape}")
                print(f"Target shape: {target.shape}")
                if 'outputs' in locals():
                    print(f"Output shape: {outputs.shape}")
                raise e

        return total_loss / len(self.train_loader), correct / total

    def validate(self, loader=None):
        """Fixed validation handling for segmentation and classification"""
        if loader is None:
            loader = self.val_loader

        self.model.eval()
        total_loss = 0
        metrics_tracker = (SegmentationMetrics(self.config.num_classes)
                          if self.is_segmentation
                          else ClassificationMetrics(self.config.num_classes))

        with torch.no_grad():
            for data, target in loader:
                data = data.to(self.device)
                target = target.to(self.device).long()

                if self.is_segmentation:
                    B = data.size(0)
                    if target.dim() == 1 or (target.dim() == 2 and target.size(1) == 1):
                        target = target.view(B, 1).repeat(1, 13*13).reshape(B, 13, 13)

                outputs = self.model(data)

                loss = self.criterion(outputs, target)
                total_loss += loss.item()

                metrics_tracker.update(outputs, target)

        metrics = metrics_tracker.compute_metrics()
        metrics['loss'] = total_loss / len(loader)

        return metrics

    def validate_and_report(self, loader=None, phase="Validation"):
        """Detailed validation with percentage-based confusion matrix"""
        val_loss, val_acc = self.validate(loader)

        all_preds = []
        all_targets = []
        confusion_mat = torch.zeros(self.config.num_classes, self.config.num_classes)

        self.model.eval()
        with torch.no_grad():
            for data, target in loader:
                data = data.to(self.device)
                target = target.to(self.device)
                outputs = self.model(data)
                _, preds = outputs.max(1)

                for t, p in zip(target.view(-1), preds.view(-1)):
                    confusion_mat[t.long(), p.long()] += 1

        confusion_mat_percent = confusion_mat.float()
        for i in range(self.config.num_classes):
            row_sum = confusion_mat[i].sum()
            if row_sum > 0:
                confusion_mat_percent[i] = confusion_mat[i] / row_sum * 100

        per_class_acc = confusion_mat.diag() / confusion_mat.sum(1)

        print(f"\n{phase} Report:")
        print("-" * 50)
        print(f"Overall Accuracy: {val_acc*100:.2f}%")
        print(f"Overall Loss: {val_loss:.4f}")

        print("\nPer-class Accuracies:")
        for i, acc in enumerate(per_class_acc):
            print(f"Class {i}: {acc*100:.2f}%")

        plt.figure(figsize=(12, 10))
        sns.heatmap(
            confusion_mat_percent.cpu().numpy(),
            annot=True,
            fmt='.1f',
            cmap='Blues',
            vmin=0,
            vmax=100,
            square=True
        )
        plt.title(f'Confusion Matrix (%) - {phase}')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')

        cbar = plt.gcf().axes[-1]
        cbar.set_ylabel('Percentage (%)', rotation=270, labelpad=15)

        plt.tight_layout()
        plt.show()

        return val_loss, val_acc

    def train(self):
        """Enhanced training loop with metrics collection"""
        best_val_metric = float('inf') if self.is_segmentation else 0

        for epoch in range(self.config.num_epochs):
            self.current_epoch = epoch

            train_loss, train_metric = self.train_epoch()

            self.training_history['train_loss'].append(train_loss)
            if self.is_segmentation:
                self.training_history['train_iou'].append(train_metric)
            else:
                self.training_history['train_acc'].append(train_metric)

            val_metrics = self.validate(self.val_loader)
            val_loss = val_metrics['loss']

            self.training_history['val_loss'].append(val_loss)
            if self.is_segmentation:
                self.training_history['val_iou'].append(val_metrics['mean_iou'])
                self.training_history['val_dice'].append(val_metrics['mean_dice'])
                self.training_history['val_mean_iou'].append(val_metrics['mean_iou'])
                val_metric = val_metrics['mean_iou']
            else:
                self.training_history['val_acc'].append(val_metrics['accuracy'])
                self.training_history['val_f1'].append(val_metrics['f1_score'])
                self.training_history['val_precision'].append(val_metrics['precision'])
                self.training_history['val_recall'].append(val_metrics['recall'])
                val_metric = val_metrics['accuracy']

            current_lr = self.optimizer.param_groups[0]['lr']
            self.training_history['learning_rates'].append(current_lr)

            print(f'Epoch {epoch}/{self.config.num_epochs}:')
            print(f'Train Loss: {train_loss:.4f}    |  Val Loss: {val_loss:.4f}')
            if self.is_segmentation:
                print(f'Train IoU: {train_metric:.4f}  |  Val IoU: {val_metrics["mean_iou"]:.4f}')
                print(f'Val Dice: {val_metrics["mean_dice"]:.4f}\n')
            else:
                print(f'Train Acc: {train_metric:.4f}  |  Val Acc: {val_metrics["accuracy"]:.4f}')
                print(f'Val F1: {val_metrics["f1_score"]:.4f}\n')

            checkpoint = {
                'epoch': epoch,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'metrics': self.training_history,
                'config': self.config,
                'task_config': self.task_config
            }

            is_best = (self.is_segmentation and val_loss < best_val_metric) or \
                     (not self.is_segmentation and val_metric > best_val_metric)

            if is_best:
                best_val_metric = val_loss if self.is_segmentation else val_metric
                torch.save(checkpoint,
                         f'checkpoints/{self.config.dataset_name}/best_{self.task_config.model_type}.pth')

            if self._should_stop_early(val_loss):
                print(f'\nEarly stopping triggered at epoch {epoch+1}')
                break

            self.scheduler.step()

        return self.training_history

    def save_checkpoint(self, filename: str):
        """Save model checkpoint"""
        checkpoint = {
            'epoch': self.current_epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config,
            'task_config': self.task_config,
            'metrics': {
                'train_loss': self.training_history['train_loss'],
                'val_loss': self.training_history['val_loss'],
                'learning_rates': self.training_history['learning_rates']
            }
        }

        if self.is_segmentation:
            checkpoint['metrics'].update({
                'train_iou': self.training_history['train_iou'],
                'val_iou': self.training_history['val_iou'],
                'val_dice': self.training_history['val_dice']
            })
        else:
            checkpoint['metrics'].update({
                'train_acc': self.training_history['train_acc'],
                'val_acc': self.training_history['val_acc'],
                'val_f1': self.training_history['val_f1']
            })

        torch.save(checkpoint, filename)

    def save_metrics(self, filename: str):
        """Save training metrics"""
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        torch.save(self.training_history, filename)

    def test(self):
        """Evaluate on test set"""
        return self.validate(self.test_loader)

def save_checkpoint(state: Dict, filename: str):
    """Save model checkpoint

    Args:
        state: Dictionary containing model state and metadata
        filename: Path to save checkpoint
    """
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    torch.save(state, filename)


def train_one_epoch(model: nn.Module,
                   train_loader: DataLoader,
                   criterion: nn.Module,
                   optimizer: torch.optim.Optimizer,
                   monitor: TrainingMonitor,
                   device: torch.device) -> float:
    """Train for one epoch and return average loss"""
    model.train()
    total_loss = 0

    pbar = tqdm(train_loader, desc='Training')
    for batch_idx, (data, target) in enumerate(pbar):
        data = data.to(device)
        target = target.to(device)

        optimizer.zero_grad()
        outputs = model(data)
        loss = criterion(outputs, target)

        loss.backward()
        optimizer.step()

        monitor.update_metrics(outputs, target)
        monitor.update_loss(loss.item())

        total_loss += loss.item()
        pbar.set_postfix({'loss': total_loss / (batch_idx + 1)})

    return total_loss / len(train_loader)

def validate(model: nn.Module,
            loader: DataLoader,
            criterion: nn.Module,
            device: torch.device,
            task_type: str = 'classification') -> Dict[str, float]:
    """Validate model with proper segmentation handling"""
    model.eval()
    metrics = defaultdict(float)
    num_batches = 0
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for data, target in loader:
            data = data.to(device)
            target = target.to(device)

            # [B, H, W]
            if task_type == 'segmentation':
                if target.dim() == 2:  # If [B, N]
                    B = target.size(0)
                    target = target.reshape(B, 13, 13)
                elif target.dim() == 1:  # If [N]
                    target = target.reshape(-1, 13, 13)

            outputs = model(data)
            if task_type == 'segmentation':
                # [B, C, H, W]
                if outputs.dim() == 3:
                    outputs = outputs.unsqueeze(1)

                preds = outputs.argmax(dim=1)  # [B, H, W]
            else:
                preds = outputs.argmax(dim=1)

            all_preds.append(preds.cpu())
            all_targets.append(target.cpu())

            loss = criterion(outputs, target)
            metrics['loss'] += loss.item()
            num_batches += 1

    all_preds = torch.cat(all_preds, dim=0)
    all_targets = torch.cat(all_targets, dim=0)

    metrics.update(calculate_metrics(all_targets, all_preds, task_type))

    # Average loss
    metrics['loss'] /= num_batches

    return metrics

def train_model(model: nn.Module,
               train_loader: DataLoader,
               val_loader: DataLoader,
               criterion: nn.Module,
               optimizer: torch.optim.Optimizer,
               scheduler: torch.optim.lr_scheduler._LRScheduler,
               num_epochs: int,
               model_name: str,
               dataset_name: str,
               task_type: str,
               device: torch.device) -> Dict:
    """
    Complete training pipeline with monitoring

    Returns:
        Dictionary containing training history and metrics
    """
    monitor = TrainingMonitor(model_name, dataset_name, task_type)

    best_val_loss = float('inf')
    patience_counter = 0

    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")

        train_loss = train_one_epoch(
            model, train_loader, criterion,
            optimizer, monitor, device
        )

        val_loss = validate(
            model, val_loader, criterion,
            monitor, device
        )

        if scheduler:
            scheduler.step()
            monitor.update_learning_rate(
                optimizer.param_groups[0]['lr']
            )

        print(f"Train Loss: {train_loss:.4f}")
        print(f"Val Loss: {val_loss:.4f}")

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            save_checkpoint({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
                'monitor': monitor
            }, f'checkpoints/{dataset_name}/best_{model_name}.pth')
        else:
            patience_counter += 1

        if patience_counter >= 15:
            print("Early stopping triggered")
            break

        if (epoch + 1) % 10 == 0:
            monitor.plot_training_progress()

    monitor.plot_final_metrics()

    return monitor.history


def train_selected_datasets(models: List[str], task_type: str = 'classification'):
    """Train models on selected datasets"""
    results = {}

    for dataset_name in SELECTED_DATASET:
        results[dataset_name] = {}
        print(f"\nProcessing dataset: {dataset_name.upper()}")

        dataset_config = dataset_configs[dataset_name]

        for model_name in models:
            print(f"\nTraining {model_name.upper()} on {dataset_name}")

            try:
                task_config = TaskConfig(
                    task_type=task_type,
                    model_type=model_name,
                    dataset_name=dataset_name,
                    in_channels=dataset_config['in_channels'],
                    num_classes=dataset_config['num_classes']
                )

                train_config = TrainingConfig(
                    dataset_name=dataset_name,
                    in_channels=dataset_config['in_channels'],
                    num_classes=dataset_config['num_classes'],
                    batch_size=32,
                    num_epochs=100
                )

                trainer = Trainer(train_config, task_config)
                metrics = trainer.train()

                test_metrics = trainer.validate(trainer.test_loader)

                results[dataset_name][model_name] = {
                    'test_metrics': test_metrics,
                    'training_history': metrics
                }

                print(f"\nTest Results for {model_name} on {dataset_name}:")
                if task_type == 'classification':
                    print(f"Test Accuracy: {test_metrics['accuracy']:.4f}")
                    print(f"Test F1 Score: {test_metrics['f1_score']:.4f}")
                else:
                    print(f"Test IoU: {test_metrics['mean_iou']:.4f}")
                    print(f"Test Dice Score: {test_metrics['mean_dice']:.4f}")

                save_dir = 'results'
                os.makedirs(save_dir, exist_ok=True)
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                torch.save({
                    'results': results,
                    'datasets': SELECTED_DATASET,
                    'models': models,
                    'timestamp': timestamp
                }, os.path.join(save_dir, f'training_results_{timestamp}.pt'))

            except Exception as e:
                print(f"Error training {model_name} on {dataset_name}: {str(e)}")
                continue

    return results

def plot_training_curves(metrics: Dict, dataset: str, model_type: str):
    """Plot training curves"""
    plt.figure(figsize=(15, 5))

    plt.subplot(131)
    plt.plot(metrics['train_loss'], label='Train')
    plt.plot(metrics['val_loss'], label='Val')
    plt.title(f'{dataset} - {model_type} Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(132)
    plt.plot(metrics['train_acc'], label='Train')
    plt.plot(metrics['val_acc'], label='Val')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(133)
    plt.plot(metrics['learning_rates'])
    plt.title('Learning Rate')
    plt.xlabel('Epoch')
    plt.ylabel('LR')
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

"""### Initial Training and Validating"""

if __name__ == "__main__":
    torch.manual_seed(42)
    np.random.seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    for dataset_name in SELECTED_DATASET:
        os.makedirs(f'checkpoints/{dataset_name}', exist_ok=True)
        os.makedirs('results', exist_ok=True)

    print("\nTraining Configuration:")
    print("="*50)
    print(f"Selected Datasets: {SELECTED_DATASET}")
    print(f"Models: {models}")

    results = {}

    for dataset_name in SELECTED_DATASET:
        results[dataset_name] = {}
        print(f"\nProcessing {dataset_name.upper()}")

        dataset_config = dataset_configs[dataset_name]

        for model_name in models:
            print(f"\nTraining {model_name.upper()} on {dataset_name}")
            try:
                task_type = 'segmentation' if model_name in ['unet', 'fcn'] else 'classification'

                task_config = TaskConfig(
                    task_type=task_type,
                    model_type=model_name,
                    dataset_name=dataset_name,
                    in_channels=dataset_config['in_channels'],
                    num_classes=dataset_config['num_classes']
                )

                train_config = TrainingConfig(
                    dataset_name=dataset_name,
                    in_channels=dataset_config['in_channels'],
                    num_classes=dataset_config['num_classes'],
                    batch_size=32,
                    num_epochs=100
                )

                trainer = Trainer(train_config, task_config)

                print("\nStarting training...")
                training_history = trainer.train()

                print("\nEvaluating on test set...")
                test_metrics = trainer.test()

                results[dataset_name][model_name] = {
                    'test_metrics': test_metrics,
                    'training_history': training_history
                }

                checkpoint_path = f'checkpoints/{dataset_name}/best_{model_name}.pth'
                metrics_path = f'checkpoints/{dataset_name}/{model_name}_metrics.pt'

                try:
                    trainer.save_checkpoint(checkpoint_path)

                    trainer.save_metrics(metrics_path)
                except Exception as save_error:
                    print(f"Error saving checkpoint/metrics: {str(save_error)}")

                timestamp = time.strftime("%Y%m%d_%H%M%S")
                results_path = f'results/training_results_{timestamp}.pt'
                try:
                    torch.save({
                        'results': results,
                        'datasets': SELECTED_DATASET,
                        'models': models,
                        'timestamp': timestamp
                    }, results_path)
                    print(f"\nResults saved to {results_path}")
                except Exception as save_error:
                    print(f"Error saving results: {str(save_error)}")

            except Exception as e:
                print(f"Error training {model_name} on {dataset_name}: {str(e)}")
                traceback.print_exc()
                continue

    print("\nTraining completed!")

"""### Training and Validation (when OVERFITTING presnet)"""

class UnifiedModelTrainer:
    """Unified training pipeline for all model types"""
    def __init__(self, model_type: str, dataset_name: str):
        self.model_type = model_type
        self.dataset_name = dataset_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        dataset_config = get_dataset_config(dataset_name)
        self.config = SimpleNamespace(
            in_channels=dataset_config['in_channels'],
            num_classes=dataset_config['num_classes'],
            spatial_size=dataset_config['spatial_size']
        )

        self.model = self._create_model().to(self.device)

        self.train_metrics = {
            'loss': [],
            'acc': [],
            'precision': [],
            'recall': [],
            'f1': [],
            'iou': [],
            'dice': [],
            'confusion_matrix': [],
            'learning_rates': []
        }
        self.val_metrics = {
            'loss': [],
            'acc': [],
            'precision': [],
            'recall': [],
            'f1': [],
            'iou': [],
            'dice': [],
            'confusion_matrix': []
        }
        self.best_val_metric = 0.0

        self.setup_training()

    def _create_model(self):
        """Create model based on type"""
        if self.model_type == 'resnet':
            return create_model(self.dataset_name)
        elif self.model_type == 'vit':
            return create_vit_model(self.dataset_name)
        elif self.model_type == '3dcnn':
            return create_3dcnn_model(self.dataset_name)
        elif self.model_type == 'hybrid':
            return create_hybrid_model(self.dataset_name)
        elif self.model_type == 'unet':
            return create_unet_model(self.dataset_name)
        elif self.model_type == 'fcn':
            return create_fcn_model(self.dataset_name)
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")

    def save_comprehensive_checkpoint(self, filename):
        """Save complete checkpoint with training history, model, optimizer, and scheduler states"""
        dataset_config = get_dataset_config(self.dataset_name)

        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'train_metrics': self.train_metrics,
            'val_metrics': self.val_metrics,
            'config': {
                'dataset_name': self.dataset_name,
                'model_type': self.model_type,
                'task_type': self.task_type,
                'in_channels': dataset_config['in_channels'],
                'num_classes': dataset_config['num_classes'],
                'spatial_size': dataset_config['spatial_size'],
                'class_names': dataset_config['class_names']
            },
        }

        os.makedirs(os.path.dirname(filename), exist_ok=True)

        torch.save(checkpoint, filename)
        print(f"Checkpoint saved to {filename}")

    def setup_training(self):
        """Initialize training components with proper loss initialization"""
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

        if self.model_type in ['unet', 'fcn']:
            self.criterion = DiceLoss(
                num_classes=get_dataset_config(self.dataset_name)['num_classes']
            ).to(self.device)
            self.task_type = 'segmentation'
        else:
            self.criterion = WeightedCrossEntropyLoss(
                num_classes=get_dataset_config(self.dataset_name)['num_classes']
            ).to(self.device)
            self.task_type = 'classification'

        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=1e-3,
            weight_decay=1e-4,
            betas=(0.9, 0.999),
            eps=1e-8
        )

        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=30, gamma=0.1)

        self.scheduler = CustomLRScheduler(
            self.optimizer,
            OptimizerConfig(
                learning_rate=1e-3,
                total_epochs=100,
                warmup_epochs=5
            )
        )


    def create_data_loaders(self):
        """Create data loaders without augmentation"""
        data = process_hyperspectral_data(self.dataset_name, silent=True)
        splits = split_dataset(data)

        task_type = 'segmentation' if self.model_type in ['unet', 'fcn'] else 'classification'

        batch_size = 4

        train_dataset = HyperspectralDataset(
            splits['patch_data']['train'][0],
            splits['patch_data']['train'][1],
            self.dataset_name,
            task_type=task_type
        )
        val_dataset = HyperspectralDataset(
            splits['patch_data']['val'][0],
            splits['patch_data']['val'][1],
            self.dataset_name,
            task_type=task_type
        )
        test_dataset = HyperspectralDataset(
            splits['patch_data']['test'][0],
            splits['patch_data']['test'][1],
            self.dataset_name,
            task_type=task_type
        )

        train_loader = DataLoader(
            train_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=0,
            pin_memory=False
        )
        val_loader = DataLoader(
            val_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=False
        )
        test_loader = DataLoader(
            test_dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=0,
            pin_memory=False
        )

        return train_loader, val_loader, test_loader

    def train_epoch(self):
        """Train for one epoch with simplified metrics tracking"""
        self.model.train()
        total_loss = 0
        total_correct = 0
        total_samples = 0

        pbar = tqdm(self.train_loader, desc='Training')
        for data, target in pbar:
            data = data.to(self.device)
            target = target.to(self.device)

            output = self.model(data)

            if self.task_type == 'classification':
                target = target.view(-1) if target.dim() > 1 else target
            else:
                target = target.view(-1, self.config.spatial_size, self.config.spatial_size)

            loss = self.criterion(output, target)
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            with torch.no_grad():
                total_loss += loss.item()
                if self.task_type == 'classification':
                    pred = output.argmax(1)
                    total_correct += pred.eq(target).sum().item()
                else:
                    pred = output.argmax(1)
                    total_correct += (pred == target).float().mean().item() * target.size(0)
                total_samples += target.size(0)

            pbar.set_postfix({
                'loss': total_loss / (pbar.n + 1),
                'acc': 100. * total_correct / total_samples
            })

        return total_loss / len(self.train_loader), total_correct / total_samples

    def validate(self, loader=None):
        """Validation step with proper task handling"""
        if loader is None:
            loader = self.val_loader

        self.model.eval()
        total_loss = 0
        total_correct = 0
        total_samples = 0
        all_preds = []
        all_targets = []

        with torch.no_grad():
            for data, target in loader:
                data = data.to(self.device)
                target = target.to(self.device)

                output = self.model(data)

                if self.task_type == 'classification':
                    if target.dim() > 1:
                        target = target.view(-1)
                else:
                    if target.dim() == 1:
                        target = target.view(-1, 13, 13)

                loss = self.criterion(output, target)

                total_loss += loss.item()

                if self.task_type == 'classification':
                    pred = output.argmax(1)
                    total_correct += pred.eq(target).sum().item()
                    all_preds.append(pred.cpu().numpy())
                    all_targets.append(target.cpu().numpy())
                else:
                    pred = output.argmax(1)
                    total_correct += (pred == target).float().mean().item() * target.size(0)
                    all_preds.append(pred.cpu().numpy().flatten())
                    all_targets.append(target.cpu().numpy().flatten())

                total_samples += target.size(0)

        all_preds = np.concatenate(all_preds)
        all_targets = np.concatenate(all_targets)

        metrics = {
            'loss': total_loss / len(loader),
            'acc': total_correct / total_samples,
            'precision': precision_score(all_targets, all_preds, average='macro'),
            'recall': recall_score(all_targets, all_preds, average='macro'),
            'f1': f1_score(all_targets, all_preds, average='macro'),
        }

        if self.task_type == 'segmentation':
            metrics['iou'] = jaccard_score(all_targets, all_preds, average='macro')
            metrics['dice'] = f1_score(all_targets, all_preds, average='macro')

        metrics['confusion_matrix'] = confusion_matrix(all_targets, all_preds)

        return metrics

    def train(self):
        """Memory-efficient training loop"""
        print(f"Training {self.model_type} on {self.device}")
        best_metric = float('inf') if self.task_type == 'segmentation' else 0
        patience_counter = 0

        try:
            for epoch in range(100):
                torch.cuda.empty_cache() if torch.cuda.is_available() else None

                print(f"\nEpoch {epoch+1}/100")

                train_loss, train_acc = self.train_epoch()
                self.train_metrics['loss'].append(train_loss)
                self.train_metrics['acc'].append(train_acc)

                val_metrics = self.validate()
                for metric, value in val_metrics.items():
                    if isinstance(value, (int, float)):
                        self.val_metrics[metric].append(value)

                self.scheduler.step()
                current_lr = self.optimizer.param_groups[0]['lr']

                print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")
                print(f"Val Loss: {val_metrics['loss']:.4f}, Val Acc: {val_metrics['acc']:.4f}")
                print(f"Learning Rate: {current_lr:.6f}")

                curr_metric = val_metrics['loss'] if self.task_type == 'segmentation' else val_metrics['acc']
                if (self.task_type == 'segmentation' and curr_metric < best_metric) or \
                  (self.task_type == 'classification' and curr_metric > best_metric):
                    best_metric = curr_metric
                    self.save_comprehensive_checkpoint(f'checkpoints/{self.dataset_name}/best_{self.model_type}.pth')
                    patience_counter = 0
                else:
                    patience_counter += 1

                if patience_counter >= 15:
                    print("Early stopping triggered")
                    break

                if (epoch + 1) % 20 == 0:
                    self.plot_metrics()
                    plt.close('all')

        except Exception as e:
            print(f"Training error: {str(e)}")
            traceback.print_exc()
        finally:
            torch.cuda.empty_cache() if torch.cuda.is_available() else None

        return self.train_metrics, self.val_metrics

    def plot_metrics(self):
        """Plot training and validation metrics during training"""
        plt.figure(figsize=(15, 10))

        plt.subplot(2, 2, 1)
        plt.plot(self.train_metrics['loss'], label='Train')
        plt.plot(self.val_metrics['loss'], label='Validation')
        plt.title('Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 2, 2)
        plt.plot(self.train_metrics['acc'], label='Train')
        plt.plot(self.val_metrics['acc'], label='Validation')
        plt.title('Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.grid(True, alpha=0.3)

        if self.task_type == 'classification':
            plt.subplot(2, 2, 3)
            if 'f1' in self.val_metrics and len(self.val_metrics['f1']) > 0:
                plt.plot(self.val_metrics['f1'], label='F1 Score')
                plt.title('F1 Score')
                plt.xlabel('Epoch')
                plt.ylabel('Score')
                plt.legend()
                plt.grid(True, alpha=0.3)
        else:
            plt.subplot(2, 2, 3)
            if 'iou' in self.val_metrics and len(self.val_metrics['iou']) > 0:
                plt.plot(self.val_metrics['iou'], label='IoU')
            if 'dice' in self.val_metrics and len(self.val_metrics['dice']) > 0:
                plt.plot(self.val_metrics['dice'], label='Dice')
            plt.title('Segmentation Metrics')
            plt.xlabel('Epoch')
            plt.ylabel('Score')
            plt.legend()
            plt.grid(True, alpha=0.3)

        plt.subplot(2, 2, 4)
        if len(self.train_metrics['learning_rates']) > 0:
            plt.plot(self.train_metrics['learning_rates'])
            plt.title('Learning Rate')
            plt.xlabel('Epoch')
            plt.ylabel('Learning Rate')
            plt.yscale('log')
            plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

def main():
    """Train all models on all datasets with memory management"""
    torch.manual_seed(42)
    np.random.seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
        torch.cuda.empty_cache()

    os.makedirs("checkpoints", exist_ok=True)
    os.makedirs("results", exist_ok=True)

    for dataset_name in SELECTED_DATASET:
        print(f"\nProcessing {dataset_name.upper()}")

        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()

        for model_type in models:
            print(f"\nTraining {model_type.upper()}")

            try:
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()

                trainer = UnifiedModelTrainer(model_type, dataset_name)

                train_metrics, val_metrics = trainer.train()

                results_dir = Path(f"results/{dataset_name}")
                results_dir.mkdir(parents=True, exist_ok=True)
                torch.save({
                    'train_metrics': train_metrics,
                    'val_metrics': val_metrics,
                    'model_type': model_type,
                    'dataset': dataset_name
                }, results_dir / f"{model_type}_results.pt")

                del trainer
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()

            except Exception as e:
                print(f"Error training {model_type} on {dataset_name}: {str(e)}")
                traceback.print_exc()
                continue

        print(f"Completed training all models for {dataset_name}")

if __name__ == "__main__":
    main()

"""# 8.Results and Visualization

## Charts
"""

def plot_overall_metrics(dataset_name, classification_metrics, segmentation_metrics, classification_models, segmentation_models):
    print("\nVisualizing Overall Metrics...")

    if classification_metrics['accuracy']:
        plt.figure(figsize=(10, 6))
        x = np.arange(len(classification_models))
        width = 0.2
        plt.bar(x - width*1.5, classification_metrics['accuracy'], width, label='Accuracy')
        plt.bar(x - width/2, classification_metrics['precision'], width, label='Precision')
        plt.bar(x + width/2, classification_metrics['recall'], width, label='Recall')
        plt.bar(x + width*1.5, classification_metrics['f1'], width, label='F1 Score')
        plt.xlabel('Models')
        plt.ylabel('Metrics')
        plt.title(f'Overall Classification Metrics - {dataset_name}')
        plt.xticks(x, classification_models)
        plt.legend()
        plt.tight_layout()
        plt.show()

    if segmentation_metrics['iou']:
        plt.figure(figsize=(8, 6))
        x = np.arange(len(segmentation_models))
        width = 0.35
        plt.bar(x - width/2, segmentation_metrics['iou'], width, label='IoU')
        plt.bar(x + width/2, segmentation_metrics['dice'], width, label='Dice')
        plt.xlabel('Models')
        plt.ylabel('Metrics')
        plt.title(f'Overall Segmentation Metrics - {dataset_name}')
        plt.xticks(x, segmentation_models)
        plt.legend()
        plt.tight_layout()
        plt.show()

def plot_accuracy_curves(dataset_name, models):
    print("\nVisualizing Accuracy Curves...")

    for model_type in models:
        results_file = Path(f"results/{dataset_name}/{model_type}_results.pt")
        if results_file.exists():
            results = torch.load(results_file)
            plt.figure(figsize=(8, 6))
            plt.plot(results['train_metrics']['acc'], label='Train')
            plt.plot(results['val_metrics']['acc'], label='Validation')
            plt.xlabel('Epoch')
            plt.ylabel('Accuracy')
            plt.title(f'Accuracy Curves - {model_type} on {dataset_name}')
            plt.legend()
            plt.tight_layout()
            plt.show()

def plot_precision_recall_curves(dataset_name, classification_models):
    print("\nVisualizing Precision-Recall Curves...")

    for model_type in classification_models:
        results_file = Path(f"results/{dataset_name}/{model_type}_results.pt")
        if results_file.exists():
            results = torch.load(results_file)
            precision = results['val_metrics']['precision']
            recall = results['val_metrics']['recall']
            plt.figure(figsize=(8, 6))
            plt.plot(recall, precision)
            plt.xlabel('Recall')
            plt.ylabel('Precision')
            plt.title(f'Precision-Recall Curve - {model_type} on {dataset_name}')
            plt.tight_layout()
            plt.show()

def plot_iou_dice_curves(dataset_name, segmentation_models):
    print("\nVisualizing IoU/Dice Curves...")

    for model_type in segmentation_models:
        results_file = Path(f"results/{dataset_name}/{model_type}_results.pt")
        if results_file.exists():
            results = torch.load(results_file)
            plt.figure(figsize=(8, 6))
            plt.plot(results['train_metrics']['iou'], label='Train IoU')
            plt.plot(results['val_metrics']['iou'], label='Validation IoU')
            plt.plot(results['train_metrics']['dice'], label='Train Dice')
            plt.plot(results['val_metrics']['dice'], label='Validation Dice')
            plt.xlabel('Epoch')
            plt.ylabel('Metric')
            plt.title(f'IoU/Dice Curves - {model_type} on {dataset_name}')
            plt.legend()
            plt.tight_layout()
            plt.show()

def plot_classification_maps(dataset_name, classification_models, device):
    """Visualize classification maps with proper shape handling"""
    print("\nVisualizing Classification Maps...")

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            if checkpoint is None:
                continue

            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            print(f"Successfully loaded weights for {model_type}")
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()

                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            dataset_config = get_dataset_config(dataset_name)
            H, W = dataset_config['spatial_size'], dataset_config['spatial_size']

            grid_size = int(np.ceil(np.sqrt(len(all_preds))))
            plot_shape = (grid_size * H, grid_size * W)

            pred_grid = np.zeros(plot_shape)
            target_grid = np.zeros(plot_shape)

            for idx in range(len(all_preds)):
                i, j = (idx // grid_size) * H, (idx % grid_size) * W
                pred_grid[i:i+H, j:j+W] = all_preds[idx]
                target_grid[i:i+H, j:j+W] = all_targets[idx]

            plt.figure(figsize=(15, 7))

            plt.subplot(1, 2, 1)
            plt.imshow(pred_grid, cmap='jet')
            plt.title('Predicted Classification Map')
            plt.axis('off')

            plt.subplot(1, 2, 2)
            plt.imshow(target_grid, cmap='jet')
            plt.title('Ground Truth')
            plt.axis('off')

            plt.suptitle(f'Classification Maps - {model_type} on {dataset_name}')
            plt.tight_layout()
            plt.show()

            accuracy = np.mean(all_preds == all_targets)
            print(f"Test Accuracy for {model_type}: {accuracy:.4f}")

        except Exception as e:
            print(f"Error plotting classification maps for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def plot_segmentation_maps(dataset_name, segmentation_models, device):
    """Visualize segmentation maps with proper error handling"""
    print("\nVisualizing Segmentation Maps...")

    for model_type in segmentation_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='segmentation'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            dataset_config = get_dataset_config(dataset_name)
            H, W = dataset_config['spatial_size'], dataset_config['spatial_size']

            grid_size = int(np.ceil(np.sqrt(len(all_preds))))
            plot_shape = (grid_size * H, grid_size * W)

            pred_grid = np.zeros(plot_shape)
            target_grid = np.zeros(plot_shape)

            for idx in range(len(all_preds)):
                i, j = (idx // grid_size) * H, (idx % grid_size) * W
                pred_grid[i:i+H, j:j+W] = all_preds[idx]
                target_grid[i:i+H, j:j+W] = all_targets[idx]

            plt.figure(figsize=(15, 7))

            plt.subplot(1, 2, 1)
            plt.imshow(pred_grid, cmap='jet')
            plt.title(f'Predicted Segmentation - {model_type}')
            plt.axis('off')

            plt.subplot(1, 2, 2)
            plt.imshow(target_grid, cmap='jet')
            plt.title('Ground Truth')
            plt.axis('off')

            plt.suptitle(f'Segmentation Maps - {model_type} on {dataset_name}')
            plt.tight_layout()
            plt.show()

            iou = np.mean(np.equal(all_preds, all_targets))
            print(f"\nSegmentation IoU for {model_type}: {iou:.4f}")

        except Exception as e:
            print(f"Error plotting segmentation maps for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def plot_confusion_matrix(dataset_name, classification_models, device):
    """Visualize confusion matrices with proper error handling"""
    print("\nVisualizing Confusion Matrices...")

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            cm = confusion_matrix(all_targets, all_preds)

            plt.figure(figsize=(12, 10))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                       xticklabels=test_dataset.class_names,
                       yticklabels=test_dataset.class_names)
            plt.title(f'Confusion Matrix - {model_type} on {dataset_name}')
            plt.xlabel('Predicted')
            plt.ylabel('True')
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            plt.tight_layout()
            plt.show()

            accuracy = np.mean(all_preds == all_targets)
            print(f"\nConfusion Matrix Accuracy for {model_type}: {accuracy:.4f}")

        except Exception as e:
            print(f"Error plotting confusion matrix for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def plot_roc_curves(dataset_name, classification_models, device):
    """Visualize ROC curves with proper error handling"""
    print("\nVisualizing ROC Curves...")

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_probs = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    probs = torch.softmax(output, dim=1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_probs.append(probs)
                    all_targets.append(targets)

            all_probs = np.concatenate(all_probs, axis=0)
            all_targets = np.concatenate(all_targets)

            plt.figure(figsize=(12, 8))
            for i in range(len(test_dataset.class_names)):
                fpr, tpr, _ = roc_curve(all_targets == i, all_probs[:, i])
                roc_auc = auc(fpr, tpr)

                plt.plot(fpr, tpr, label=f'{test_dataset.class_names[i]} (AUC = {roc_auc:.2f})')

            plt.plot([0, 1], [0, 1], 'k--', label='Random')
            plt.xlabel('False Positive Rate')
            plt.ylabel('True Positive Rate')
            plt.title(f'ROC Curves - {model_type} on {dataset_name}')
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.tight_layout()
            plt.grid(True)
            plt.show()

        except Exception as e:
            print(f"Error plotting ROC curves for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def plot_error_analysis(dataset_name, classification_models, device):
    """Visualize error analysis with proper error handling"""
    print("\nVisualizing Error Analysis...")

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            incorrect_mask = all_preds != all_targets
            incorrect_indices = np.where(incorrect_mask)[0]

            if len(incorrect_indices) > 0:
                incorrect_preds = all_preds[incorrect_mask]
                incorrect_targets = all_targets[incorrect_mask]

                plt.figure(figsize=(15, 8))

                plt.subplot(1, 2, 1)
                plt.scatter(incorrect_indices, incorrect_preds, c='red', label='Predicted', alpha=0.6)
                plt.scatter(incorrect_indices, incorrect_targets, c='blue', label='Actual', alpha=0.6)
                plt.xlabel('Sample Index')
                plt.ylabel('Class')
                plt.title('Misclassified Samples')
                plt.legend()
                plt.grid(True)

                plt.subplot(1, 2, 2)
                error_counts = {}
                for pred, target in zip(incorrect_preds, incorrect_targets):
                    error_pair = (target, pred)
                    error_counts[error_pair] = error_counts.get(error_pair, 0) + 1

                error_labels = [f"{test_dataset.class_names[t]}→{test_dataset.class_names[p]}"
                              for (t, p) in error_counts.keys()]
                plt.bar(error_labels, error_counts.values())
                plt.xticks(rotation=45, ha='right')
                plt.ylabel('Count')
                plt.title('Error Distribution')

                plt.suptitle(f'Error Analysis - {model_type} on {dataset_name}')
                plt.tight_layout()
                plt.show()

                print(f"\nError Analysis Summary for {model_type}:")
                print(f"Total samples: {len(all_targets)}")
                print(f"Incorrect predictions: {len(incorrect_indices)}")
                print(f"Accuracy: {1 - len(incorrect_indices)/len(all_targets):.4f}")
            else:
                print(f"\nNo errors found for {model_type}!")

        except Exception as e:
            print(f"Error in error analysis for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def print_classification_report(dataset_name, classification_models, device):
    """Print classification report with proper error handling"""
    print("\nClassification Report...")

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            print(f"\nClassification Report for {model_type} on {dataset_name}:")
            print(classification_report(
                all_targets,
                all_preds,
                target_names=test_dataset.class_names,
                digits=4
            ))

            cm = confusion_matrix(all_targets, all_preds)
            print("\nConfusion Matrix:")
            print(cm)

        except Exception as e:
            print(f"Error generating classification report for {model_type}: {str(e)}")
            traceback.print_exc()
            continue



def load_checkpoint(checkpoint_file: Path) -> Dict:
    """Load checkpoint with flexible state dict loading"""
    try:
        checkpoint = torch.load(checkpoint_file, map_location='cpu')

        required_keys = ['model_state_dict', 'optimizer_state_dict', 'config']
        if not all(key in checkpoint for key in required_keys):
            print(f"Warning: Checkpoint missing some expected keys: {checkpoint.keys()}")

        return checkpoint

    except Exception as e:
        print(f"Error loading checkpoint {checkpoint_file}: {str(e)}")
        raise

def create_specific_model(model_type: str, dataset_name: str) -> nn.Module:
    """
    Create a model instance based on model type

    Args:
        model_type: Type of model to create
        dataset_name: Name of dataset for model configuration

    Returns:
        Instantiated model
    """
    if model_type == 'resnet':
        return create_model(dataset_name)
    elif model_type == 'vit':
        return create_vit_model(dataset_name)
    elif model_type == '3dcnn':
        return create_3dcnn_model(dataset_name)
    elif model_type == 'hybrid':
        return create_hybrid_model(dataset_name)
    elif model_type == 'unet':
        return create_unet_model(dataset_name)
    elif model_type == 'fcn':
        return create_fcn_model(dataset_name)
    else:
        raise ValueError(f"Unknown model type: {model_type}")

def main():
    """Main visualization function with error handling"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    classification_models = ['resnet', 'vit', '3dcnn', 'hybrid']
    segmentation_models = ['unet', 'fcn']

    for dataset_name in SELECTED_DATASET:
        print(f"\nVisualizing results for {dataset_name.upper()}")

        results_dir = Path(f"results/{dataset_name}")
        if not results_dir.exists():
            print(f"No results directory found for {dataset_name}")
            continue

        try:
            classification_metrics = {
                'accuracy': [], 'precision': [], 'recall': [], 'f1': []
            }
            segmentation_metrics = {
                'iou': [], 'dice': []
            }

            for model_type in classification_models + segmentation_models:
                try:
                    results_file = Path(f"results/{dataset_name}/{model_type}_results.pt")
                    if not results_file.exists():
                        print(f"No results found for {model_type} on {dataset_name}")
                        continue

                    results = torch.load(results_file)

                    if model_type in classification_models:
                        classification_metrics['accuracy'].append(results['val_metrics']['acc'][-1])
                        classification_metrics['precision'].append(results['val_metrics']['precision'][-1])
                        classification_metrics['recall'].append(results['val_metrics']['recall'][-1])
                        classification_metrics['f1'].append(results['val_metrics']['f1'][-1])
                    else:
                        segmentation_metrics['iou'].append(results['val_metrics']['iou'][-1])
                        segmentation_metrics['dice'].append(results['val_metrics']['dice'][-1])

                except Exception as e:
                    print(f"Error processing results for {model_type}: {str(e)}")
                    continue

            if any(len(metric) > 0 for metric in classification_metrics.values()):
                plot_overall_metrics(dataset_name, classification_metrics, segmentation_metrics,
                                  classification_models, segmentation_models)
                plot_accuracy_curves(dataset_name, classification_models + segmentation_models)
                plot_precision_recall_curves(dataset_name, classification_models)
                plot_classification_maps(dataset_name, classification_models, device)
                plot_confusion_matrix(dataset_name, classification_models, device)
                plot_roc_curves(dataset_name, classification_models, device)
                plot_error_analysis(dataset_name, classification_models, device)
                print_classification_report(dataset_name, classification_models, device)

            if any(len(metric) > 0 for metric in segmentation_metrics.values()):
                plot_iou_dice_curves(dataset_name, segmentation_models)
                plot_segmentation_maps(dataset_name, segmentation_models, device)

            plt.close('all')
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()

        except Exception as e:
            print(f"Error processing dataset {dataset_name}: {str(e)}")
            continue

if __name__ == "__main__":
    main()

"""### Charts color graded and normalized"""

def plot_overall_metrics(dataset_name, classification_metrics, segmentation_metrics, classification_models, segmentation_models):
    print("\nVisualizing Overall Metrics...")

    if classification_metrics['accuracy']:
        plt.figure(figsize=(10, 6))
        x = np.arange(len(classification_models))
        width = 0.2
        plt.bar(x - width*1.5, classification_metrics['accuracy'], width, label='Accuracy')
        plt.bar(x - width/2, classification_metrics['precision'], width, label='Precision')
        plt.bar(x + width/2, classification_metrics['recall'], width, label='Recall')
        plt.bar(x + width*1.5, classification_metrics['f1'], width, label='F1 Score')
        plt.xlabel('Models')
        plt.ylabel('Metrics')
        plt.title(f'Overall Classification Metrics - {dataset_name}')
        plt.xticks(x, classification_models)
        plt.legend()
        plt.tight_layout()
        plt.show()

    if segmentation_metrics['iou']:
        plt.figure(figsize=(8, 6))
        x = np.arange(len(segmentation_models))
        width = 0.35
        plt.bar(x - width/2, segmentation_metrics['iou'], width, label='IoU')
        plt.bar(x + width/2, segmentation_metrics['dice'], width, label='Dice')
        plt.xlabel('Models')
        plt.ylabel('Metrics')
        plt.title(f'Overall Segmentation Metrics - {dataset_name}')
        plt.xticks(x, segmentation_models)
        plt.legend()
        plt.tight_layout()
        plt.show()

def plot_accuracy_curves(dataset_name, models):
    print("\nVisualizing Accuracy Curves...")

    for model_type in models:
        results_file = Path(f"results/{dataset_name}/{model_type}_results.pt")
        if results_file.exists():
            results = torch.load(results_file)
            plt.figure(figsize=(8, 6))
            plt.plot(results['train_metrics']['acc'], label='Train')
            plt.plot(results['val_metrics']['acc'], label='Validation')
            plt.xlabel('Epoch')
            plt.ylabel('Accuracy')
            plt.title(f'Accuracy Curves - {model_type} on {dataset_name}')
            plt.legend()
            plt.tight_layout()
            plt.show()

def plot_precision_recall_curves(dataset_name, classification_models):
    print("\nVisualizing Precision-Recall Curves...")

    for model_type in classification_models:
        results_file = Path(f"results/{dataset_name}/{model_type}_results.pt")
        if results_file.exists():
            results = torch.load(results_file)
            precision = results['val_metrics']['precision']
            recall = results['val_metrics']['recall']
            plt.figure(figsize=(8, 6))
            plt.plot(recall, precision)
            plt.xlabel('Recall')
            plt.ylabel('Precision')
            plt.title(f'Precision-Recall Curve - {model_type} on {dataset_name}')
            plt.tight_layout()
            plt.show()

def plot_iou_dice_curves(dataset_name, segmentation_models):
    print("\nVisualizing IoU/Dice Curves...")

    for model_type in segmentation_models:
        results_file = Path(f"results/{dataset_name}/{model_type}_results.pt")
        if results_file.exists():
            results = torch.load(results_file)

            plt.figure(figsize=(12, 8))

            if len(results['val_metrics']['iou']) > 0:
                plt.plot(results['val_metrics']['iou'],
                        linestyle='-',
                        linewidth=2,
                        color='#F4B942',
                        label='Validation IoU')

                plt.plot(results['val_metrics']['dice'],
                        linestyle='--',
                        linewidth=2,
                        color='#E15759',
                        label='Validation Dice')

            if len(results['train_metrics'].get('iou', [])) > 0:
                plt.plot(results['train_metrics']['iou'],
                        linestyle='-',
                        linewidth=2,
                        color='#2D7DB3',
                        label='Train IoU')

                plt.plot(results['train_metrics']['dice'],
                        linestyle='--',
                        linewidth=2,
                        color='#4FB477',
                        label='Train Dice')
            else:
                print(f"\nNote: Training metrics not available for {model_type}")

            plt.xlabel('Epoch')
            plt.ylabel('Metric')
            plt.title(f'IoU/Dice Curves - {model_type} on {dataset_name}')
            plt.legend(loc='lower right')
            plt.grid(True, linestyle='--', alpha=0.3)

            plt.minorticks_on()
            plt.grid(True, which='minor', linestyle=':', alpha=0.2)

            plt.tight_layout()
            plt.show()

def plot_segmentation_maps(dataset_name, segmentation_models, device):
    """Visualize segmentation maps with proper error handling and custom colors"""
    print("\nVisualizing Segmentation Maps...")

    base_colors = ['#4E79A7', '#F28E2B', '#E15759', '#76B7B2', '#59A14F',
                   '#EDC948', '#B07AA1', '#FF9DA7', '#9C755F', '#BAB0AC',
                   '#808080', '#D4A797', '#A0CBE8', '#F1CE63', '#D4A6C8',
                   '#9D7660', '#D7B5A6', '#B279A2', '#D6BCC0', '#BB7693']

    def get_extended_colors(n_classes):
        if n_classes <= len(base_colors):
            return base_colors[:n_classes]
        else:
            additional_colors = []
            for i in range(n_classes - len(base_colors)):
                h = i / (n_classes - len(base_colors))
                rgb = colorsys.hsv_to_rgb(h, 1.0, 1.0)
                additional_colors.append('#{:02x}{:02x}{:02x}'.format(
                    int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255)))
            return base_colors + additional_colors

    for model_type in segmentation_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='segmentation'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            dataset_config = get_dataset_config(dataset_name)
            H, W = dataset_config['spatial_size'], dataset_config['spatial_size']
            n_classes = len(dataset_config['class_names'])
            class_colors = get_extended_colors(n_classes)
            custom_cmap = ListedColormap(class_colors)

            grid_size = int(np.ceil(np.sqrt(len(all_preds))))
            plot_shape = (grid_size * H, grid_size * W)

            pred_grid = np.zeros(plot_shape)
            target_grid = np.zeros(plot_shape)

            for idx in range(len(all_preds)):
                i, j = (idx // grid_size) * H, (idx % grid_size) * W
                pred_grid[i:i+H, j:j+W] = all_preds[idx]
                target_grid[i:i+H, j:j+W] = all_targets[idx]

            fig = plt.figure(figsize=(20, 8))
            gs = gridspec.GridSpec(1, 3, width_ratios=[10, 10, 3])

            ax1 = plt.subplot(gs[0])
            im1 = ax1.imshow(pred_grid, cmap=custom_cmap)
            ax1.set_title(f'Predicted Segmentation - {model_type}', pad=20)
            ax1.axis('off')

            ax2 = plt.subplot(gs[1])
            im2 = ax2.imshow(target_grid, cmap=custom_cmap)
            ax2.set_title('Ground Truth', pad=20)
            ax2.axis('off')

            ax3 = plt.subplot(gs[2])
            ax3.axis('off')
            legend_elements = [Patch(facecolor=class_colors[i],
                                   edgecolor='black',
                                   linewidth=1,
                                   label=dataset_config['class_names'][i])
                             for i in range(n_classes)]
            ax3.legend(handles=legend_elements,
                      loc='center left',
                      title='Classes',
                      bbox_to_anchor=(0, 0.5),
                      borderaxespad=0,
                      ncol=1,
                      frameon=True,
                      fancybox=True,
                      shadow=True)

            plt.suptitle(f'Segmentation Maps - {model_type} on {dataset_name}', y=1.02)
            plt.tight_layout()
            plt.show()

            iou = np.mean(np.equal(all_preds, all_targets))
            print(f"\nSegmentation IoU for {model_type}: {iou:.4f}")

        except Exception as e:
            print(f"Error plotting segmentation maps for {model_type}: {str(e)}")
            traceback.print_exc()
            continue


def plot_classification_maps(dataset_name, classification_models, device):
    """Visualize classification maps with distinct colors per class"""
    print("\nVisualizing Classification Maps...")

    base_colors = ['#4E79A7', '#F28E2B', '#E15759', '#76B7B2', '#59A14F',
                   '#EDC948', '#B07AA1', '#FF9DA7', '#9C755F', '#BAB0AC',
                   '#808080', '#D4A797', '#A0CBE8', '#F1CE63', '#D4A6C8',
                   '#9D7660', '#D7B5A6', '#B279A2', '#D6BCC0', '#BB7693']

    def get_extended_colors(n_classes):
        if n_classes <= len(base_colors):
            return base_colors[:n_classes]
        else:
            additional_colors = []
            for i in range(n_classes - len(base_colors)):
                h = i / (n_classes - len(base_colors))
                rgb = colorsys.hsv_to_rgb(h, 1.0, 1.0)
                additional_colors.append('#{:02x}{:02x}{:02x}'.format(
                    int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255)))
            return base_colors + additional_colors

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            dataset_config = get_dataset_config(dataset_name)
            H, W = dataset_config['spatial_size'], dataset_config['spatial_size']

            n_classes = len(dataset_config['class_names'])
            class_colors = get_extended_colors(n_classes)
            custom_cmap = ListedColormap(class_colors)

            grid_size = int(np.ceil(np.sqrt(len(all_preds))))
            plot_shape = (grid_size * H, grid_size * W)

            pred_grid = np.zeros(plot_shape)
            target_grid = np.zeros(plot_shape)

            for idx in range(len(all_preds)):
                i, j = (idx // grid_size) * H, (idx % grid_size) * W
                pred_grid[i:i+H, j:j+W] = all_preds[idx]
                target_grid[i:i+H, j:j+W] = all_targets[idx]

            fig = plt.figure(figsize=(20, 8))
            gs = gridspec.GridSpec(1, 3, width_ratios=[10, 10, 3])

            ax1 = plt.subplot(gs[0])
            im1 = ax1.imshow(pred_grid, cmap=custom_cmap)
            ax1.set_title('Predicted Classification Map', pad=20)
            ax1.axis('off')

            ax2 = plt.subplot(gs[1])
            im2 = ax2.imshow(target_grid, cmap=custom_cmap)
            ax2.set_title('Ground Truth', pad=20)
            ax2.axis('off')

            ax3 = plt.subplot(gs[2])
            ax3.axis('off')
            legend_elements = [Patch(facecolor=class_colors[i],
                                   edgecolor='black',
                                   linewidth = 1,
                                   label=dataset_config['class_names'][i])
                             for i in range(n_classes)]
            ax3.legend(handles=legend_elements,
                      loc='center left',
                      title='Classes',
                      bbox_to_anchor=(0, 0.5),
                      borderaxespad=0,
                      ncol=1,
                      frameon=True,
                      fancybox=True,
                      shadow=True)

            plt.suptitle(f'Classification Maps - {model_type} on {dataset_name}', y=1.02)
            plt.tight_layout()
            plt.show()

            accuracy = np.mean(all_preds == all_targets)
            print(f"\nClassification Accuracy for {model_type}: {accuracy:.4f}")

        except Exception as e:
            print(f"Error plotting classification maps for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def plot_confusion_matrix(dataset_name, classification_models, device):
    """Visualize normalized confusion matrices"""
    print("\nVisualizing Confusion Matrices...")

    colors = ['#ffffff', '#d1e1ee', '#a3c4e3', '#75a7d8', '#477dcd', '#1953c2']
    custom_cmap = LinearSegmentedColormap.from_list('custom_blues', colors)

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            cm = confusion_matrix(all_targets, all_preds)
            row_sums = cm.sum(axis=1)
            cm_normalized = np.zeros_like(cm, dtype=float)

            for i in range(len(row_sums)):
                if row_sums[i] != 0:
                    cm_normalized[i] = cm[i] / row_sums[i]

            plt.figure(figsize=(12, 10))

            sns.heatmap(cm_normalized,
                       annot=True,
                       fmt='.2f',
                       cmap=custom_cmap,
                       vmin=0,
                       vmax=1,
                       xticklabels=test_dataset.class_names,
                       yticklabels=test_dataset.class_names,
                       square=True,
                       cbar_kws={'label': 'Normalized Frequency'})

            plt.title(f'Normalized Confusion Matrix - {model_type} on {dataset_name}')
            plt.xlabel('Predicted Class')
            plt.ylabel('True Class')

            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)

            plt.tight_layout()
            plt.show()

        except Exception as e:
            print(f"Error plotting confusion matrix for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def plot_roc_curves(dataset_name, classification_models, device):
    """Visualize ROC curves with proper error handling"""
    print("\nVisualizing ROC Curves...")

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_probs = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    probs = torch.softmax(output, dim=1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_probs.append(probs)
                    all_targets.append(targets)

            all_probs = np.concatenate(all_probs, axis=0)
            all_targets = np.concatenate(all_targets)

            plt.figure(figsize=(12, 8))
            for i in range(len(test_dataset.class_names)):
                fpr, tpr, _ = roc_curve(all_targets == i, all_probs[:, i])
                roc_auc = auc(fpr, tpr)

                plt.plot(fpr, tpr, label=f'{test_dataset.class_names[i]} (AUC = {roc_auc:.2f})')

            plt.plot([0, 1], [0, 1], 'k--', label='Random')
            plt.xlabel('False Positive Rate')
            plt.ylabel('True Positive Rate')
            plt.title(f'ROC Curves - {model_type} on {dataset_name}')
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.tight_layout()
            plt.grid(True)
            plt.show()

        except Exception as e:
            print(f"Error plotting ROC curves for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def plot_error_analysis(dataset_name, classification_models, device):
    """Visualize error analysis with proper error handling"""
    print("\nVisualizing Error Analysis...")

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            incorrect_mask = all_preds != all_targets
            incorrect_indices = np.where(incorrect_mask)[0]

            if len(incorrect_indices) > 0:
                incorrect_preds = all_preds[incorrect_mask]
                incorrect_targets = all_targets[incorrect_mask]

                plt.figure(figsize=(15, 8))

                plt.subplot(1, 2, 1)
                plt.scatter(incorrect_indices, incorrect_preds, c='red', label='Predicted', alpha=0.6)
                plt.scatter(incorrect_indices, incorrect_targets, c='blue', label='Actual', alpha=0.6)
                plt.xlabel('Sample Index')
                plt.ylabel('Class')
                plt.title('Misclassified Samples')
                plt.legend()
                plt.grid(True)

                plt.subplot(1, 2, 2)
                error_counts = {}
                for pred, target in zip(incorrect_preds, incorrect_targets):
                    error_pair = (target, pred)
                    error_counts[error_pair] = error_counts.get(error_pair, 0) + 1

                error_labels = [f"{test_dataset.class_names[t]}→{test_dataset.class_names[p]}"
                              for (t, p) in error_counts.keys()]
                plt.bar(error_labels, error_counts.values())
                plt.xticks(rotation=45, ha='right')
                plt.ylabel('Count')
                plt.title('Error Distribution')

                plt.suptitle(f'Error Analysis - {model_type} on {dataset_name}')
                plt.tight_layout()
                plt.show()

                print(f"\nError Analysis Summary for {model_type}:")
                print(f"Total samples: {len(all_targets)}")
                print(f"Incorrect predictions: {len(incorrect_indices)}")
                print(f"Accuracy: {1 - len(incorrect_indices)/len(all_targets):.4f}")
            else:
                print(f"\nNo errors found for {model_type}!")

        except Exception as e:
            print(f"Error in error analysis for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def print_classification_report(dataset_name, classification_models, device):
    """Print classification report with proper error handling"""
    print("\nClassification Report...")

    for model_type in classification_models:
        try:
            checkpoint_file = Path(f"checkpoints/{dataset_name}/best_{model_type}.pth")
            if not checkpoint_file.exists():
                print(f"No checkpoint found for {model_type} on {dataset_name}")
                continue

            checkpoint = load_checkpoint(checkpoint_file)
            model = create_specific_model(model_type, dataset_name).to(device)
            model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            model.eval()

            test_dataset = HyperspectralDataset(
                splits['patch_data']['test'][0],
                splits['patch_data']['test'][1],
                dataset_name,
                task_type='classification'
            )
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

            all_preds = []
            all_targets = []
            with torch.no_grad():
                for data, target in test_loader:
                    data = data.to(device)
                    output = model(data)
                    preds = output.argmax(1).cpu().numpy()
                    targets = target.cpu().numpy()
                    all_preds.extend(preds)
                    all_targets.extend(targets)

            all_preds = np.array(all_preds)
            all_targets = np.array(all_targets)

            print(f"\nClassification Report for {model_type} on {dataset_name}:")
            print(classification_report(
                all_targets,
                all_preds,
                target_names=test_dataset.class_names,
                digits=4
            ))

            cm = confusion_matrix(all_targets, all_preds)
            print("\nConfusion Matrix:")
            print(cm)

        except Exception as e:
            print(f"Error generating classification report for {model_type}: {str(e)}")
            traceback.print_exc()
            continue

def load_checkpoint(checkpoint_file: Path) -> Dict:
    """Load checkpoint with flexible state dict loading"""
    try:
        checkpoint = torch.load(checkpoint_file, map_location='cpu')

        required_keys = ['model_state_dict', 'optimizer_state_dict', 'config']
        if not all(key in checkpoint for key in required_keys):
            print(f"Warning: Checkpoint missing some expected keys: {checkpoint.keys()}")

        return checkpoint

    except Exception as e:
        print(f"Error loading checkpoint {checkpoint_file}: {str(e)}")
        raise

def create_specific_model(model_type: str, dataset_name: str) -> nn.Module:
    """
    Create a model instance based on model type

    Args:
        model_type: Type of model to create
        dataset_name: Name of dataset for model configuration

    Returns:
        Instantiated model
    """
    if model_type == 'resnet':
        return create_model(dataset_name)
    elif model_type == 'vit':
        return create_vit_model(dataset_name)
    elif model_type == '3dcnn':
        return create_3dcnn_model(dataset_name)
    elif model_type == 'hybrid':
        return create_hybrid_model(dataset_name)
    elif model_type == 'unet':
        return create_unet_model(dataset_name)
    elif model_type == 'fcn':
        return create_fcn_model(dataset_name)
    else:
        raise ValueError(f"Unknown model type: {model_type}")

def main():
    """Main visualization function with error handling"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    classification_models = ['resnet', 'vit', '3dcnn', 'hybrid']
    segmentation_models = ['unet', 'fcn']

    for dataset_name in SELECTED_DATASET:
        print(f"\nVisualizing results for {dataset_name.upper()}")

        results_dir = Path(f"results/{dataset_name}")
        if not results_dir.exists():
            print(f"No results directory found for {dataset_name}")
            continue

        try:
            classification_metrics = {
                'accuracy': [], 'precision': [], 'recall': [], 'f1': []
            }
            segmentation_metrics = {
                'iou': [], 'dice': []
            }

            for model_type in classification_models + segmentation_models:
                try:
                    results_file = Path(f"results/{dataset_name}/{model_type}_results.pt")
                    if not results_file.exists():
                        print(f"No results found for {model_type} on {dataset_name}")
                        continue

                    results = torch.load(results_file)

                    if model_type in classification_models:
                        classification_metrics['accuracy'].append(results['val_metrics']['acc'][-1])
                        classification_metrics['precision'].append(results['val_metrics']['precision'][-1])
                        classification_metrics['recall'].append(results['val_metrics']['recall'][-1])
                        classification_metrics['f1'].append(results['val_metrics']['f1'][-1])
                    else:
                        segmentation_metrics['iou'].append(results['val_metrics']['iou'][-1])
                        segmentation_metrics['dice'].append(results['val_metrics']['dice'][-1])

                except Exception as e:
                    print(f"Error processing results for {model_type}: {str(e)}")
                    continue

            if any(len(metric) > 0 for metric in classification_metrics.values()):
                plot_overall_metrics(dataset_name, classification_metrics, segmentation_metrics,
                                  classification_models, segmentation_models)
                plot_accuracy_curves(dataset_name, classification_models + segmentation_models)
                plot_precision_recall_curves(dataset_name, classification_models)
                plot_classification_maps(dataset_name, classification_models, device)
                plot_confusion_matrix(dataset_name, classification_models, device)
                plot_roc_curves(dataset_name, classification_models, device)
                plot_error_analysis(dataset_name, classification_models, device)
                print_classification_report(dataset_name, classification_models, device)

            if any(len(metric) > 0 for metric in segmentation_metrics.values()):
                plot_iou_dice_curves(dataset_name, segmentation_models)
                plot_segmentation_maps(dataset_name, segmentation_models, device)

            # Clean up
            plt.close('all')
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()

        except Exception as e:
            print(f"Error processing dataset {dataset_name}: {str(e)}")
            continue

if __name__ == "__main__":
    main()